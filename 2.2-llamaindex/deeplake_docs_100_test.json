{
    "queries": {
        "80e50c2b-c751-4d4d-b7d4-b620c2cbbb01": "What is the data type of the \"embeddings\" column added to the dataset using deeplake.types.Embedding?",
        "da9f8c78-ac62-48ca-b8d7-ebdc95cbdd73": "What data type can you retrieve from a column using the `get_async` function, and how does it differ from other retrieval methods?",
        "ab752689-3504-4438-a146-630a73962377": "What is Cross-Origin Resource Sharing (CORS) and how does it relate to enabling access to buckets containing data?",
        "59a676ae-e5c9-4623-9ac0-9db314455e4d": "What would happen if the axis of the graph of membrane potential modeled by n^6 was extended to t = infinity, and how does this relate to the eventual Membrane Voltage reached?",
        "ed056f0b-6f45-4dc4-a660-e4ec5bb1020c": "What is the primary function of the Deep Lake Vector Store as described in LangChain documentation?",
        "b5b9cae1-edb6-4b49-9a41-ee13397f0dca": "What is the purpose of enabling CORS (Cross-Origin Resource Sharing) in S3?",
        "4d4c13d1-2887-4c8d-a940-a48c9a74f9ff": "What is the purpose of provisioning role-based access in AWS with Deep Lake?",
        "2b91667e-55bb-4892-9872-99aacc8684f1": "What is the main goal of using ColBERT in the context of Discover Restaurants Using ColPali and the Late Interaction Mechanism?",
        "ea93a406-c44d-4422-8a14-db8cc2cc4a7d": "What type of query can you use to find documents that contain a specific term, and how does it differ from using BM25 similarity?",
        "a8d7de2f-1a6b-4770-932f-6973513ce45a": "What is the primary use case for setting up a Deep Lake database for an upcoming examination?",
        "dfedaf8d-054a-4b07-8305-d9ff25b782e2": "What are the different methods to create a dataset, as listed under the \"Creation Methods\" section of the API Reference?",
        "c7817bd3-306f-45ee-aa38-737a4045a550": "What is the purpose of converting the embedding generated by `embedding_function(query)` into a string using `\",\".join(str(c) for c in embed_query)?",
        "8294835d-73f7-4e33-8f19-6f6f2625b222": "What is Deep Lake, and what are its features that allow it to copy and synchronize datasets across different storage locations?",
        "5b1f1e7a-fc31-4d2a-b9d7-686fcf51faf1": "What is the recommended way to handle data streaming and batching when using Deep Lake?",
        "3ffcd8bd-9745-4759-b346-34ea3ea3793b": "How do I enable CORS in Azure?",
        "1b8299cc-7880-4df5-8a2b-17166cec5ac3": "What data type is used to represent images and embeddings in DeepLake, and how are they added as columns to a dataset?",
        "18938c92-7323-4318-92b3-79548eb95142": "What features of Deep Lake's vector search and semantic operations are essential for a machine learning application, and how can you configure these settings for optimal performance?",
        "a0ccbed3-284e-4ea5-9d3c-184ce2e3c4c5": "What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in the study?",
        "41bfb727-d48b-4bc5-95bd-b3bd7128d623": "What data type is used for storing text columns in DeepLake, and what index type is specified for this column?",
        "4e08456c-d891-49a9-91fc-46374706b9ab": "What is the default value for the \"sample_compression\" parameter when no specific compression method is specified?"
    },
    "corpus": {
        "node_531": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_266": "Parameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`index` |  `int | slice | list | tuple` |  Can be:\n\n  * int: Single item index\n  * slice: Range of indices (e.g., 0:10)\n  * list/tuple: Multiple specific indices\n\n|  _required_  \n  \nReturns:\n\nType | Description  \n---|---  \n`ndarray | list | Dict | str | bytes | None` |  The data at the specified index/indices. Type depends on the column's data type.  \n  \nExamples:\n\n    \n    \n    # Get single item\n    image = column[0]\n    \n    # Get range\n    batch = column[0:32]\n    \n    # Get specific indices\n    items = column[[1, 5, 10]]\n    \n\n####  `` __setitem__ \u00b6\n\n    \n    \n    __setitem__(index: int | slice, value: Any) -> None\n    \n\nSet data in the column at the specified index or range.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`index` |  `int | slice` |  Can be:\n\n  * int: Single item index\n  * slice: Range of indices (e.g., 0:10)\n\n|  _required_  \n`value` |  `Any` |  The data to store. Must match the column's data type. |  _required_  \n  \nExamples:\n\n    \n    \n    # Update single item\n    column[0] = new_image\n    \n    # Update range\n    column[0:32] = new_batch\n    \n\n####  `` get_async \u00b6\n\n    \n    \n    get_async(index: int | slice | list | tuple) -> Future\n    \n\nAsynchronously retrieve data from the column. Useful for large datasets or\nwhen loading multiple items in ML pipelines.",
        "node_103": "please enable Cross-Origin Resource Sharing (CORS) in the\nbuckets containing the Deep Lake dataset and any linked data, by inserting the\nsnippet below in the CORS section of the Permissions tab for the bucket:\n\n    \n    \n    [\n        {\n          \"origin\": [\"https://app.activeloop.ai\"],\n          \"method\": [\"GET\", \"HEAD\"],\n          \"responseHeader\": [\"*\"],\n          \"maxAgeSeconds\": 3600\n        }\n    ]\n    \n\n## Next Steps\u00b6\n\n  * Provisioning Federated Credentials\n\nBack to top",
        "node_741": "Embeddings are generated\nwithout gradients and converted to a list format, stored in\n`query_embeddings`.\n\n    \n    \n    queries = [\n        \"At Time (ms) = 0, the membrane potential modeled by n^6 is at -70 ms. If the axis of this graph was extended to t = infinity, what Membrane Voltage would the line modeled by n^6 eventually reach?\",\n        \"Percent frequency distribution of fiber lengths in cortex and spinal cord by diameter\"\n    ]\n    \n    batch_queries = processor.process_queries(queries).to(model.device)\n    with torch.no_grad():\n        query_embeddings = model(**batch_queries)\n    query_embeddings = query_embeddings.tolist()\n    \n\n### Retrieve the most similar images\u00b6\n\nFor each embedding in `query_embeddings`, we format it as a nested array\nstring for querying. The innermost lists (`q_substrs`) are converted to\n`ARRAY[]` format, and then combined into a single string, `q_str`. This\nformatted string is used in a query on `vector_search_images`, calculating the\n`maxsim` similarity between `q_str` and `embedding`. The query returns the top\n2 results, ordered by similarity score (`score`). This loop performs\nsimilarity searches for each query embedding.",
        "node_184": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\nUsing Deep Lake as a Vector Store in LangChain\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore  VectorStore  Table of contents \n      * How to Use Deep Lake as a Vector Store in LangChain \n      * Downloading and Preprocessing the Data \n      * A note on chunking text files \n      * Creating the Deep Lake Vector Store \n      * Use the Vector Store in a Q&A App \n      * Accessing the Low Level Deep Lake API (Advanced) \n      * SelfQueryRetriever with Deep Lake \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM",
        "node_460": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_636": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_109": "* 6) ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT \n      * 7) Discover Restaurants Using ColPali and the Late Interaction Mechanism \n        * Download the ColPali model \n        * Create a new dataset to store the ColPali embeddings \n        * Save the data in the dataset \n        * Chat with images \n        * Retrieve the most similar images \n        * VQA: Visual Question Answering \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Load the Data from Deep Lake \n  * 1) Create the Dataset and Use an Inverted Index for Filtering \n    * Extract the data \n    * Add the data to the dataset \n    * Search for the restaurant using a specific word \n    * Show the results \n  * 2) Create the Dataset and use BM25 to Retrieve the Data \n    * Add data to the dataset \n    * Search for the restaurant using a specific sentence \n    * Show the results \n  * 3) Create the Dataset and use Vector",
        "node_291": "query(f\"\"\"\n        SELECT *\n        FROM \"s3://bucket/embeddings\"\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Text Search\u00b6\n\nText search using BM25 or keyword matching:\n\n    \n    \n    # Semantic search using BM25\n    results = deeplake.query(\"\"\"\n        SELECT *\n        FROM \"s3://bucket/documents\"\n        ORDER BY BM25_SIMILARITY(text, 'search query') DESC\n        LIMIT 10\n    \"\"\")\n    \n    # Keyword search using CONTAINS\n    results = deeplake.query(\"\"\"\n        SELECT *\n        FROM \"s3://bucket/metadata\"\n        WHERE CONTAINS(keywords, 'specific term')\n    \"\"\")\n    \n\n## Array Operations\u00b6\n\nOperate on multidimensional arrays:\n\n    \n    \n    # Select specific array dimensions\n    results = deeplake.query(\"\"\"\n        SELECT features[:, 0:10]\n        FROM \"s3://bucket/features\"\n    \"\"\")\n    \n    # Filter by array values\n    results = deeplake.query(\"\"\"\n        SELECT *\n        FROM \"s3://bucket/features\"\n        WHERE features[0] > 0.5\n    \"\"\")\n    \n    # Aggregate array operations\n    results = deeplake.query(\"\"\"\n        SELECT AVG(features, axis=0)\n        FROM \"s3://bucket/features\"\n    \"\"\")\n    \n\n## Joining Datasets\u00b6\n\nJoin data across different datasets and across different clouds:\n\n    \n    \n    # Join datasets from different storage\n    results = deeplake.query(\"\"\"\n        SELECT i.image, i.embedding, m.labels, m.metadata\n        FROM \"s3://bucket1/images\" AS i\n        JOIN \"s3://bucket2/metadata\" AS m \n        ON i.id = m.image_id\n        WHERE m.verified = true\n    \"\"\")\n    \n    # Complex join with filtering\n    results = deeplake.query(\"\"\"\n        SELECT \n            i.image,\n            e.embedding,\n            l.label\n        FROM \"s3://bucket1/images\" AS i\n        JOIN \"gcs://bucket2/embeddings\" AS e ON i.id = e.",
        "node_405": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_235": "Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset  Dataset  Table of contents \n      * Creation Methods \n        * create \n        * open \n        * open_read_only \n        * like \n      * Dataset Class \n        * Dataset \n      * ReadOnlyDataset Class \n        * ReadOnlyDataset \n      * DatasetView Class \n        * DatasetView \n      * Class Comparison \n        * Dataset \n        * ReadOnlyDataset \n        * DatasetView \n      * Examples \n        * Querying Data \n        * Data Access \n        * Async Operations \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Creation Methods \n    * create \n    * open \n    * open_read_only \n    * like \n  * Dataset Class \n    * Dataset \n  *",
        "node_126": "1. **Generate Embedding for Query** : \n\n     * We call `embedding_function(query)` to generate an embedding for this query. Since `embedding_function` returns a list, we access the first (and only) item with `[0]`, storing the result in `embed_query`.\n  2. **Convert Embedding to String** : \n\n     * We convert `embed_query` (a list of numbers) into a single comma-separated string using `\",\".join(str(c) for c in embed_query)`. This step stores the embedding as a formatted string in `str_query`, preparing it for further processing or use in queries.\n\n    \n    \n    query = \"A restaurant that serves good burritos.\"\n    embed_query = embedding_function(query)[0]\n    str_query = \",\".join(str(c) for c in embed_query)\n    \n\n  1. **Define Query with Cosine Similarity** : \n  2. We construct a TQL query (`query_vs`) to search within the `vector_search` dataset.\n\n  3. The query calculates the **cosine similarity** between the `embedding` column and `str_query`, which is the embedding of our query, `\"A restaurant that serves good burritos.\"`. This similarity score `score` measures how closely each entry matches our query.\n\n  4. **Order by Score and Limit Results** : \n\n  5. The query orders results by `score` in descending order, showing the most relevant matches first. We limit the results to the top 3 matches to focus on the best results.\n\n  6. **Execute Query** : \n\n  7. `vector_search.query(query_vs)` runs the query on the dataset, storing the output in `view_vs`, which contains the top 3 most similar entries based on cosine similarity. This approach helps us retrieve the most relevant records matching our query in `vector_search`.",
        "node_337": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\nDataset Copying and Synchronization\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets  Synchronize Datasets  Table of contents \n      * Copying Datasets \n      * Dataset Synchronization \n        * Pull Changes \n        * Push Changes \n      * Synchronization Example \n      * Summary \n\nTable of contents\n\n  * Copying Datasets \n  * Dataset Synchronization \n    * Pull Changes \n    * Push Changes \n  * Synchronization Example \n  * Summary \n\n# Dataset Copying and Synchronization\u00b6\n\nDeep Lake allows copying and synchronizing datasets across different storage\nlocations.",
        "node_211": "**Simple Data Loading** : Deep Lake automatically handles data streaming and batching, so you don't need to write custom data loaders.\n\n  2. **Efficient Storage** : Data is stored in an optimized format and loaded on-demand, saving disk space and memory.\n\n  3. **Easy Tensor Mapping** : The `deeplake_tensors` config maps your dataset's tensor names to what MMDetection expects, making it easy to use any dataset.\n\n  4. **Built-in Authentication** : Deep Lake handles authentication and access control for your datasets securely.\n\n  5. **Distributed Training Support** : The integration works seamlessly with MMDetection's distributed training capabilities.\n\n## Monitoring Training\u00b6\n\nYou can monitor the training progress in the work directory:\n\n    \n    \n    # Check latest log file\n    log_file = os.path.join(cfg.work_dir, 'latest.log')\n    if os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            print(f.read())\n    \n\n## Inference\u00b6\n\nAfter training, you can use the model for inference:\n\n    \n    \n    from mmdet.apis import inference_detector, init_detector\n    \n    # Load trained model\n    checkpoint = os.path.join(cfg.work_dir, 'latest.pth')\n    model = init_detector(config_path, checkpoint)\n    \n    # Load an image\n    img = 'path/to/test/image.jpg'\n    \n    # Run inference\n    result = inference_detector(model, img)\n    \n\n## Common Issues and Solutions\u00b6\n\n  1. If you get CUDA out of memory errors:\n\n     * Reduce `samples_per_gpu` in the config\n     * Use smaller image sizes in the pipeline\n  2. If training is slow:\n\n     * Increase `num_workers` in `deeplake_dataloader`\n     * Use distributed training with multiple GPUs\n  3.",
        "node_488": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_554": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_381": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_165": "**Text Extraction** : \n\n     * The text data from the medical dataset is extracted into a list (`medical_text`) by iterating over the dataset and pulling the `text` field for each entry.\n  2. **Batch Embedding Generation** : \n\n     * The text data is processed in batches of 1,000 entries using the ColBERT model (`ckpt.docFromText`), which generates embeddings for each batch.\n\n     * The embeddings are appended to a list (`all_vectors`) for later use.\n\n  3. **Efficient Processing** :\n\n     * Batching ensures efficient processing, especially when dealing with large datasets, as it prevents memory overload and speeds up embedding generation.\n\n    \n    \n    all_vectors = []\n    medical_text = [el[\"text\"] for el in medical_dataset]\n    \n    for i in range(0, len(medical_text), 1000):\n        chunk = medical_text[i:i+1000]\n        vectors_chunk = ckpt.docFromText(chunk)\n        all_vectors.extend(vectors_chunk)\n    \n    \n    \n    list_of_embeddings = [vector.tolist() for vector in all_vectors]\n    len(list_of_embeddings)\n    \n\nWe convert the embeddings into Python lists for compatibility with Deep Lake\nstorage and checks the total number of embeddings. Each embedding from\nall_vectors is transformed using `.tolist()`, creating list_of_embeddings, and\n`len(list_of_embeddings)` confirms the total count matches the processed text\nentries.\n\n    \n    \n    medical_dataset[\"embedding\"][0:len(list_of_embeddings)] = list_of_embeddings\n    medical_dataset.commit()\n    \n\nThis code performs a semantic search using ColBERT embeddings, leveraging the\nMaxSim operator, executed directly in the cloud (as described in the `index-\non-the-lake` section), for efficient similarity computations.\n\n  1. **Query Embedding** : The query is embedded with `ckpt.queryFromText` and converted into a format compatible with TQL queries.\n\n    \n    \n    query_vectors = ckpt.queryFromText([\"What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in the study?\"])[0]\n    query_vectors = query_vectors.tolist()\n    \n\n  1.",
        "node_455": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_281": "NOTE: Since binary masks often contain large amounts of data, it is\nrecommended to compress them using lz4.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`sample_compression` |  `str | None` |  How to compress each row's value. Possible values: lz4, null (default: null) |  `None`  \n`chunk_compression` |  `str | None` |  How to compress all the values stored in a single file. Possible values: lz4, null (default: null) |  `None`  \n  \nExamples:\n\n    \n    \n    ds.add_column(\"col1\", types.BinaryMask(sample_compression=\"lz4\"))\n    ds.append([{\"col1\": np.zeros((512, 512, 5), dtype=\"bool\")}])\n    \n    \n    \n    # Basic binary mask\n    ds.add_column(\"masks\", deeplake.types.BinaryMask())\n    \n    # With compression\n    ds.add_column(\"masks\", deeplake.types.BinaryMask(\n        sample_compression=\"lz4\"\n    ))\n    \n\n##  `` deeplake.types.SegmentMask \u00b6\n\n    \n    \n    SegmentMask(\n        dtype: DataType | str = \"uint8\",\n        sample_compression: str | None = None,\n        chunk_compression: str | None = None,\n    ) -> Type\n    \n\nSegmentation masks are 2D representations of class labels where a numerical\nclass value is encoded in an array of same shape as the image.\n\nNOTE: Since segmentation masks often contain large amounts of data, it is\nrecommended to compress them using lz4.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`sample_compression` |  `str | None` |  How to compress each row's value. Possible values: lz4, null (default: null) |  `None`  \n`chunk_compression` |  `str | None` |  How to compress all the values stored in a single file."
    },
    "relevant_docs": {
        "80e50c2b-c751-4d4d-b7d4-b620c2cbbb01": [
            "node_531"
        ],
        "da9f8c78-ac62-48ca-b8d7-ebdc95cbdd73": [
            "node_266"
        ],
        "ab752689-3504-4438-a146-630a73962377": [
            "node_103"
        ],
        "59a676ae-e5c9-4623-9ac0-9db314455e4d": [
            "node_741"
        ],
        "ed056f0b-6f45-4dc4-a660-e4ec5bb1020c": [
            "node_184"
        ],
        "b5b9cae1-edb6-4b49-9a41-ee13397f0dca": [
            "node_460"
        ],
        "4d4c13d1-2887-4c8d-a940-a48c9a74f9ff": [
            "node_636"
        ],
        "2b91667e-55bb-4892-9872-99aacc8684f1": [
            "node_109"
        ],
        "ea93a406-c44d-4422-8a14-db8cc2cc4a7d": [
            "node_291"
        ],
        "a8d7de2f-1a6b-4770-932f-6973513ce45a": [
            "node_405"
        ],
        "dfedaf8d-054a-4b07-8305-d9ff25b782e2": [
            "node_235"
        ],
        "c7817bd3-306f-45ee-aa38-737a4045a550": [
            "node_126"
        ],
        "8294835d-73f7-4e33-8f19-6f6f2625b222": [
            "node_337"
        ],
        "5b1f1e7a-fc31-4d2a-b9d7-686fcf51faf1": [
            "node_211"
        ],
        "3ffcd8bd-9745-4759-b346-34ea3ea3793b": [
            "node_488"
        ],
        "1b8299cc-7880-4df5-8a2b-17166cec5ac3": [
            "node_554"
        ],
        "18938c92-7323-4318-92b3-79548eb95142": [
            "node_381"
        ],
        "a0ccbed3-284e-4ea5-9d3c-184ce2e3c4c5": [
            "node_165"
        ],
        "41bfb727-d48b-4bc5-95bd-b3bd7128d623": [
            "node_455"
        ],
        "4e08456c-d891-49a9-91fc-46374706b9ab": [
            "node_281"
        ]
    },
    "mode": "text"
}
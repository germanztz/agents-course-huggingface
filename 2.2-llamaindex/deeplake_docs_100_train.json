{
    "queries": {
        "ff7267a0-e17a-4d8e-9b7f-413a1a7806e8": "What type of data can be stored using this database?",
        "6674535d-7323-4bca-8d35-7dfd16ddf286": "What is the primary purpose of enabling CORS (Cross-Origin Resource Sharing) in AWS S3, according to the documentation?",
        "27444152-0ce2-475c-b97d-5913cc01ecec": "What is the purpose of enabling CORS (Cross-Origin Resource Sharing) in S3, and how does it relate to role-based access control?",
        "0961fab0-d6c8-454e-b3e9-1aa530c6ec2f": "import deeplake as dpl",
        "f0ec27f9-7452-4ac6-afe3-311b65201bd3": "What is the purpose of enabling CORS in S3?",
        "e27115d2-6ba7-471a-9f5c-633a932eb25f": "What happens if no version is given when tagging a dataset?",
        "ee7252f7-6508-4f83-a34e-35dc393b8305": "What is the primary difference between Deep Lake and DVC in terms of data storage format?",
        "f072e6d0-465a-458f-9e74-940c9adc23ed": "What is the purpose of the Deep Lake Slack community and survey?",
        "a4a77652-93c2-412d-a710-a401f50197fd": "How do you enable CORS (Cross-Origin Resource Sharing) in S3 (Amazon Simple Storage Service)?",
        "63adba5a-c5d1-4faf-b643-924b67dff787": "What is the method used to combine scores from vector-based search results (vector results) and BM25 search results in a hybrid search?",
        "ec94b0f5-53eb-4445-a62d-cebea13f52f8": "How do you enable CORS in S3?",
        "cc842c7e-dff5-4c97-95d0-130412211900": "What is the purpose of adding a column named \"text\" with a specific index type (BM25) to a Deeplake dataset for RAG applications?",
        "da826b2c-60b8-4dbb-84e7-3aa32395d380": "What benefits does registering with Activeloop offer?",
        "1d7cbf3a-c381-449f-b876-a690bfa55af2": "What does \"Do not share my personal information\" suggest about user consent and privacy policies?",
        "57ec3e58-f259-4a9a-b15b-df74df56bd5a": "What is GitHub Copilot, and what type of tool does it use?",
        "ff9270fa-7412-43db-a009-727074522d99": "What is the purpose of adding a column called \"embeddings\" with a size of 1536 in Deeplake?",
        "2e3edd22-6ebe-471e-8735-e0b9036aeb05": "What type of data compression is supported by Deep Lake for images and masks?",
        "a0f9e2dd-99d9-4801-8027-f7d05ed08748": "What is Deep Lake primarily designed for, and what type of data formats does it store?",
        "30c423b1-eb09-41d3-8db8-502e3da2b043": "What is Deep Lake and how can it be installed?",
        "2a825624-3282-4d33-8c93-171c22991be5": "What is the primary difference between Deep Lake and MosaicML's data storage formats?",
        "63f8815f-5b81-4c50-8dbf-ec7d8978b0f0": "What data types does Deep Lake support for ML applications, and how can it be integrated with popular frameworks like PyTorch and TensorFlow?",
        "4cb49d07-9722-4968-ab77-855b0cefc6fb": "What is the name of the pretrained checkpoint that can be loaded to use ColBERT's capabilities in semantic search and ranking tasks efficiently?",
        "7624e38c-94b4-4d67-974e-6d1bc03e34ce": "What is the recommended approach when iterating over a dataset, and why is it faster than accessing rows individually?",
        "ec0ab26f-80a1-4a97-aefa-2e02e408e8f5": "What data types can you store and query in Deep Lake, besides vector search?",
        "aa16e6f8-d694-4796-845d-5cd120b0d20d": "What is the primary purpose of Deep Lake, and how does it differ from other databases?",
        "ce733ec2-eaba-4264-937d-a25b88f12a2b": "What is the recommended method for getting the version timestamp, and what does it imply about the accuracy of this value compared to deeplake.Version.client_timestamp?",
        "69af123c-785d-490f-8f3a-35d0722fee74": "What is the purpose of adding a column for \"images\" in the dataset with type deeplake.types.Image()?",
        "fce01963-73ff-4404-9042-94faa9f1f306": "What is the purpose of creating a Deep Lake dataset inside the `./animals_dl` folder?",
        "112119cc-08b2-4fd6-8445-4a498b9ffd31": "What are the top 5 results from both vector search and BM25 similarity searches, along with their scores for a given query?",
        "f6a9bf06-3ede-4a9e-8244-01c28e2b6111": "What data type is the 'ds' variable, as it can hold a dataset with multiple columns and rows?",
        "b12a9464-62dd-42b5-be1a-f2eb628625bd": "What is the primary purpose of using a Large Language Model (LLM) in this context, and how does it differ from simply listing relevant documents?",
        "ce38040b-9064-4e6b-970d-aada69d05154": "What data type is used to store embeddings in DeepLake?",
        "6ca9b4ac-2617-4794-b1a5-1e07d044ba1c": "What is the purpose of provisioning Role-Based Access in Deep Lake's AWS integration?",
        "ae61fd82-3ab3-475a-ae15-2c4c08bd5730": "What is the data type of the `image` column after it's saved to the vector search images dataset?",
        "be439e90-c1eb-46ab-bd59-46186c745a6f": "How do I install Deep Lake using pip?",
        "09236568-d5cb-4fbe-9ae5-9b6ba1d17ec8": "What is the purpose of clicking on a link to go to the latest version of a webpage?",
        "87d76774-7d61-4a92-bf18-0c43a0e699e9": "What data compression type is used for the \"masks\" column in the Computer Vision application?",
        "5b68ef3e-3e66-4376-880d-48e6f472d2dc": "What are the benefits of using Deep Lake Integration for semantic segmentation, as mentioned in the table of contents?",
        "5fa8b928-fe11-4f00-8408-e506606dd9e4": "What data structure does Deeplake use to store and manage its datasets, as demonstrated by the code snippet that creates a dataset with three columns: \"images\", \"embeddings\", and \"labels\"?",
        "f9518384-c84b-4fb3-9643-9384a69aa588": "What data type and shape is assigned to the new 'embedding' column added to the medical dataset?",
        "8cd47418-b686-4bec-9a8a-fee06898f49d": "How do I integrate Deeplake with my existing machine learning framework, considering it is optimized for PyTorch and TensorFlow?",
        "db48e8d4-67d3-4112-a671-8e4d2561d7ac": "What data types does Deep Lake support for machine learning applications, and how are they integrated with popular ML frameworks such as PyTorch and TensorFlow?",
        "6b6adb75-1201-4c20-96fe-b8a085b61910": "What type of credentials do Deep Lake Managed use to grant client access to cloud storage?",
        "773c7d41-c514-418b-825d-0aaa0b6ab984": "What type of data does the column hold, and how is it accessed using async/await and get_async methods?",
        "da1e2c5e-424d-421f-9828-a5e6e7e32fbd": "What data types and operations can you use with Deep Lake to create a diverse set of questions for the upcoming quiz/examination?",
        "87ce603d-ce54-478b-aed3-6e044561a247": "What features of Deep Lake's vector search and semantic operations would you like to explore further, considering its optimized architecture for machine learning applications?",
        "de666ccc-e8a9-42b1-9ef3-b73fd46fa530": "What is the main benefit of using Deep Lake's automatic format conversion feature, and how does it handle different mask formats such as binary, RLE, and polygon?",
        "a7099122-df85-47d7-b83d-5fec4819d6ec": "What happens if the PyTorch library is not installed, and how can you handle this situation?",
        "d2d9181e-bfb6-4d94-b0bb-1a95554b1b6f": "What is the purpose of the `rename` method in the `Tags` class?",
        "24f39dad-c53b-4ff2-b78d-6ea2f3f899e8": "What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in the study among susceptible dogs?",
        "8293b1d5-658c-46f8-ac46-ffd5044dc262": "What is Deep Lake and how does it help build a Q&A App?",
        "fdcc1d90-c16a-4bdd-91e9-803493465fa0": "What data structure (Queue) is used to manage the data generated by the `AsyncImageDataset` class and how does it help improve data loading times?",
        "ea5ad105-9896-4801-9288-0c3a454f4c47": "What data types and formats are supported by Deep Lake's vector search capabilities, and how do they compare with other popular semantic search methods?",
        "4401931d-eb27-4f07-9040-568363099508": "What is the primary benefit of using Deep Lake while storing data in your own cloud, such as AWS, Azure, or GCP, without passing it through Activeloop Servers?",
        "d868cffb-9d59-4af1-a86b-094d561fdb5e": "What is the purpose of adding a column \"text\" with index type BM25 to the dataset ds in the RAG application use case?",
        "80fcdf86-7dca-4262-bc6a-f8ab29a54508": "What data types does Deep Lake support for machine learning applications?",
        "3863282b-e7b4-4ecd-aa0d-73e8bbdae715": "What data compression algorithms does Deep Lake support for storing images and other media types?",
        "2960ec79-13f5-436d-8a48-c7b5120efc12": "What is the purpose of adding a column named \"embeddings\" with size 1536 using deeplake's types.Embedding?",
        "dc591afd-82b8-44d0-bd5a-008893cd7c0a": "What is the impact of setting `quantize` to `True` on the performance of a dataset created with the COCO Images schema?",
        "048822fe-1910-4059-a15a-e8fdf15588ec": "What happens if 'aws_access_key_id', 'aws_secret_access_key', 'aws_session_token' are present when using credentials managed in your Activeloop organization?",
        "2f2cf480-2e6b-4802-b797-1ed8ef38765a": "What type of compression is used for image data in the Computer Vision application?",
        "de4a69f2-73ca-4eb1-b99c-4a97285bb859": "What type of data storage is used by Deeplake for storing datasets, specifically \"s3://my-bucket/dataset\" or a local path?",
        "cd5d69f7-e700-407c-a459-948c370a762f": "What specific aspect of Deep Lake's functionality would you like us to explore further as part of your upcoming quiz, given its vector search capabilities and integration with ML frameworks?",
        "8a68c998-48fd-44bd-bfd2-33a4bf0c4daa": "What type of platform does GitHub offer for enterprises?",
        "0a92de03-b293-4f13-a274-a12fa66d6ccf": "What is the default compression format used when storing image data in Deeplake?",
        "98fc5f1e-5e7b-4f3a-9981-3cc0b54ce11e": "What type of data compression is supported for image data in Deeplake?",
        "76b551a3-d724-4ba3-b430-5bde4481f774": "What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in a medical study?",
        "309f1c59-cf51-4d85-85c6-0c05d9dcf076": "What is the main objective of using a specific sentence for searching a restaurant, and how does it relate to the Hybrid Search method?",
        "e527b35f-3015-4a30-9555-cf54a6658cea": "What data type is used to represent embeddings in deeplake, as indicated by the schema example deeplake.schemas.TextEmbeddings?",
        "54035737-f430-439f-824c-2960cbffc636": "What is the main difference between Deep Lake and DVC's approach to storing data, specifically regarding dataset version control?",
        "934c5436-4026-4f76-bbf2-511f58fcc3d9": "What type of data compression is supported by Deep Lake's \"SegmentMask\" column?",
        "307ffce4-3ac2-451d-af58-8b6fccb0dce2": "What is the purpose of storing vector results and BM25 scores in separate variables (`vs_results` and `bm25_results`) after executing both queries?",
        "f3970fe2-c5e7-4a67-90fc-497a67442a04": "What is the purpose of storing and querying AI data with a database?",
        "9205f8c2-fe3b-40fb-a810-8467fef62958": "What is the primary access level granted when creating a `ReadOnlyDataset` class?",
        "b0495368-b39a-42ec-ad68-64b578073ae3": "What happens to the voltage modeled by n^6 as time approaches infinity?",
        "6a8fba83-2507-4691-873d-9cb4c6622afc": "What is the output of calling `ds.branch(\"Branch1\")`?",
        "5d105cb2-d0c8-4308-bd74-c9d187cf38a3": "What is the purpose of setting the \"indexing_mode\" property of a dataset?",
        "23fa1d2b-1541-40c2-91b9-23048dda4edd": "What specific AI features would you like to test on a sample dataset from Deep Lake, and how can we utilize vector search capabilities for efficient similarity measurements between different data types such as images and embeddings?",
        "cd741ffe-ad32-441e-9382-3b4c86e72dd6": "What data structure would you recommend setting up for Deep Lake to efficiently store and manage large-scale image and embedding datasets?",
        "a2dff3a9-6d5e-4657-9260-2af292d4f05b": "What is the purpose of saving the dataset ready for storing data for multi-modal search tasks with images and metadata after defining its structure?"
    },
    "corpus": {
        "node_783": "We\nwould like to thank William Silversmith @SeungLab for his awesome cloud-volume\ntool.\n\n## About\n\nDatabase for AI. Store Vectors, Images, Texts, Videos, etc. Use with\nLLMs/LangChain. Store, query, version, & visualize any AI data. Stream data in\nreal-time to PyTorch/TensorFlow.",
        "node_604": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_556": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_176": "figQA_dataset = \"figQA_dataset\"\n    fig_qa = deeplake.open_read_only(f\"al://activeloop/{figQA_dataset}\")\n    figure_images = [Image.fromarray(el[\"image\"]) for el in fig_qa]\n    questions = [el[\"question\"] for el in  fig_qa]\n    \n\n### Create a new dataset to store the ColPali embeddings\u00b6\n\nWe create a Deep Lake dataset named `\"tabqa_colpali\"` for ColPali's table-\nbased question answering. Stored in `vector_search_images`, it includes an\n`embedding`** column for 2D float arrays, a `question` column for text, and an\n`image` column for table images. After defining the structure,\n`vector_search_images.commit()` saves the setup, optimizing it for ColPali's\nmulti-modal retrieval in table QA tasks.\n\n    \n    \n    late_interaction_dataset_name = \"figQA_colpali\"\n    vector_search_images = deeplake.create(f\"al://{org_id}/{late_interaction_dataset_name}\")\n    \n    vector_search_images.add_column(name=\"embedding\", dtype=types.Array(types.Float32(),dimensions=2))\n    vector_search_images.add_column(name=\"question\", dtype=types.Text())\n    vector_search_images.add_column(name=\"image\", dtype=types.Image(dtype=types.UInt8()))\n    \n    vector_search_images.commit()\n    \n\n### Save the data in the dataset\u00b6\n\nWe batch-process and store ColPali embeddings for table-based question\nanswering. Using a `batch_size` of 2, we take the first 10 tables and\nquestions from `table_qa`. For each pair, if `question` is a single string,\nit's converted to a list. The `table_image` is processed in batches, passed\nthrough `processor` and ColPali, and embeddings are generated without\ngradients. These embeddings are stored as lists and appended with each\nquestion and image to `vector_search_images`.Finally,\n`vector_search_images.commit()` saves everything for efficient retrieval.",
        "node_436": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_253": "If no version is given, the current version is\ntagged.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`name` |  `str` |  The name of the tag |  _required_  \n`version` |  `str | None` |  The version of the dataset to tag |  `None`  \n  \n####  `` tags `property` \u00b6\n\n    \n    \n    tags: Tags\n    \n\nThe collection of deeplake.Tags within the dataset\n\n####  `` push \u00b6\n\n    \n    \n    push(\n        url: str,\n        creds: dict[str, str] | None = None,\n        token: str | None = None,\n    ) -> None\n    \n\nPushes any new history from this dataset to the dataset at the given url\n\nSimilar to deeplake.Dataset.pull but the other direction.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`url` |  `str` |  The URL of the destination dataset |  _required_  \n`creds` |  `dict[str, str] | None` |  Optional credentials needed to connect to the dataset |  `None`  \n`token` |  `str | None` |  Optional deeplake token |  `None`  \n  \n####  `` pull \u00b6\n\n    \n    \n    pull(\n        url: str,\n        creds: dict[str, str] | None = None,\n        token: str | None = None,\n    ) -> None\n    \n\nPulls any new history from the dataset at the passed url into this dataset.\n\nSimilar to deeplake.Dataset.push but the other direction.",
        "node_25": "Deep Lake datasets can be visualized and version\ncontrolled. Weaviate is limited to light metadata on top of the embeddings and\nhas no visualization. Deep Lake also has a performant dataloader for fine-\ntuning your Large Language Models.\n\n**Deep Lake vs DVC**\n\nDeep Lake and DVC offer dataset version control similar to git for data, but\ntheir methods for storing data differ significantly. Deep Lake converts and\nstores data as chunked compressed arrays, which enables rapid streaming to ML\nmodels, whereas DVC operates on top of data stored in less efficient\ntraditional file structures. The Deep Lake format makes dataset versioning\nsignificantly easier compared to traditional file structures by DVC when\ndatasets are composed of many files (i.e., many images). An additional\ndistinction is that DVC primarily uses a command-line interface, whereas Deep\nLake is a Python package. Lastly, Deep Lake offers an API to easily connect\ndatasets to ML frameworks and other common ML tools and enables instant\ndataset visualization through Activeloop's visualization tool.\n\n**Deep Lake vs MosaicML MDS format**\n\n  * **Data Storage Format:** Deep Lake operates on a columnar storage format, whereas MDS utilizes a row-wise storage approach. This fundamentally impacts how data is read, written, and organized in each system.\n  * **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor. This feature eliminates the need for additional compressions like zstd, which would otherwise demand more CPU cycles for decompressing on top of formats like jpeg.",
        "node_63": "## Community\n\nJoin our **Slack community** to learn more about unstructured dataset\nmanagement using Deep Lake and to get help from the Activeloop team and other\nusers.\n\nWe'd love your feedback by completing our 3-minute **survey**.\n\nAs always, thanks to our amazing contributors!\n\nMade with contributors-img.\n\nPlease read CONTRIBUTING.md to get started with making contributions to Deep\nLake.\n\n## README Badge\n\nUsing Deep Lake? Add a README badge to let everyone know:\n\n    \n    \n    [![deeplake](https://img.shields.io/badge/powered%20by-Deep%20Lake%20-ff5a1f.svg)](https://github.com/activeloopai/deeplake)\n\n## Disclaimers\n\n**Dataset Licenses**\n\nDeep Lake users may have access to a variety of publicly available datasets.\nWe do not host or distribute these datasets, vouch for their quality or\nfairness, or claim that you have a license to use the datasets. It is your\nresponsibility to determine whether you have permission to use the datasets\nunder their license.\n\nIf you're a dataset owner and do not want your dataset to be included in this\nlibrary, please get in touch through a GitHub issue. Thank you for your\ncontribution to the ML community!\n\n**Usage Tracking**\n\nBy default, we collect usage data using Bugout (here's the code that does it).\nIt does not collect user data other than anonymized IP address data, and it\nonly logs the Deep Lake library's own actions. This helps our team understand\nhow the tool is used and how to build features that matter to you!",
        "node_524": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_701": "I love their wet Chili Verde burritos'}, score=0.04177094836797888)}\n    \n\n### Fusion method\u00b6\n\nWe define weights for our hybrid search: `VECTOR_WEIGHT` and `LEXICAL_WEIGHT`\nare both set to `0.5`, giving equal importance to vector-based and BM25\nscores.\n\n  1. **Initialize Results Dictionary** : \n\n     * We create an empty dictionary, `results`, to store documents with their combined scores from both search methods.\n  2. **Combine Scores** : \n\n     * We iterate over the unique document IDs from `docs_vs` and `docs_bm25`.\n\n     * For each document: \n\n       * We add it to `results`, defaulting to the version available (vector or BM25).\n       * We calculate a weighted score: `vs_score` from vector results (if present in `docs_vs`) and `bm_score` from BM25 results (if present in `docs_bm25`).\n       * The final `results[k].score` is set by adding `vs_score` and `bm_score`.\n\nThis produces a fused score for each document in `results`, ready to rank in\nthe hybrid search.",
        "node_234": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\nDataset Classes\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset  Dataset  Table of contents \n      * Creation Methods \n        * create \n        * open \n        * open_read_only \n        * like \n      * Dataset Class \n        * Dataset",
        "node_414": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_77": "## Storing Datasets in Your Own Cloud\u00b6\n\nDeep Lake can be used as a pure OSS package without any registration or\nrelationship with Activeloop. However, registering with Activeloop offers\nseveral benefits:\n\n  * Storage provided by Activeloop\n  * Access to Deep Lake App, which provides dataset visualization, querying, version control UI, dataset analytics, and other powerful features\n  * Managed credentials for Deep Lake datasets stored outside of Activeloop\n\nTip\n\nWhen connecting data from your cloud using Managed Credentials, the data is\nnever stored or cached in Deep Lake. All Deep Lake user interfaces (browser,\npython, etc.) fetch data directly from long-term storage.\n\n## Next Steps\u00b6\n\n  * Storage Options\n  * Configuring Managed Credentials\n\nBack to top",
        "node_785": "### Footer navigation\n\n  * Terms\n  * Privacy\n  * Security\n  * Status\n  * Docs\n  * Contact\n  * Manage cookies \n  * Do not share my personal information \n\nYou can\u2019t perform that action at this time.",
        "node_42": "Skip to content\n\n## Navigation Menu\n\nToggle navigation\n\nSign in\n\n  * Product \n\n    * GitHub Copilot\n\nWrite better code with AI\n\n    * GitHub Advanced Security\n\nFind and fix vulnerabilities\n\n    * Actions\n\nAutomate any workflow\n\n    * Codespaces\n\nInstant dev environments\n\n    * Issues\n\nPlan and track work\n\n    * Code Review\n\nManage code changes\n\n    * Discussions\n\nCollaborate outside of code\n\n    * Code Search\n\nFind more, search less\n\nExplore\n\n    * All features \n    * Documentation \n    * GitHub Skills \n    * Blog \n\n  * Solutions \n\nBy company size\n\n    * Enterprises \n    * Small and medium teams \n    * Startups \n    * Nonprofits \n\nBy use case\n\n    * DevSecOps \n    * DevOps \n    * CI/CD \n    * View all use cases \n\nBy industry\n\n    * Healthcare \n    * Financial services \n    * Manufacturing \n    * Government \n    * View all industries \n\nView all solutions\n\n  * Resources \n\nTopics\n\n    * AI \n    * DevOps \n    * Security \n    * Software Development \n    * View all \n\nExplore\n\n    * Learning Pathways \n    * Events & Webinars \n    * Ebooks & Whitepapers \n    * Customer Stories \n    * Partners \n    * Executive Insights \n\n  * Open Source \n\n    * GitHub Sponsors\n\nFund open source developers\n\n    * The ReadME Project\n\nGitHub community articles\n\nRepositories\n\n    * Topics \n    * Trending \n    * Collections \n\n  * Enterprise \n\n    * Enterprise platform\n\nAI-powered developer platform\n\nAvailable add-ons\n\n    * GitHub Advanced Security\n\nEnterprise-grade security features\n\n    * Copilot for business\n\nEnterprise-grade AI features\n\n    * Premium Support\n\nEnterprise-grade 24/7 support\n\n  * Pricing\n\nSearch or jump to.",
        "node_375": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_403": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_62": "**Deep Lake vs Zarr** Deep Lake and Zarr both offer storage of data as chunked\narrays. However, Deep Lake is primarily designed for returning data as arrays\nusing a simple API, rather than actually storing raw arrays (even though\nthat's also possible). Deep Lake stores data in use-case-optimized formats,\nsuch as jpeg or png for images, or mp4 for video, and the user treats the data\nas if it's an array, because Deep Lake handles all the data processing in\nbetween. Deep Lake offers more flexibility for storing arrays with dynamic\nshape (ragged tensors), and it provides several features that are not naively\navailable in Zarr such as version control, data streaming, and connecting data\nto ML Frameworks.\n\n## Community\n\nJoin our **Slack community** to learn more about unstructured dataset\nmanagement using Deep Lake and to get help from the Activeloop team and other\nusers.\n\nWe'd love your feedback by completing our 3-minute **survey**.\n\nAs always, thanks to our amazing contributors!\n\nMade with contributors-img.\n\nPlease read CONTRIBUTING.md to get started with making contributions to Deep\nLake.\n\n## README Badge\n\nUsing Deep Lake? Add a README badge to let everyone know:\n\n    \n    \n    [![deeplake](https://img.shields.io/badge/powered%20by-Deep%20Lake%20-ff5a1f.svg)](https://github.com/activeloopai/deeplake)\n\n## Disclaimers\n\n**Dataset Licenses**\n\nDeep Lake users may have access to a variety of publicly available datasets.",
        "node_766": "**Native Compression with Lazy NumPy-like Indexing** Store images, audio, and\nvideos in their native compression. Slice, index, iterate, and interact with\nyour data like a collection of NumPy arrays in your system's memory. Deep Lake\nlazily loads data only when needed, e.g., when training a model or running\nqueries.  **Dataloaders for Popular Deep Learning Frameworks** Deep Lake comes\nwith built-in dataloaders for Pytorch and TensorFlow. Train your model with a\nfew lines of code - we even take care of dataset shuffling. :)  **Integrations\nwith Powerful Tools** Deep Lake has integrations with Langchain and LLamaIndex\nas a vector store for LLM apps, Weights & Biases for data lineage during model\ntraining, MMDetection for training object detection models, and MMSegmentation\nfor training semantic segmentation models.  **100+ most-popular image, video,\nand audio datasets available in seconds** Deep Lake community has uploaded\n100+ image, video and audio datasets like MNIST, COCO, ImageNet, CIFAR, GTZAN\nand others.  **Instant Visualization Support in theDeep Lake App** Deep Lake\ndatasets are instantly visualized with bounding boxes, masks, annotations,\netc. in Deep Lake Visualizer (see below).\n\n## \ud83d\ude80 How to install Deep Lake\n\nDeep Lake can be installed using pip:\n\n    \n    \n    pip install deeplake\n\n### To access all of Deep Lake's features, please register in the Deep Lake\nApp.",
        "node_58": "An additional\ndistinction is that DVC primarily uses a command-line interface, whereas Deep\nLake is a Python package. Lastly, Deep Lake offers an API to easily connect\ndatasets to ML frameworks and other common ML tools and enables instant\ndataset visualization through Activeloop's visualization tool.\n\n**Deep Lake vs MosaicML MDS format**\n\n  * **Data Storage Format:** Deep Lake operates on a columnar storage format, whereas MDS utilizes a row-wise storage approach. This fundamentally impacts how data is read, written, and organized in each system.\n  * **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor. This feature eliminates the need for additional compressions like zstd, which would otherwise demand more CPU cycles for decompressing on top of formats like jpeg.\n  * **Shuffling:** MDS currently offers more advanced shuffling strategies.\n  * **Version Control & Visualization Support:** A notable feature of Deep Lake is its native version control and in-browser data visualization, a feature not present for MosaicML data format. This can provide significant advantages in managing, understanding, and tracking different versions of the data.\n\n**Deep Lake vs TensorFlow Datasets (TFDS)**\n\nDeep Lake and TFDS seamlessly connect popular datasets to ML frameworks. Deep\nLake datasets are compatible with both PyTorch and TensorFlow, whereas TFDS\nare only compatible with TensorFlow. A key difference between Deep Lake and\nTFDS is that Deep Lake datasets are designed for streaming from the cloud,\nwhereas TFDS must be downloaded locally prior to use.",
        "node_557": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_163": "* `ColBERTConfig` provides configuration options for the ColBERT model, such as directory paths and other settings.\n\n  2. **Initializing the Checkpoint** : \n\n     * `\"colbert-ir/colbertv2.0\"` specifies the name of the pretrained checkpoint to load. This could be a path to a local model file or a remote model identifier, depending on your setup.\n\n     * `ColBERTConfig(root=\"experiments\")` sets the root directory where model-related experiments will be saved or accessed. This is useful for organizing logs, results, and intermediate files.\n\n  3. **Purpose** : \n\n     * The `ckpt` object now contains the pretrained ColBERT model and its configuration, ready to be used for tasks like ranking or embedding documents in information retrieval pipelines.\n\nThis step sets up the foundation for using ColBERT's capabilities in semantic\nsearch and ranking tasks efficiently.\n\n    \n    \n    from colbert.modeling.checkpoint import Checkpoint\n    from colbert.infra import ColBERTConfig\n    \n    ckpt = Checkpoint(\n        \"colbert-ir/colbertv2.0\", colbert_config=ColBERTConfig(root=\"experiments\")\n    )\n    \n\nIn this example, we copy, structure, and process a **medical dataset** to\ngenerate embeddings for text documents using a pretrained ColBERT model.\n\n  1. **Dataset Copy and Setup** : \n\n     * The `deeplake.copy()` function duplicates the `medical_dataset` from the Activeloop repository into your organization's workspace.\n\n     * `deeplake.open()` then opens the dataset for modifications, allowing us to add or manipulate columns.\n\n  2. **Adding an Embedding Column** : \n\n     * A new column named `embedding` is added to the dataset with the data type `types.Array(types.Float32(), dimensions=2)`, preparing it to store 2D embeddings generated from the medical text.",
        "node_322": "This will prevent accidental modifications to the\ndataset and will improve the performance of the data access.\n\n### Prefer batch access instead of row by row access\u00b6\n\nIf you need to iterate over the dataset or specific column, prefer using\nbatches instead of row by row access.\n\n    \n    \n    # Process all columns with batches. Fast approach.\n    batch_size = 500\n    for batch in ds.batches(batch_size):\n        print(batch[\"column1\"])\n    \n    # Process single column with batches. Fast approach.\n    column = ds[\"column1\"]\n    for i in range(0, len(column), batch_size):\n        print(column[i:i+batch_size])\n    \n    # Process all columns row by row. Slower than batch access.\n    for row in ds:\n        print(row[\"column1\"])\n    \n    # Process single column row by row. Slower than batch access.\n    for i in range(len(column)):\n        print(column[i])\n    \n\n### Use `query` for complex data filtering and search\u00b6\n\nDeep Lake supports SQL-like queries to filter and search the data. If you need\nto filter the data based on multiple columns or complex conditions, prefer\nusing the deeplake.DatasetView.query or deeplake.query method, instead of\ndoing manual iteration and filtering.\n\n### Avoid accessing the data of the whole column\u00b6\n\nThe column data can be accessed directly by `ds[\"column_name\"][:]`. For the\nlarge datasets this can lead to memory issues. Prefer divide the data into\nbatches and process them separately.\n\n### Consider using async data access\u00b6\n\nDeep Lake supports async data access and query. If your workflow allows async\nprocessing and benefits from that, consider using async data access. Please\nrefer to the Async Data Loader guide for the details.\n\n## Storage and Data Management\u00b6\n\n### Understand the storage differences\u00b6\n\nDeep Lake supports multiple storage backends, which are differentiated by url\nschema.\n\n  * In memory datasets: `mem://dataset_id`. These datasets are stored in memory and are not persisted. They are useful for temporary data storage and testing.\n  * Local datasets: `file://path/to/dataset`. These datasets are stored on the local disk.",
        "node_497": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_37": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake? \n\n# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.",
        "node_296": "This timestamp is not guaranteed to be accurate, and\ndeeplake.Version.timestamp should generally be used instead.\n\n#####  `` id `property` \u00b6\n\n    \n    \n    id: str\n    \n\nThe unique version identifier\n\n#####  `` message `property` \u00b6\n\n    \n    \n    message: str | None\n    \n\nThe description of the version provided at commit time.\n\n#####  `` open \u00b6\n\n    \n    \n    open() -> ReadOnlyDataset\n    \n\nFetches the dataset corresponding to the version\n\n#####  `` timestamp `property` \u00b6\n\n    \n    \n    timestamp: datetime\n    \n\nThe version timestamp.\n\nThis is based on the storage provider's clock, and so generally more accurate\nthan deeplake.Version.client_timestamp.\n\n    \n    \n    # Get current version\n    version_id = ds.version\n    \n    # Access specific version\n    version = ds.history[version_id]\n    print(f\"Version: {version.id}\")\n    print(f\"Message: {version.message}\")\n    print(f\"Timestamp: {version.timestamp}\")\n    \n    # Open dataset at specific version\n    old_ds = version.open()\n    \n\n## History\u00b6\n\n####  `` deeplake.History \u00b6\n\nThe version history of a deeplake.Dataset.\n\n#####  `` __getitem__ \u00b6\n\n    \n    \n    __getitem__(offset: int) -> Version\n    \n    \n    \n    __getitem__(version: str) -> Version\n    \n    \n    \n    __getitem__(input: int | str) -> Version\n    \n\n#####  `` __iter__ \u00b6\n\n    \n    \n    __iter__() -> Iterator[Version]\n    \n\nIterate over the history, starting at the initial version\n\n#####  `` __len__ \u00b6\n\n    \n    \n    __len__() -> int\n    \n\nThe number of versions within the history\n\n    \n    \n    # View all versions\n    for version in ds.history:\n        print(f\"Version {version.id}: {version.message}\")\n        print(f\"Created: {version.timestamp}\")\n    \n    # Get specific version\n    version = ds.history[version_id]\n    \n    # Get version by index\n    first_version = ds.history[0]\n    latest_version = ds.history[-1]\n    \n\n## Branching\u00b6\n\n### Branch\u00b6\n\n####  `` deeplake.Branch \u00b6\n\nDescribes a branch within the dataset.\n\nBranches are created using deeplake.Dataset.branch.",
        "node_406": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_752": "Running the following code will create a Deep Lake\ndataset inside of the `./animals_dl` folder.\n\nIn [58]:\n\nCopied!\n\n    \n    \n    import deeplake\n    import numpy as np\n    import os\n    \n    ds = deeplake.create('./animals_dl') # Creates the dataset\n    \n\nimport deeplake import numpy as np import os ds =\ndeeplake.create('./animals_dl') # Creates the dataset\n\nNext, let's inspect the folder structure for the source dataset './animals' to\nfind the class names and the files that need to be uploaded to the Deep Lake\ndataset.\n\nIn [59]:\n\nCopied!\n\n    \n    \n    # Find the class_names and list of files that need to be uploaded\n    dataset_folder = '/Users/istranic/ActiveloopCode/Datasets/animals'\n    \n    # Find the subfolders, but filter additional files like DS_Store that are added on Mac machines.\n    class_names = [item for item in os.listdir(dataset_folder) if os.path.isdir(os.path.join(dataset_folder, item))]\n    \n    files_list = []\n    for dirpath, dirnames, filenames in os.walk(dataset_folder):\n        for filename in filenames:\n            files_list.append(os.path.join(dirpath, filename))\n    \n\n# Find the class_names and list of files that need to be uploaded\ndataset_folder = '/Users/istranic/ActiveloopCode/Datasets/animals' # Find the\nsubfolders, but filter additional files like DS_Store that are added on Mac\nmachines. class_names = [item for item in os.listdir(dataset_folder) if\nos.path.isdir(os.path.join(dataset_folder, item))] files_list = [] for\ndirpath, dirnames, filenames in os.walk(dataset_folder): for filename in\nfilenames: files_list.append(os.path.join(dirpath, filename))\n\nNext, let's **create the dataset columns and upload data**.\n\nIn [ ]:\n\nCopied!",
        "node_131": "We then execute both queries, storing vector results in `vs_results` and BM25\nresults in `bm25_results`. This allows us to compare results from both search\nmethods.\n\n    \n    \n    tql_vs = f\"\"\"\n        SELECT *, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        )\n        ORDER BY cosine_similarity(embedding, ARRAY[{embedding_string}]) DESC \n        LIMIT 5\n    \"\"\"\n    \n    tql_bm25 = f\"\"\"\n        SELECT *, BM25_SIMILARITY(restaurant_review, '{query}') as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        ) \n        ORDER BY BM25_SIMILARITY(restaurant_review, '{query}') DESC \n        LIMIT 5\n    \"\"\"\n    \n    vs_results = vector_search.query(tql_vs)\n    bm25_results = vector_search.query(tql_bm25)\n    print(vs_results)\n    print(bm25_results)\n    \n\nOutput:\n\n    \n    \n    Dataset(columns=(embedding,restaurant_name,restaurant_review,owner_answer,row_id,score), length=5)\n    Dataset(columns=(embedding,restaurant_name,restaurant_review,owner_answer,row_id,score), length=5)\n    \n\n### Show the scores\u00b6\n\n    \n    \n    for el_vs in vs_results:\n        print(f\"vector search score: {el_vs['score']}\")\n    \n    for el_bm25 in bm25_results:\n        print(f\"bm25 score: {el_bm25['score']}\")\n    \n\nOutput:\n\n    \n    \n    vector search score: 0.5322654247283936\n    vector search score: 0.46281781792640686\n    vector search score: 0.4580579102039337\n    vector search score: 0.45585304498672485\n    vector search score: 0.4528498649597168\n    bm25 score: 13.076177597045898\n    bm25 score: 11.206666946411133\n    bm25 score: 11.",
        "node_115": "After appending the data,\n`ds.commit()` saves the changes permanently to the dataset, ensuring all new\nentries are stored and ready for further processing.\n\n    \n    \n    ds.append({\n        \"restaurant_name\": restaurant_name,\n        \"restaurant_review\": restaurant_review,\n        \"owner_answer\": owner_answer\n    })\n    ds.commit()\n    print(ds)\n    \n\nOutput:\n\n    \n    \n    Dataset(columns=(restaurant_name,restaurant_review,owner_answer), length=18625)\n    \n\n### Search for the restaurant using a specific word\u00b6\n\nWe define a search query to find any entries in the dataset `ds` where the\nword `\"tapas\"` appears in the `restaurant_review` column. The command\n`ds.query()` runs a TQL query with `SELECT *`, which retrieves all entries\nthat match the condition `CONTAINS(restaurant_review, '{word}')`. This search\nfilters the dataset to show only records containing the specified word\n(`tapas`) in their reviews. The results are saved in the variable `view`.\n\nDeep Lake offers a high-performance SQL-based query engine for data analysis\ncalled `TQL` (Tensor Query Language). You can find the official documentation\nhere.\n\n    \n    \n    word = 'burritos'\n    view = ds.query(f\"\"\"\n        SELECT * \n        WHERE CONTAINS(restaurant_review, '{word}')\n        LIMIT 4\n    \"\"\")\n    print(view)\n    \n\nOutput:\n\n    \n    \n    Dataset(columns=(restaurant_name,restaurant_review,owner_answer), length=4)\n    \n\n### Show the results\u00b6\n\n    \n    \n    for row in view:\n        print(f\"Restaurant name: {row['restaurant_name']} \\nReview: {row['restaurant_review']}\")\n    \n\nOutput:\n\n    \n    \n    Restaurant name: Los Amigos\n    Review: Best Burritos i have ever tried!!!!! Wolderful!!!\n    Restaurant name: Los Amigos\n    Review: Really good breakfast burrito, and just burritos in general\n    Restaurant name: Los Amigos\n    Review: Ordered two of their veggie burritos, nothing crazy just added extra cheese and sour cream.",
        "node_130": "The introduction of a Large Language Model\n(LLM) allows the system to generate text-based answers, delivering direct\nresponses instead of simply listing relevant documents.\n\nWe open the `vector_search` dataset to perform a hybrid search. First, we\ndefine a query `\"Let's grab a drink\"` and generate its embedding using\n`embedding_function(query)[0]`. We then convert this embedding into a comma-\nseparated string `embedding_string`, preparing it for use in combined text and\nvector-based searches.\n\n    \n    \n    vector_search = deeplake.open(f\"al://{org_id}/{dataset_name_vs}\")\n    \n\n### Search for the correct restaurant using a specific sentence\u00b6\n\n    \n    \n    query = \"I feel like a drink\"\n    embed_query = embedding_function(query)[0]\n    embedding_string = \",\".join(str(c) for c in embed_query)\n    \n\nWe create two queries:\n\n  1. **Vector Search** (`tql_vs`): Calculates cosine similarity with `embedding_string` and returns the top 5 matches by score.\n\n  2. **BM25 Search** (`tql_bm25`): Ranks `restaurant_review` by BM25 similarity to `query`, also limited to the top 5.\n\nWe then execute both queries, storing vector results in `vs_results` and BM25\nresults in `bm25_results`. This allows us to compare results from both search\nmethods.\n\n    \n    \n    tql_vs = f\"\"\"\n        SELECT *, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        )\n        ORDER BY cosine_similarity(embedding, ARRAY[{embedding_string}]) DESC \n        LIMIT 5\n    \"\"\"\n    \n    tql_bm25 = f\"\"\"\n        SELECT *, BM25_SIMILARITY(restaurant_review, '{query}') as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        ) \n        ORDER BY BM25_SIMILARITY(restaurant_review, '{query}') DESC \n        LIMIT 5\n    \"\"\"\n    \n    vs_results = vector_search.query(tql_vs)\n    bm25_results = vector_search.",
        "node_563": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_592": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\n\ud83c\udf0a Deep Lake: Multi-Modal AI Database\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Key Features \n    * \ud83d\udd0d Vector Search & Semantic Operations \n    * \ud83d\ude80 Optimized for Machine Learning \n    * \u2601\ufe0f Cloud-Native Architecture \n  * Quick Installation \n  * Basic Usage \n  * Common Use Cases \n    * Deep Learning Training \n    * RAG Applications \n    * Computer Vision \n  * Next Steps \n  * Resources \n  * Why Deep Lake?",
        "node_157": "The dataset includes\nan `embedding` column for 512-dimensional image embeddings, a\n`restaurant_name` column for names, and an `image` column for storing images\nin UInt8 format. After defining the structure, `vector_search_images.commit()`\nsaves it, making the dataset ready for storing data for multi-modal search\ntasks with images and metadata.\n\n    \n    \n    import deeplake\n    scraped_data = deeplake.open_read_only(\"al://activeloop/restaurant_dataset_complete\")\n    \n\nThis code extracts restaurant details from `scraped_data` into separate lists:\n\n  1. **Initialize Lists** : `restaurant_name` and `images` are initialized to store respective data for each restaurant.\n\n  2. **Populate Lists** : For each entry (`el`) in `scraped_data`, the code appends: \n\n     * `el['restaurant_name']` to `restaurant_name`,\n     * `el['images']['urls']` to `images`.\n\nAfter running, each list holds a specific field from all restaurants, ready\nfor further processing.\n\n    \n    \n    restaurant_name = []\n    images = []\n    for el in scraped_data:\n        restaurant_name.append(el['restaurant_name'])\n        images.append(el['images']['urls'])\n    \n    \n    \n    image_dataset_name = \"restaurant_dataset_with_images\"\n    vector_search_images = deeplake.create(f\"al://{org_id}/{image_dataset_name}\")\n    \n    vector_search_images.add_column(name=\"embedding\", dtype=types.Embedding(512))\n    vector_search_images.add_column(name=\"restaurant_name\", dtype=types.Text())\n    vector_search_images.add_column(name=\"image\", dtype=types.Image(dtype=types.UInt8()))\n    \n    vector_search_images.commit()\n    \n\n### Convert the URLs into images\u00b6\n\nWe retrieve images for each restaurant from URLs in scraped_data and store\nthem in restaurants_images. For each restaurant, we extract image URLs,\nrequest each URL, and filter for successful responses (status code 200). These\nresponses are then converted to PIL images and added to restaurants_images as\nlists of images, with each sublist containing the images for one restaurant.",
        "node_17": "**Native Compression with Lazy NumPy-like Indexing** Store images, audio, and\nvideos in their native compression. Slice, index, iterate, and interact with\nyour data like a collection of NumPy arrays in your system's memory. Deep Lake\nlazily loads data only when needed, e.g., when training a model or running\nqueries.  **Dataloaders for Popular Deep Learning Frameworks** Deep Lake comes\nwith built-in dataloaders for Pytorch and TensorFlow. Train your model with a\nfew lines of code - we even take care of dataset shuffling. :)  **Integrations\nwith Powerful Tools** Deep Lake has integrations with Langchain and LLamaIndex\nas a vector store for LLM apps, Weights & Biases for data lineage during model\ntraining, MMDetection for training object detection models, and MMSegmentation\nfor training semantic segmentation models.  **100+ most-popular image, video,\nand audio datasets available in seconds** Deep Lake community has uploaded\n100+ image, video and audio datasets like MNIST, COCO, ImageNet, CIFAR, GTZAN\nand others.  **Instant Visualization Support in theDeep Lake App** Deep Lake\ndatasets are instantly visualized with bounding boxes, masks, annotations,\netc. in Deep Lake Visualizer (see below).\n\n## \ud83d\ude80 How to install Deep Lake\n\nDeep Lake can be installed using pip:\n\n    \n    \n    pip install deeplake\n\n### To access all of Deep Lake's features, please register in the Deep Lake\nApp.",
        "node_82": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.",
        "node_647": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_214": "* Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM  Segmentation with MM  Table of contents \n        * Integration Interface \n          * Example Configuration with Deep Lake \n        * Prerequisites \n        * Setup \n        * Configuration \n        * Training \n        * Deep Lake Integration Benefits \n        * Monitoring Training \n        * Inference \n          * Key Integration Parameters \n        * Common Issues and Solutions \n          * Custom Loss Functions \n          * Multiple Optimization Strategies \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Integration Interface \n    * Example Configuration with Deep Lake \n  * Prerequisites \n  * Setup \n  * Configuration \n  * Training \n  * Deep Lake Integration Benefits \n  * Monitoring Training \n  * Inference \n    * Key Integration Parameters \n  * Common Issues and Solutions \n    * Custom Loss Functions \n    * Multiple Optimization Strategies \n\n# Semantic Segmentation with Deep",
        "node_618": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_164": "1. **Dataset Copy and Setup** : \n\n     * The `deeplake.copy()` function duplicates the `medical_dataset` from the Activeloop repository into your organization's workspace.\n\n     * `deeplake.open()` then opens the dataset for modifications, allowing us to add or manipulate columns.\n\n  2. **Adding an Embedding Column** : \n\n     * A new column named `embedding` is added to the dataset with the data type `types.Array(types.Float32(), dimensions=2)`, preparing it to store 2D embeddings generated from the medical text.\n\n    \n    \n    deeplake.copy(f\"al://activeloop/medical_dataset\", f\"al://{org_id}/medical_dataset\")\n    \n    \n    \n    medical_dataset = deeplake.open(f\"al://{org_id}/medical_dataset\")\n    medical_dataset.summary()\n    \n\nOutput:\n\n    \n    \n    Dataset(columns=(text,embedding), length=19719)\n    +---------+---------------------------------------+\n    | column  |                 type                  |\n    +---------+---------------------------------------+\n    |  text   |                 text                  |\n    +---------+---------------------------------------+\n    |embedding|array(dtype=float32, shape=[None,None])|\n    +---------+---------------------------------------+\n    \n    \n    \n    medical_dataset.add_column(name=\"embedding\", dtype=types.Array(types.Float32(),dimensions=2))\n    medical_dataset.commit()\n    \n\n  1. **Text Extraction** : \n\n     * The text data from the medical dataset is extracted into a list (`medical_text`) by iterating over the dataset and pulling the `text` field for each entry.\n  2. **Batch Embedding Generation** : \n\n     * The text data is processed in batches of 1,000 entries using the ColBERT model (`ckpt.docFromText`), which generates embeddings for each batch.\n\n     * The embeddings are appended to a list (`all_vectors`) for later use.\n\n  3. **Efficient Processing** :\n\n     * Batching ensures efficient processing, especially when dealing with large datasets, as it prevents memory overload and speeds up embedding generation.",
        "node_613": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_505": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_84": "Most Deep Lake services run\non the client, and our browser App or Python API directly read/write data from\nobject storage.\n\nDeep Lake Managed credentials should be set up for granting the client access\nto cloud storage. Managed Credentials use IAM Policies or Federated\nCredentials on Activeloop's backend to generate temporary credentials that are\nused by the client do access the data.\n\n## Default Storage\u00b6\n\nDefault storage enables you to map the Deep Lake path\n`al://org_id/dataset_name` to a cloud path of your choice. Subsequently, all\ndatasets created using the Deep Lake path will be stored at the user-\nspecified, and they can be accessed using API tokens and managed credentials\nfrom Deep Lake. By default, the default storage is set as Activeloop Storage,\nand you may change it using the UI below.\n\nNote\n\nIn order to visualize data in the Deep Lake browser application, it is\nnecessary to enable CORS in the bucket containing any source data.\n\n## Connecting Deep Lake Dataset in your Cloud to the Deep Lake to App\u00b6\n\nIf you do not set the Default Storage as your own cloud, Datasets in user's\nclouds can be connected to the Deep Lake App using the Python API below. Once\na dataset is connected to Deep Lake, it is assigned a Deep Lake path\n`al://org_id/dataset_name`, and it can be accessed using API tokens and\nmanaged credentials from Deep Lake, without continuously having to specify\ncloud credentials.\n\n#### Connecting Datasets in the Python API\u00b6\n\n    \n    \n    # Use deeplake.connect to connect a dataset in your cloud to the Deep Lake App\n    # Managed Credentials (creds_key) for accessing the data \n    # (See Managed Credentials above)\n    ds = deeplake.create('s3://my_bucket/dataset_name',\n    creds={'creds_key': 'managed_creds_key'}) # or deeplake.open\n    \n    # Specify your own path and dataset name for \n    # future access to the dataset.",
        "node_271": "Examples:\n\n    \n    \n    # Async batch load\n    future = column.get_async(slice(0, 32))\n    batch = future.result()\n    \n    # Using with async/await\n    async def load_batch():\n        batch = await column.get_async(slice(0, 32))\n        return batch\n    \n\n####  `` metadata `property` \u00b6\n\n    \n    \n    metadata: ReadOnlyMetadata\n    \n\nAccess the column's metadata. Useful for storing statistics, preprocessing\nparameters, or other information about the column data.\n\nReturns:\n\nName | Type | Description  \n---|---|---  \n`ReadOnlyMetadata` |  `ReadOnlyMetadata` |  A ReadOnlyMetadata object for reading metadata.  \n  \nExamples:\n\n    \n    \n    # Access preprocessing parameters\n    mean = column.metadata[\"mean\"]\n    std = column.metadata[\"std\"]\n    \n    # Check available metadata\n    for key in column.metadata.keys():\n        print(f\"{key}: {column.metadata[key]}\")\n    \n\n####  `` name `property` \u00b6\n\n    \n    \n    name: str\n    \n\nGet the name of the column.\n\nReturns:\n\nName | Type | Description  \n---|---|---  \n`str` |  `str` |  The column name.",
        "node_605": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_653": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_221": "abspath(cfg.work_dir))\n    \n        # train_segmentor\n        mmseg_deeplake.train_segmentor(\n            model,\n            cfg,\n            distributed=True,  # Set to True for multi-GPU training\n            validate=True, # Set to True if you have validation data\n        )\n    \n\n## Deep Lake Integration Benefits\u00b6\n\n  1. **Efficient Mask Handling** : Deep Lake efficiently stores and loads segmentation masks, which can be large and memory-intensive.\n\n  2. **Automatic Format Conversion** : Deep Lake handles conversion between different mask formats (binary, RLE, polygon) automatically.\n\n  3. **Smart Batching** : Deep Lake's dataloader handles variable-sized images and masks efficiently.\n\n  4. **Memory Management** : Data is loaded on-demand, preventing out-of-memory issues with large datasets.\n\n  5. **Distributed Training Support** : Seamless integration with MMSegmentation's distributed training.\n\n## Monitoring Training\u00b6\n\nMonitor training progress:\n\n    \n    \n    # Check latest log file\n    log_file = os.path.join(cfg.work_dir, 'latest.log')\n    if os.path.exists(log_file):\n        with open(log_file, 'r') as f:\n            print(f.read())\n    \n\n## Inference\u00b6\n\nAfter training, use the model for inference:\n\n    \n    \n    from mmseg.apis import inference_segmentor, init_segmentor\n    \n    # Load trained model\n    checkpoint = os.path.join(cfg.work_dir, 'latest.pth')\n    model = init_segmentor(config_path, checkpoint)\n    \n    # Load an image\n    img = 'path/to/test/image.jpg'\n    \n    # Run inference\n    result = inference_segmentor(model, img)\n    \n\n### Key Integration Parameters\u00b6\n\n  * **`data`** : Central to the MMSegmentation configuration file, it specifies the training and validation datasets, transformations, and paths.\n    * **`train`** : Contains dataset path, credentials, and transformations for training data.\n    * **`val`** : Contains dataset path, credentials, and transformations for validation data.\n    * **`pipeline`** : A list of transformations applied to the dataset.",
        "node_260": "Raises:\n\nType | Description  \n---|---  \n`ImportError` |  If TensorFlow is not installed  \n  \nExamples:\n\n    \n    \n    dl = ds.tensorflow().shuffle(500).batch(32)\n    for i_batch, sample_batched in enumerate(dl):\n         process_batch(sample_batched)\n    \n\n####  `` pytorch \u00b6\n\n    \n    \n    pytorch(transform: Callable[[Any], Any] = None)\n    \n\nReturns a PyTorch `torch.utils.data. Dataset` wrapper around this dataset.\n\nBy default, no transformations are applied and each row is returned as a\n`dict` with keys of column names.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`transform` |  `Callable[[Any], Any]` |  A custom function to apply to each sample before returning it |  `None`  \n  \nRaises:\n\nType | Description  \n---|---  \n`ImportError` |  If pytorch is not installed  \n  \nExamples:\n\n    \n    \n    from torch.utils.data import DataLoader\n    \n    dl = DataLoader(ds.pytorch(), batch_size=60,\n                                shuffle=True, num_workers=8)\n    for i_batch, sample_batched in enumerate(dl):\n        process_batch(sample_batched)\n    \n\n####  `` summary \u00b6\n\n    \n    \n    summary() -> None\n    \n\nPrints a summary of the dataset.\n\nExamples:\n\n    \n    \n    ds.summary()\n    \n\n## Class Comparison\u00b6\n\n### Dataset\u00b6\n\n  * Full read-write access\n  * Can create/modify columns\n  * Can append/update data\n  * Can commit changes\n  * Can create version tags\n  * Can push/pull changes\n\n    \n    \n    ds = deeplake.create(\"s3://bucket/dataset\")\n    # or\n    ds = deeplake.open(\"s3://bucket/dataset\")\n    \n    # Can modify\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"labels\", deeplake.types.ClassLabel(\"int32\"))\n    ds.add_column(\"confidence\", \"float32\")\n    ds[\"labels\"].metadata[\"class_names\"] = [\"cat\", \"dog\"]   \n    ds.",
        "node_301": "#####  `` rename \u00b6\n\n    \n    \n    rename(new_name: str) -> None\n    \n\nRenames the tag within the dataset\n\n#####  `` version `property` \u00b6\n\n    \n    \n    version: str\n    \n\nThe version that has been tagged\n\n    \n    \n    # Create tag\n    ds.tag(\"v1.0\")\n    \n    # Access tagged version\n    tag = ds.tags[\"v1.0\"]\n    print(f\"Tag: {tag.name}\")\n    print(f\"Version: {tag.version}\")\n    \n    # Open dataset at tag\n    tagged_ds = tag.open()\n    \n    # Rename tag\n    tag.rename(\"v1.0.0\")\n    \n    # Delete tag\n    tag.delete()\n    \n\n### Tags\u00b6\n\n####  `` deeplake.Tags \u00b6\n\nProvides access to the tags within a dataset.\n\nIt is returned by the deeplake.Dataset.tags property.",
        "node_167": "1. **Query Embedding** : The query is embedded with `ckpt.queryFromText` and converted into a format compatible with TQL queries.\n\n    \n    \n    query_vectors = ckpt.queryFromText([\"What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in the study?\"])[0]\n    query_vectors = query_vectors.tolist()\n    \n\n  1. **TQL Query Construction** : The `maxsim` function compares the query embedding to dataset embeddings, ranking results by similarity and limiting them to the top `n_res` matches.\n\n  2. **Query Execution** : `medical_dataset.query` retrieves the most relevant entries based on semantic similarity.\n\n    \n    \n    n_res = 3\n    q_substrs = [f\"ARRAY[{','.join(str(x) for x in sq)}]\" for sq in query_vectors]\n    q_str = f\"ARRAY[{','.join(q_substrs)}]\"\n    \n    # Construct a formatted TQL query\n    tql_colbert = f\"\"\"\n        SELECT *, maxsim(embedding, {q_str}) as score\n        ORDER BY maxsim(embedding, {q_str}) DESC \n        LIMIT {n_res}\n    \"\"\"\n    \n    # Execute the query and append the results\n    results = medical_dataset.query(tql_colbert)\n    \n\nHere are the results:\n\n    \n    \n    for res in results:\n        print(f\"Text: {res['text']}\")\n    \n\nOutput:\n\n    \n    \n    Text: In resistant dogs, myocardial infarction did not affect any measure of heart rate variability: 1) mean RR interval, 2) standard deviation of the mean RR interval, and 3) the coefficient of variance (standard deviation/RR interval). By contrast, after myocardial infarction, susceptible dogs showed significant decrease in all measures of heart rate variability. Before myocardial infarction, no differences were seen between susceptible and resistant dogs. However, 30 days after infarction, epidemiologic analysis of the coefficient of variance showed high sensitivity and specificity (88% and 80%, respectively), predicting susceptibility.",
        "node_187": "in a Q&A App \n  * Accessing the Low Level Deep Lake API (Advanced) \n  * SelfQueryRetriever with Deep Lake \n\n# Using Deep Lake as a Vector Store in LangChain\u00b6\n\n## How to Use Deep Lake as a Vector Store in LangChain\u00b6\n\nDeep Lake can be used as a VectorStore in LangChain for building Apps that\nrequire filtering and vector search. In this tutorial we will show how to\ncreate a Deep Lake Vector Store in LangChain and use it to build a Q&A App\nabout the Twitter OSS recommendation algorithm. This tutorial requires\ninstallation of:\n\nInstall the main libraries:\n\n    \n    \n    pip install --upgrade --quiet  langchain-openai langchain-deeplake tiktoken\n    \n\n## Downloading and Preprocessing the Data\u00b6\n\nFirst, let's import necessary packages and make sure the Activeloop and OpenAI\nkeys are in the environmental variables `ACTIVELOOP_TOKEN`, `OPENAI_API_KEY`.\n\n    \n    \n    import os\n    import getpass\n    from langchain_openai import OpenAIEmbeddings\n    from langchain_deeplake.vectorstores import DeeplakeVectorStore\n    from langchain_community.document_loaders import TextLoader\n    from langchain_text_splitters import CharacterTextSplitter\n    from langchain.chains import RetrievalQA\n    from langchain_openai import ChatOpenAI\n    \n\nNext, we set up environmental variables\n\n    \n    \n    if \"OPENAI_API_KEY\" not in os.environ:\n        os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n    \n    if \"ACTIVELOOP_TOKEN\" not in os.environ:\n        os.environ[\"ACTIVELOOP_TOKEN\"] = getpass.getpass(\"activeloop token:\")\n    \n\nNext, let's clone the Twitter OSS recommendation algorithm:\n\n    \n    \n    !git clone https://github.com/twitter/the-algorithm\n    \n\nNext, let's load all the files from the repo into a list:\n\n    \n    \n    repo_path = '/the-algorithm'\n    \n    docs = []\n    for dirpath, dirnames, filenames in os.walk(repo_path):\n        for file in filenames:\n            try:\n                loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n                docs.extend(loader.load_and_split())\n            except Exception as e:\n                print(e)\n                pass\n    \n\n## A note on chunking text files\u00b6\n\nText files are typically split into chunks before creating embeddings.",
        "node_205": "While this method is straightforward, it can become a\nbottleneck when working with large datasets with multiple tensors.\n\n## Asynchronous Data Fetching\u00b6\n\nThe asynchronous fetching method utilizes asyncio and threading to load data\nin parallel. This significantly improves loading times, especially for large\ndatasets with multiple tensors.\n\n    \n    \n    import deeplake\n    \n    import asyncio\n    from threading import Thread, Lock\n    from multiprocessing import Queue\n    \n    lock = Lock()\n    index = -1\n    def generate_data(ds: deeplake.Dataset):\n        total_count = len(ds)\n        global index\n        while True:\n            idx = 0\n            with lock:\n                index = (index + 1) % (total_count - 1)\n                idx = index\n            yield ds[idx]\n    \n    class AsyncImageDataset(torch.utils.data.IterableDataset):\n        def __init__(self, deeplake_ds: deeplake.Dataset, transform: Callable = None, max_queue_size: int = 1024):\n            self.ds = deeplake_ds\n            self.transform = transform\n            self.worked_started = False\n            self.data_generator = generate_data(self.ds)\n            self.q = Queue(maxsize=max_queue_size)\n    \n        async def run_async(self):\n            for item in self.data_generator:\n                data = await asyncio.gather(\n                    item.get_async(\"images\"),\n                    item.get_async(\"masks\")\n                )\n                self.q.put(data)\n    \n        def start_worker(self):\n            loop = asyncio.new_event_loop()\n    \n            for _ in range(128):\n                loop.create_task(self.run_async())\n    \n            def loop_in_thread(loop):\n                asyncio.set_event_loop(loop)\n                loop.run_forever()\n    \n            self.loop_thread = Thread(target=loop_in_thread, args=(loop,), daemon=True)\n            self.loop_thread.start()\n    \n            self.worked_started = True\n    \n        def __iter__(self):\n            while True:\n                if not self.worked_started:\n                    self.start_worker()\n    \n                # wait until some data is filled\n                while self.q.empty():\n                    pass\n    \n                image, mask = self.q.get()\n                if self.transform is not None:\n                    image, mask = self.transform((image, mask))\n    \n                yield image, mask\n    \n\nThe `AsyncImageDataset` utilizes Python\u2019s `asyncio` library to fetch images\nand masks concurrently from `deeplake.Dataset`, minimizing data loading times.",
        "node_361": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_83": "Skip to content\n\nYou're not viewing the latest version.  **Click here to go to latest.**\n\nSetting up Deep Lake in Your Cloud\n\nInitializing search\n\n  * Getting Started  Getting Started \n    * Quickstart \n    * Authentication \n    * Storage and Credentials  Storage and Credentials \n      * Storage and Credentials \n      * Storage Options \n      * Managed credentials  Managed credentials \n        * Overview  Overview  Table of contents \n          * Connecting Data From Your Cloud Using Deep Lake Managed Credentials \n          * Default Storage \n          * Connecting Deep Lake Dataset in your Cloud to the Deep Lake to App \n          * Using Manage Credentials with Linked Tensors \n          * Next Steps \n        * AWS  AWS \n          * Enabling CORS in S3 \n          * Provisioning Role-Based Access \n        * Azure  Azure \n          * Enabling CORS in Azure \n          * Provisioning Federated Credentials \n          * Azure Workload Identities \n        * GCP  GCP \n          * Enabling CORS in GCP \n          * Provisioning Federated Credentials \n  * User Guides  User Guides \n    * RAG \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    * Migrating to Deep Lake v4 \n    * Annotations  Annotations \n      * Labelbox \n  * API Reference  API Reference \n    * Dataset \n    * Column \n    * Types \n    * Query \n    * Version Control \n    * Schemas \n    * Metadata \n  * Advanced  Advanced \n    * Best Practices \n    * TQL Syntax \n    * Visualize Datasets \n    * Synchronize Datasets \n\nTable of contents\n\n  * Connecting Data From Your Cloud Using Deep Lake Managed Credentials \n  * Default Storage \n  * Connecting Deep Lake Dataset in your Cloud to the Deep Lake to App \n  * Using Manage Credentials with Linked Tensors \n  * Next Steps \n\n# Setting up Deep Lake in Your Cloud\u00b6\n\n## Connecting Data From Your Cloud Using Deep Lake Managed Credentials\u00b6\n\nYou can use Deep Lake while storing data in your own cloud (AWS, Azure, GCS)\nwithout data passing through Activeloop Servers.",
        "node_562": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_529": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_643": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_435": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_306": "This schema includes the following fields: \\- id (uint64): Unique identifier\nfor each entry. \\- chunk_index (uint16): Position of the text chunk within the\ndocument. \\- document_id (uint64): Unique identifier for the document the\nembedding came from. \\- date_created (uint64): Timestamp when the document was\nread. \\- text_chunk (text): The text of the shard. \\- embedding\n(dtype=float32, size=embedding_size): The embedding of the text.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`embedding_size` |  `int` |  int Size of the embeddings. |  _required_  \n`quantize` |  `bool` |  bool, optional If true, quantize the embeddings to slightly decrease accuracy while greatly increasing query speed. Default is False. |  `False`  \n  \nExamples:\n\nCreate a dataset with the standard schema:\n\n    \n    \n    ds = deeplake.create(\"tmp://\", schema=deeplake.schemas.TextEmbeddings(768))\n    \n\nCustomize the schema before creating the dataset:\n\n    \n    \n    schema = deeplake.schemas.TextEmbeddings(768)\n    schema[\"text_embed\"] = schema.pop(\"embedding\")\n    schema[\"author\"] = types.Text()\n    ds = deeplake.create(\"tmp://\", schema=schema)\n    \n\nAdd a new field to the schema:\n\n    \n    \n    schema = deeplake.schemas.TextEmbeddings(768)\n    schema[\"language\"] = types.Text()\n    ds = deeplake.create(\"tmp://\", schema=schema)\n    \n    \n    \n    # Create dataset with text embeddings schema\n    ds = deeplake.create(\"s3://bucket/dataset\",\n        schema=deeplake.schemas.TextEmbeddings(768))\n    \n    # Customize before creation\n    schema = deeplake.schemas.TextEmbeddings(768)\n    schema[\"text_embedding\"] = schema.pop(\"embedding\")\n    schema[\"source\"] = deeplake.types.Text()\n    ds = deeplake.create(\"s3://bucket/dataset\", schema=schema)\n    \n    # Add field to existing schema\n    schema = deeplake.schemas.TextEmbeddings(768)\n    schema[\"language\"] = deeplake.types.Text()\n    ds = deeplake.create(\"s3://bucket/dataset\", schema=schema)\n    \n\n## COCO Images Schema\u00b6\n\n###  `` deeplake.schemas.COCOImages \u00b6\n\n    \n    \n    COCOImages(\n        embedding_size: int,\n        quantize: bool = False,\n        objects: bool = True,\n        keypoints: bool = False,\n        stuffs: bool = False,\n    ) -> dict[str, DataType | str | Type]\n    \n\nA schema for storing COCO-based image data.",
        "node_245": "* If 'aws_access_key_id', 'aws_secret_access_key', 'aws_session_token' are present, these take precedence over credentials present in the environment or in credentials file. Currently only works with s3 paths.\n  * It supports 'aws_access_key_id', 'aws_secret_access_key', 'aws_session_token', 'endpoint_url', 'aws_region', 'profile_name' as keys.\n  * To use credentials managed in your Activeloop organization, use they key 'creds_key': 'managed_key_name'. This requires the org_id dataset argument to be set.\n  * If nothing is given is, credentials are fetched from the environment variables. This is also the case when creds is not passed for cloud datasets\n\n|  `None`  \n`token` |  `str` |  Activeloop token to authenticate user. |  `None`  \n  \nExamples:\n\n    \n    \n    ds = deeplake.open_read_only(\"directory_path\")\n    ds.summary()\n    \n    Example Output:\n    Dataset length: 5\n    Columns:\n      id       : int32\n      url      : text\n      embedding: embedding(768)\n    \n    ds = deeplake.open_read_only(\"file:///path/to/dataset\")\n    \n    ds = deeplake.open_read_only(\"s3://bucket/path/to/dataset\")\n    \n    ds = deeplake.open_read_only(\"azure://bucket/path/to/dataset\")\n    \n    ds = deeplake.open_read_only(\"gcs://bucket/path/to/dataset\")\n    \n    ds = deeplake.open_read_only(\"mem://in-memory\")\n    \n\n###  `` deeplake.like \u00b6\n\n    \n    \n    like(\n        src: DatasetView,\n        dest: str,\n        creds: dict[str, str] | None = None,\n        token: str | None = None,\n    ) -> Dataset\n    \n\nCreates a new dataset by copying the `source` dataset's structure to a new\nlocation.\n\nNote\n\nNo data is copied.\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`src` |  `DatasetView` |  The dataset to copy the structure from.",
        "node_495": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_374": "create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings, ARRAY[{text_vector}]) DESC\n        LIMIT 100\n    \"\"\")\n    \n\n## Common Use Cases\u00b6\n\n### Deep Learning Training\u00b6\n\n    \n    \n    # PyTorch integration\n    from torch.utils.data import DataLoader\n    \n    loader = DataLoader(ds.pytorch(), batch_size=32, shuffle=True)\n    for batch in loader:\n        images = batch[\"images\"]\n        labels = batch[\"labels\"]\n        # training code.\n    \n\n### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.",
        "node_481": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_10": "Skip to content\n\n## Navigation Menu\n\nToggle navigation\n\nSign in\n\n  * Product \n\n    * GitHub Copilot\n\nWrite better code with AI\n\n    * GitHub Advanced Security\n\nFind and fix vulnerabilities\n\n    * Actions\n\nAutomate any workflow\n\n    * Codespaces\n\nInstant dev environments\n\n    * Issues\n\nPlan and track work\n\n    * Code Review\n\nManage code changes\n\n    * Discussions\n\nCollaborate outside of code\n\n    * Code Search\n\nFind more, search less\n\nExplore\n\n    * All features \n    * Documentation \n    * GitHub Skills \n    * Blog \n\n  * Solutions \n\nBy company size\n\n    * Enterprises \n    * Small and medium teams \n    * Startups \n    * Nonprofits \n\nBy use case\n\n    * DevSecOps \n    * DevOps \n    * CI/CD \n    * View all use cases \n\nBy industry\n\n    * Healthcare \n    * Financial services \n    * Manufacturing \n    * Government \n    * View all industries \n\nView all solutions\n\n  * Resources \n\nTopics\n\n    * AI \n    * DevOps \n    * Security \n    * Software Development \n    * View all \n\nExplore\n\n    * Learning Pathways \n    * Events & Webinars \n    * Ebooks & Whitepapers \n    * Customer Stories \n    * Partners \n    * Executive Insights \n\n  * Open Source \n\n    * GitHub Sponsors\n\nFund open source developers\n\n    * The ReadME Project\n\nGitHub community articles\n\nRepositories\n\n    * Topics \n    * Trending \n    * Collections \n\n  * Enterprise \n\n    * Enterprise platform\n\nAI-powered developer platform\n\nAvailable add-ons\n\n    * GitHub Advanced Security\n\nEnterprise-grade security features\n\n    * Copilot for business\n\nEnterprise-grade AI features\n\n    * Premium Support\n\nEnterprise-grade 24/7 support\n\n  * Pricing\n\nSearch or jump to.",
        "node_487": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_483": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_729": "Each embedding from\nall_vectors is transformed using `.tolist()`, creating list_of_embeddings, and\n`len(list_of_embeddings)` confirms the total count matches the processed text\nentries.\n\n    \n    \n    medical_dataset[\"embedding\"][0:len(list_of_embeddings)] = list_of_embeddings\n    medical_dataset.commit()\n    \n\nThis code performs a semantic search using ColBERT embeddings, leveraging the\nMaxSim operator, executed directly in the cloud (as described in the `index-\non-the-lake` section), for efficient similarity computations.\n\n  1. **Query Embedding** : The query is embedded with `ckpt.queryFromText` and converted into a format compatible with TQL queries.\n\n    \n    \n    query_vectors = ckpt.queryFromText([\"What were the key risk factors for the development of posthemorrhagic/postoperative epilepsy in the study?\"])[0]\n    query_vectors = query_vectors.tolist()\n    \n\n  1. **TQL Query Construction** : The `maxsim` function compares the query embedding to dataset embeddings, ranking results by similarity and limiting them to the top `n_res` matches.\n\n  2. **Query Execution** : `medical_dataset.query` retrieves the most relevant entries based on semantic similarity.",
        "node_671": "* Search for the restaurant using a specific sentence \n      * 4) Explore Results with Hybrid Search \n        * Search for the correct restaurant using a specific sentence \n        * Show the scores \n        * Normalize the score \n        * Fusion method \n        * Show the results \n        * Let's run a search on a multiple dataset \n        * Comparison of Sync vs Async Query Performance \n      * 5) Integrating Image Embeddings for Multi-Modal Search \n        * Create the embedding function for images \n        * Create a new dataset to save the images \n        * Convert the URLs into images \n        * Search similar images \n        * Performing a similar image search based on a specific image \n        * Show similar images and the their respective restaurants \n      * 6) ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT \n      * 7) Discover Restaurants Using ColPali and the Late Interaction Mechanism \n        * Download the ColPali model \n        * Create a new dataset to store the ColPali embeddings \n        * Save the data in the dataset \n        * Chat with images \n        * Retrieve the most similar images \n        * VQA: Visual Question Answering \n    * VectorStore \n    * Deep Learning  Deep Learning \n      * Quickstart \n      * DataLoader \n      * Object Detection with MM \n      * Segmentation with MM \n    *",
        "node_240": "See `deeplake.schema` such as deeplake.schemas.TextEmbeddings for common starting schemas. |  `None`  \n  \nExamples:\n\n    \n    \n    # Create a dataset in your local filesystem:\n    ds = deeplake.create(\"directory_path\")\n    ds.add_column(\"id\", types.Int32())\n    ds.add_column(\"url\", types.Text())\n    ds.add_column(\"embedding\", types.Embedding(768))\n    ds.commit()\n    ds.summary()\n    \n    \n    \n    # Create dataset in your app.activeloop.ai organization:\n    ds = deeplake.create(\"al://organization_id/dataset_name\")\n    \n    # Create a dataset stored in your cloud using specified credentials:\n    ds = deeplake.create(\"s3://mybucket/my_dataset\",\n        creds = {\"aws_access_key_id\": id, \"aws_secret_access_key\": key})\n    \n    # Create dataset stored in your cloud using app.activeloop.ai managed credentials.\n    ds = deeplake.create(\"s3://mybucket/my_dataset\",\n        creds = {\"creds_key\": \"managed_creds_key\"}, org_id = \"my_org_id\")\n    \n    ds = deeplake.create(\"azure://bucket/path/to/dataset\")\n    \n    ds = deeplake.create(\"gcs://bucket/path/to/dataset\")\n    \n    ds = deeplake.create(\"mem://in-memory\")\n    \n\nRaises:\n\nType | Description  \n---|---  \n`LogExistsError` |  if a dataset already exists at the given URL  \n  \n###  `` deeplake.open \u00b6\n\n    \n    \n    open(\n        url: str,\n        creds: dict[str, str] | None = None,\n        token: str | None = None,\n    ) -> Dataset\n    \n\nOpens an existing dataset, potenitally for modifying its content.\n\nSee deeplake.open_read_only for opening the dataset in read only mode\n\nTo create a new dataset, see deeplake.create\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`url` |  `str` |  The URL of the dataset.",
        "node_57": "Deep Lake datasets can be visualized and version\ncontrolled. Weaviate is limited to light metadata on top of the embeddings and\nhas no visualization. Deep Lake also has a performant dataloader for fine-\ntuning your Large Language Models.\n\n**Deep Lake vs DVC**\n\nDeep Lake and DVC offer dataset version control similar to git for data, but\ntheir methods for storing data differ significantly. Deep Lake converts and\nstores data as chunked compressed arrays, which enables rapid streaming to ML\nmodels, whereas DVC operates on top of data stored in less efficient\ntraditional file structures. The Deep Lake format makes dataset versioning\nsignificantly easier compared to traditional file structures by DVC when\ndatasets are composed of many files (i.e., many images). An additional\ndistinction is that DVC primarily uses a command-line interface, whereas Deep\nLake is a Python package. Lastly, Deep Lake offers an API to easily connect\ndatasets to ML frameworks and other common ML tools and enables instant\ndataset visualization through Activeloop's visualization tool.\n\n**Deep Lake vs MosaicML MDS format**\n\n  * **Data Storage Format:** Deep Lake operates on a columnar storage format, whereas MDS utilizes a row-wise storage approach. This fundamentally impacts how data is read, written, and organized in each system.\n  * **Compression:** Deep Lake offers a more flexible compression scheme, allowing control over both chunk-level and sample-level compression for each column or tensor. This feature eliminates the need for additional compressions like zstd, which would otherwise demand more CPU cycles for decompressing on top of formats like jpeg.",
        "node_599": "### RAG Applications\u00b6\n\n    \n    \n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    # Store text and embeddings\n    ds.add_column(\"text\", deeplake.types.Text(index_type=deeplake.types.BM25))\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(1536))\n    \n    # Semantic search\n    results = ds.query(\"\"\"\n        SELECT text\n        ORDER BY BM25_SIMILARITY(text, 'machine learning') DESC\n        LIMIT 10\n    \"\"\")\n    \n\n### Computer Vision\u00b6\n\n    \n    \n    # Store images and annotations\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    ds.add_column(\"images\", deeplake.types.Image(sample_compression=\"jpeg\"))\n    ds.add_column(\"boxes\", deeplake.types.BoundingBox())\n    ds.add_column(\"masks\", deeplake.types.SegmentMask(sample_compression='lz4'))\n    \n    # Add data\n    ds.append({\n        \"images\": imgs,\n        \"boxes\": bboxes,\n        \"masks\": smasks\n    })\n    \n\n## Next Steps\u00b6\n\n  * Check out our Quickstart Guide for detailed setup\n  * Explore RAG Applications\n  * See Deep Learning Integration\n\n## Resources\u00b6\n\n  * GitHub Repository\n  * API Reference\n  * Community Support\n\n## Why Deep Lake?\u00b6\n\n  * **Performance** : Optimized for ML workloads with efficient data streaming\n  * **Scalability** : Handle billions of samples directly from the cloud\n  * **Flexibility** : Support for all major ML frameworks and cloud providers\n  * **Cost-Efficiency** : Smart storage management and compression\n  * **Developer Experience** : Simple, intuitive API with comprehensive features\n\nBack to top",
        "node_694": "We then execute both queries, storing vector results in `vs_results` and BM25\nresults in `bm25_results`. This allows us to compare results from both search\nmethods.\n\n    \n    \n    tql_vs = f\"\"\"\n        SELECT *, cosine_similarity(embedding, ARRAY[{embedding_string}]) as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        )\n        ORDER BY cosine_similarity(embedding, ARRAY[{embedding_string}]) DESC \n        LIMIT 5\n    \"\"\"\n    \n    tql_bm25 = f\"\"\"\n        SELECT *, BM25_SIMILARITY(restaurant_review, '{query}') as score\n        FROM (\n            SELECT *, ROW_NUMBER() AS row_id\n        ) \n        ORDER BY BM25_SIMILARITY(restaurant_review, '{query}') DESC \n        LIMIT 5\n    \"\"\"\n    \n    vs_results = vector_search.query(tql_vs)\n    bm25_results = vector_search.query(tql_bm25)\n    print(vs_results)\n    print(bm25_results)\n    \n\nOutput:\n\n    \n    \n    Dataset(columns=(embedding,restaurant_name,restaurant_review,owner_answer,row_id,score), length=5)\n    Dataset(columns=(embedding,restaurant_name,restaurant_review,owner_answer,row_id,score), length=5)\n    \n\n### Show the scores\u00b6\n\n    \n    \n    for el_vs in vs_results:\n        print(f\"vector search score: {el_vs['score']}\")\n    \n    for el_bm25 in bm25_results:\n        print(f\"bm25 score: {el_bm25['score']}\")\n    \n\nOutput:\n\n    \n    \n    vector search score: 0.5322654247283936\n    vector search score: 0.46281781792640686\n    vector search score: 0.4580579102039337\n    vector search score: 0.45585304498672485\n    vector search score: 0.4528498649597168\n    bm25 score: 13.076177597045898\n    bm25 score: 11.206666946411133\n    bm25 score: 11.",
        "node_34": "We\nwould like to thank William Silversmith @SeungLab for his awesome cloud-volume\ntool.\n\n## About\n\nDatabase for AI. Store Vectors, Images, Texts, Videos, etc. Use with\nLLMs/LangChain. Store, query, version, & visualize any AI data. Stream data in\nreal-time to PyTorch/TensorFlow.",
        "node_237": "* DatasetView \n  * Class Comparison \n    * Dataset \n    * ReadOnlyDataset \n    * DatasetView \n  * Examples \n    * Querying Data \n    * Data Access \n    * Async Operations \n\n# Dataset Classes\u00b6\n\nDeep Lake provides three dataset classes with different access levels:\n\nClass | Description  \n---|---  \nDataset | Full read-write access with all operations  \nReadOnlyDataset | Read-only access to prevent modifications  \nDatasetView | Read-only view of query results  \n  \n## Creation Methods\u00b6\n\n###  `` deeplake.create \u00b6\n\n    \n    \n    create(\n        url: str,\n        creds: dict[str, str] | None = None,\n        token: str | None = None,\n        schema: dict[str, DataType | str | Type] | None = None,\n    ) -> Dataset\n    \n\nCreates a new dataset at the given URL.\n\nTo open an existing dataset, use deeplake.open\n\nParameters:\n\nName | Type | Description | Default  \n---|---|---|---  \n`url` |  `str` |  The URL of the dataset. URLs can be specified using the following protocols:\n\n  * `file://path` local filesystem storage\n  * `al://org_id/dataset_name` A dataset on app.activeloop.ai\n  * `azure://bucket/path` or `az://bucket/path` Azure storage\n  * `gs://bucket/path` or `gcs://bucket/path` or `gcp://bucket/path` Google Cloud storage\n  * `s3://bucket/path` S3 storage\n  * `mem://name` In-memory storage that lasts the life of the process\n\nA URL without a protocol is assumed to be a file:// URL |  _required_  \n`creds` |  `(dict, str)` |  The string `ENV` or a dictionary containing credentials used to access the dataset at the path.",
        "node_746": "question = queries[0]\n    output_image = \"image.jpg\"\n    img = Image.fromarray(colpali_results[0][\"image\"][0])\n    img.save(output_image)\n    \n\nThe following code opens `\"image.jpg\"` in binary mode, encodes it to a base64\nstring, and passes it with `question` to the `generate_VQA` function, which\nreturns an answer based on the image.\n\n    \n    \n    import base64\n    \n    with open(output_image, \"rb\") as image_file:\n        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n    \n    answer = generate_VQA(base64_image, question)\n    print(answer)\n    \n\nOutput:\n\n    \n    \n    'As time approaches infinity, the voltage modeled by n^6 will eventually stabilize at the equilibrium potential for potassium (EK), which is represented at approximately -90 mV on the graph.'\n    \n\nWe've now gained a solid understanding of multi-modal data processing,\nadvanced retrieval techniques, and hybrid search methods using state-of-the-\nart models like ColPali. With these skills, you're equipped to tackle complex,\nreal-world applications that require deep insights from both text and image\ndata.\n\nKeep experimenting, stay curious, and continue building innovative\nsolutions\u2014this is just the beginning of what's possible in the field of AI-\ndriven search and information retrieval.\n\n**To learn more about Deep Lake v4, visit theofficial blog post and\ndocumentation.**\n\nBack to top",
        "node_297": "Branches are created using deeplake.Dataset.branch.\n\n#####  `` __hash__ `class-attribute` \u00b6\n\n    \n    \n    __hash__: None = None\n    \n\n#####  `` base `property` \u00b6\n\n    \n    \n    base: tuple[str, str] | None\n    \n\nThe base branch id and version\n\n#####  `` delete \u00b6\n\n    \n    \n    delete() -> None\n    \n\nDeletes the branch from the dataset\n\n#####  `` id `property` \u00b6\n\n    \n    \n    id: str\n    \n\nThe unique identifier of the branch\n\n#####  `` name `property` \u00b6\n\n    \n    \n    name: str\n    \n\nThe name of the branch\n\n#####  `` open \u00b6\n\n    \n    \n    open() -> Dataset\n    \n\nOpens corresponding branch of the dataset\n\n#####  `` rename \u00b6\n\n    \n    \n    rename(new_name: str) -> None\n    \n\nRenames the branch within the dataset\n\n#####  `` timestamp `property` \u00b6\n\n    \n    \n    timestamp: datetime\n    \n\nThe branch creation timestamp\n\n    \n    \n    # Create branch\n    ds.branch(\"Branch1\")\n    \n    # Access branch\n    branch = ds.branches[\"Branch1\"]\n    print(f\"Branch: {branch.name}\")\n    print(f\"Created: {branch.timestamp}\")\n    print(f\"Base: {branch.base}\")\n    \n    # Open dataset at tag\n    branch_ds = branch.open()\n    \n    # Rename branch\n    branch.rename(\"Other Branch\")\n    \n    # Delete branch\n    branch.delete()\n    \n\n### Branches\u00b6\n\n####  `` deeplake.Branches \u00b6\n\nProvides access to the branches within a dataset.\n\nIt is returned by the deeplake.Dataset.branches property.",
        "node_256": "####  `` version `property` \u00b6\n\n    \n    \n    version: str\n    \n\nThe currently checked out version of the dataset\n\n####  `` history `property` \u00b6\n\n    \n    \n    history: History\n    \n\nThis dataset's version history\n\n####  `` schema `property` \u00b6\n\n    \n    \n    schema: Schema\n    \n\nThe schema of the dataset.\n\n####  `` indexing_mode `instance-attribute` \u00b6\n\n    \n    \n    indexing_mode: IndexingMode\n    \n\nThe indexing mode of the dataset. This property can be set to change the\nindexing mode of the dataset for the current session, other sessions will not\nbe affected.\n\nExamples:\n\n    \n    \n    ds = deeplake.open(\"mem://ds_id\")\n    ds.indexing_mode = deeplake.IndexingMode.Automatic\n    ds.commit()\n    \n\n## ReadOnlyDataset Class\u00b6\n\nRead-only version of Dataset. Cannot modify data but provides access to all\ndata and metadata.\n\n###  `` deeplake.ReadOnlyDataset \u00b6\n\nBases: `DatasetView`\n\n####  `` query \u00b6\n\n    \n    \n    query(query: str) -> DatasetView\n    \n\nExecutes the given TQL query against the dataset and return the results as a\ndeeplake.DatasetView.\n\nExamples:\n\n    \n    \n    result = ds.query(\"select * where category == 'active'\")\n    for row in result:\n        print(\"Id is: \", row[\"id\"])\n    \n\n####  `` query_async \u00b6\n\n    \n    \n    query_async(query: str) -> Future\n    \n\nAsynchronously executes the given TQL query against the dataset and return a\nfuture that will resolve into deeplake.DatasetView.",
        "node_445": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_633": "# \ud83c\udf0a Deep Lake: Multi-Modal AI Database\u00b6\n\nDeep Lake is a database specifically designed for machine learning and AI\napplications, offering efficient data management, vector search capabilities,\nand seamless integration with popular ML frameworks.\n\n## Key Features\u00b6\n\n### \ud83d\udd0d Vector Search & Semantic Operations\u00b6\n\n  * High-performance similarity search for embeddings\n  * BM25-based semantic text search\n  * Support for building RAG applications\n  * Efficient indexing strategies for large-scale search\n\n### \ud83d\ude80 Optimized for Machine Learning\u00b6\n\n  * Native integration with PyTorch and TensorFlow\n  * Efficient batch processing for training\n  * Built-in support for common ML data types (images, embeddings, tensors)\n  * Automatic data streaming with smart caching\n\n### \u2601\ufe0f Cloud-Native Architecture\u00b6\n\n  * Native support for major cloud providers:\n    * Amazon S3\n    * Google Cloud Storage\n    * Azure Blob Storage\n  * Cost-efficient data management\n  * Data versioning and lineage tracking\n\n## Quick Installation\u00b6\n\n    \n    \n    pip install deeplake\n    \n\n## Basic Usage\u00b6\n\n    \n    \n    import deeplake\n    \n    # Create a dataset\n    ds = deeplake.create(\"s3://my-bucket/dataset\")  # or local path\n    \n    # Add data columns\n    ds.add_column(\"images\", deeplake.types.Image())\n    ds.add_column(\"embeddings\", deeplake.types.Embedding(768))\n    ds.add_column(\"labels\", deeplake.types.Text())\n    \n    # Add data\n    ds.append([{\n        \"images\": image_array,\n        \"embeddings\": embedding_vector,\n        \"labels\": \"cat\"\n    }])\n    \n    # Vector similarity search\n    text_vector = ','.join(str(x) for x in search_vector)\n    results = ds.query(f\"\"\"\n        SELECT *\n        ORDER BY COSINE_SIMILARITY(embeddings,",
        "node_720": "The dataset includes\nan `embedding` column for 512-dimensional image embeddings, a\n`restaurant_name` column for names, and an `image` column for storing images\nin UInt8 format. After defining the structure, `vector_search_images.commit()`\nsaves it, making the dataset ready for storing data for multi-modal search\ntasks with images and metadata.\n\n    \n    \n    import deeplake\n    scraped_data = deeplake.open_read_only(\"al://activeloop/restaurant_dataset_complete\")\n    \n\nThis code extracts restaurant details from `scraped_data` into separate lists:\n\n  1. **Initialize Lists** : `restaurant_name` and `images` are initialized to store respective data for each restaurant.\n\n  2. **Populate Lists** : For each entry (`el`) in `scraped_data`, the code appends: \n\n     * `el['restaurant_name']` to `restaurant_name`,\n     * `el['images']['urls']` to `images`.\n\nAfter running, each list holds a specific field from all restaurants, ready\nfor further processing.\n\n    \n    \n    restaurant_name = []\n    images = []\n    for el in scraped_data:\n        restaurant_name.append(el['restaurant_name'])\n        images.append(el['images']['urls'])\n    \n    \n    \n    image_dataset_name = \"restaurant_dataset_with_images\"\n    vector_search_images = deeplake.create(f\"al://{org_id}/{image_dataset_name}\")\n    \n    vector_search_images.add_column(name=\"embedding\", dtype=types.Embedding(512))\n    vector_search_images.add_column(name=\"restaurant_name\", dtype=types.Text())\n    vector_search_images.add_column(name=\"image\", dtype=types.Image(dtype=types.UInt8()))\n    \n    vector_search_images.commit()\n    \n\n### Convert the URLs into images\u00b6\n\nWe retrieve images for each restaurant from URLs in scraped_data and store\nthem in restaurants_images. For each restaurant, we extract image URLs,\nrequest each URL, and filter for successful responses (status code 200). These\nresponses are then converted to PIL images and added to restaurants_images as\nlists of images, with each sublist containing the images for one restaurant."
    },
    "relevant_docs": {
        "ff7267a0-e17a-4d8e-9b7f-413a1a7806e8": [
            "node_783"
        ],
        "6674535d-7323-4bca-8d35-7dfd16ddf286": [
            "node_604"
        ],
        "27444152-0ce2-475c-b97d-5913cc01ecec": [
            "node_556"
        ],
        "0961fab0-d6c8-454e-b3e9-1aa530c6ec2f": [
            "node_176"
        ],
        "f0ec27f9-7452-4ac6-afe3-311b65201bd3": [
            "node_436"
        ],
        "e27115d2-6ba7-471a-9f5c-633a932eb25f": [
            "node_253"
        ],
        "ee7252f7-6508-4f83-a34e-35dc393b8305": [
            "node_25"
        ],
        "f072e6d0-465a-458f-9e74-940c9adc23ed": [
            "node_63"
        ],
        "a4a77652-93c2-412d-a710-a401f50197fd": [
            "node_524"
        ],
        "63adba5a-c5d1-4faf-b643-924b67dff787": [
            "node_701"
        ],
        "ec94b0f5-53eb-4445-a62d-cebea13f52f8": [
            "node_234"
        ],
        "cc842c7e-dff5-4c97-95d0-130412211900": [
            "node_414"
        ],
        "da826b2c-60b8-4dbb-84e7-3aa32395d380": [
            "node_77"
        ],
        "1d7cbf3a-c381-449f-b876-a690bfa55af2": [
            "node_785"
        ],
        "57ec3e58-f259-4a9a-b15b-df74df56bd5a": [
            "node_42"
        ],
        "ff9270fa-7412-43db-a009-727074522d99": [
            "node_375"
        ],
        "2e3edd22-6ebe-471e-8735-e0b9036aeb05": [
            "node_403"
        ],
        "a0f9e2dd-99d9-4801-8027-f7d05ed08748": [
            "node_62"
        ],
        "30c423b1-eb09-41d3-8db8-502e3da2b043": [
            "node_766"
        ],
        "2a825624-3282-4d33-8c93-171c22991be5": [
            "node_58"
        ],
        "63f8815f-5b81-4c50-8dbf-ec7d8978b0f0": [
            "node_557"
        ],
        "4cb49d07-9722-4968-ab77-855b0cefc6fb": [
            "node_163"
        ],
        "7624e38c-94b4-4d67-974e-6d1bc03e34ce": [
            "node_322"
        ],
        "ec0ab26f-80a1-4a97-aefa-2e02e408e8f5": [
            "node_497"
        ],
        "aa16e6f8-d694-4796-845d-5cd120b0d20d": [
            "node_37"
        ],
        "ce733ec2-eaba-4264-937d-a25b88f12a2b": [
            "node_296"
        ],
        "69af123c-785d-490f-8f3a-35d0722fee74": [
            "node_406"
        ],
        "fce01963-73ff-4404-9042-94faa9f1f306": [
            "node_752"
        ],
        "112119cc-08b2-4fd6-8445-4a498b9ffd31": [
            "node_131"
        ],
        "f6a9bf06-3ede-4a9e-8244-01c28e2b6111": [
            "node_115"
        ],
        "b12a9464-62dd-42b5-be1a-f2eb628625bd": [
            "node_130"
        ],
        "ce38040b-9064-4e6b-970d-aada69d05154": [
            "node_563"
        ],
        "6ca9b4ac-2617-4794-b1a5-1e07d044ba1c": [
            "node_592"
        ],
        "ae61fd82-3ab3-475a-ae15-2c4c08bd5730": [
            "node_157"
        ],
        "be439e90-c1eb-46ab-bd59-46186c745a6f": [
            "node_17"
        ],
        "09236568-d5cb-4fbe-9ae5-9b6ba1d17ec8": [
            "node_82"
        ],
        "87d76774-7d61-4a92-bf18-0c43a0e699e9": [
            "node_647"
        ],
        "5b68ef3e-3e66-4376-880d-48e6f472d2dc": [
            "node_214"
        ],
        "5fa8b928-fe11-4f00-8408-e506606dd9e4": [
            "node_618"
        ],
        "f9518384-c84b-4fb3-9643-9384a69aa588": [
            "node_164"
        ],
        "8cd47418-b686-4bec-9a8a-fee06898f49d": [
            "node_613"
        ],
        "db48e8d4-67d3-4112-a671-8e4d2561d7ac": [
            "node_505"
        ],
        "6b6adb75-1201-4c20-96fe-b8a085b61910": [
            "node_84"
        ],
        "773c7d41-c514-418b-825d-0aaa0b6ab984": [
            "node_271"
        ],
        "da1e2c5e-424d-421f-9828-a5e6e7e32fbd": [
            "node_605"
        ],
        "87ce603d-ce54-478b-aed3-6e044561a247": [
            "node_653"
        ],
        "de666ccc-e8a9-42b1-9ef3-b73fd46fa530": [
            "node_221"
        ],
        "a7099122-df85-47d7-b83d-5fec4819d6ec": [
            "node_260"
        ],
        "d2d9181e-bfb6-4d94-b0bb-1a95554b1b6f": [
            "node_301"
        ],
        "24f39dad-c53b-4ff2-b78d-6ea2f3f899e8": [
            "node_167"
        ],
        "8293b1d5-658c-46f8-ac46-ffd5044dc262": [
            "node_187"
        ],
        "fdcc1d90-c16a-4bdd-91e9-803493465fa0": [
            "node_205"
        ],
        "ea5ad105-9896-4801-9288-0c3a454f4c47": [
            "node_361"
        ],
        "4401931d-eb27-4f07-9040-568363099508": [
            "node_83"
        ],
        "d868cffb-9d59-4af1-a86b-094d561fdb5e": [
            "node_562"
        ],
        "80fcdf86-7dca-4262-bc6a-f8ab29a54508": [
            "node_529"
        ],
        "3863282b-e7b4-4ecd-aa0d-73e8bbdae715": [
            "node_643"
        ],
        "2960ec79-13f5-436d-8a48-c7b5120efc12": [
            "node_435"
        ],
        "dc591afd-82b8-44d0-bd5a-008893cd7c0a": [
            "node_306"
        ],
        "048822fe-1910-4059-a15a-e8fdf15588ec": [
            "node_245"
        ],
        "2f2cf480-2e6b-4802-b797-1ed8ef38765a": [
            "node_495"
        ],
        "de4a69f2-73ca-4eb1-b99c-4a97285bb859": [
            "node_374"
        ],
        "cd5d69f7-e700-407c-a459-948c370a762f": [
            "node_481"
        ],
        "8a68c998-48fd-44bd-bfd2-33a4bf0c4daa": [
            "node_10"
        ],
        "0a92de03-b293-4f13-a274-a12fa66d6ccf": [
            "node_487"
        ],
        "98fc5f1e-5e7b-4f3a-9981-3cc0b54ce11e": [
            "node_483"
        ],
        "76b551a3-d724-4ba3-b430-5bde4481f774": [
            "node_729"
        ],
        "309f1c59-cf51-4d85-85c6-0c05d9dcf076": [
            "node_671"
        ],
        "e527b35f-3015-4a30-9555-cf54a6658cea": [
            "node_240"
        ],
        "54035737-f430-439f-824c-2960cbffc636": [
            "node_57"
        ],
        "934c5436-4026-4f76-bbf2-511f58fcc3d9": [
            "node_599"
        ],
        "307ffce4-3ac2-451d-af58-8b6fccb0dce2": [
            "node_694"
        ],
        "f3970fe2-c5e7-4a67-90fc-497a67442a04": [
            "node_34"
        ],
        "9205f8c2-fe3b-40fb-a810-8467fef62958": [
            "node_237"
        ],
        "b0495368-b39a-42ec-ad68-64b578073ae3": [
            "node_746"
        ],
        "6a8fba83-2507-4691-873d-9cb4c6622afc": [
            "node_297"
        ],
        "5d105cb2-d0c8-4308-bd74-c9d187cf38a3": [
            "node_256"
        ],
        "23fa1d2b-1541-40c2-91b9-23048dda4edd": [
            "node_445"
        ],
        "cd741ffe-ad32-441e-9382-3b4c86e72dd6": [
            "node_633"
        ],
        "a2dff3a9-6d5e-4657-9260-2af292d4f05b": [
            "node_720"
        ]
    },
    "mode": "text"
}
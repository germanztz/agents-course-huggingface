{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Agents in LlamaIndex\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "## Let's install the dependencies\n",
    "\n",
    "We will install the dependencies for this unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-index in /home/daimler/.local/lib/python3.11/site-packages (0.12.23)\n",
      "Requirement already satisfied: datasets in /home/daimler/.local/lib/python3.11/site-packages (3.3.2)\n",
      "Requirement already satisfied: llama-index-callbacks-arize-phoenix in /home/daimler/.local/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma in /home/daimler/.local/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: llama-index-embeddings-ollama in /home/daimler/.local/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: llama-index-llms-ollama in /home/daimler/.local/lib/python3.11/site-packages (0.5.3)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5.0,>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-cli<0.5.0,>=0.4.1 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.23 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.12.23.post2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4.0,>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.6.8)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.4.0,>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.3.25)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.4.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4.0,>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4.0,>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5.0,>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.4.6)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: filelock in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /home/daimler/.local/lib/python3.11/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (3.11.13)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in /home/daimler/.local/lib/python3.11/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: openinference-instrumentation-llama-index>=3.0.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-callbacks-arize-phoenix) (3.3.1)\n",
      "Requirement already satisfied: chromadb>=0.5.17 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-vector-stores-chroma) (0.6.3)\n",
      "Requirement already satisfied: ollama>=0.3.1 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-embeddings-ollama) (0.4.7)\n",
      "Requirement already satisfied: build>=1.0.3 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.10.6)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.19.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.15.2)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (32.0.1)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/daimler/.local/lib/python3.11/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/daimler/.local/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: openai>=1.14.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.66.3)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/daimler/.local/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.23->llama-index) (2.0.39)\n",
      "Requirement already satisfied: dataclasses-json in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (1.2.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (3.4.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (11.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (0.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-core<0.13.0,>=0.12.23->llama-index) (1.17.2)\n",
      "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.14)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/lib/python3/dist-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (5.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /home/daimler/.local/lib/python3.11/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.4.post1)\n",
      "Requirement already satisfied: click in /home/daimler/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/daimler/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/daimler/.local/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: openinference-instrumentation>=0.1.17 in /home/daimler/.local/lib/python3.11/site-packages (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix) (0.1.23)\n",
      "Requirement already satisfied: openinference-semantic-conventions>=0.1.9 in /home/daimler/.local/lib/python3.11/site-packages (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix) (0.1.14)\n",
      "Requirement already satisfied: opentelemetry-instrumentation in /home/daimler/.local/lib/python3.11/site-packages (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions in /home/daimler/.local/lib/python3.11/site-packages (from openinference-instrumentation-llama-index>=3.0.0->llama-index-callbacks-arize-phoenix) (0.52b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daimler/.local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daimler/.local/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/daimler/.local/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/daimler/.local/lib/python3.11/site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/lib/python3/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index) (2.5)\n",
      "Requirement already satisfied: pyproject_hooks in /home/daimler/.local/lib/python3.11/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /home/daimler/.local/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.46.1)\n",
      "Requirement already satisfied: anyio in /home/daimler/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/daimler/.local/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/daimler/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/daimler/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/daimler/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/daimler/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/daimler/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /home/daimler/.local/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.9)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.4 in /home/daimler/.local/lib/python3.11/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.5)\n",
      "Requirement already satisfied: coloredlogs in /home/daimler/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/daimler/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /home/daimler/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.3)\n",
      "Requirement already satisfied: sympy in /home/daimler/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.13.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/daimler/.local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /home/daimler/.local/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5.0,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.6.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.69.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.31.0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.31.0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.52b0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.52b0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.52b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/daimler/.local/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.52b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /usr/lib/python3/dist-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/daimler/.local/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/daimler/.local/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/daimler/.local/lib/python3.11/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/lib/python3/dist-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/daimler/.local/lib/python3.11/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.19.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/daimler/.local/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.23->llama-index) (3.1.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/daimler/.local/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.23->llama-index) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/daimler/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/daimler/.local/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.23->llama-index) (3.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/daimler/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/daimler/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/daimler/.local/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/daimler/.local/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/lib/python3/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/daimler/.local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/daimler/.local/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/daimler/.local/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U  \\\n",
    "    llama-index \\\n",
    "    datasets \\\n",
    "    llama-index-callbacks-arize-phoenix \\\n",
    "    llama-index-vector-stores-chroma \\\n",
    "    llama-index-embeddings-ollama \\\n",
    "    llama-index-llms-ollama \\\n",
    "    # llama-index-llms-huggingface-api \\\n",
    "    # llama-index==0.10.38 \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Initialising agents\n",
    "\n",
    "Let's start by initialising an agent. We will use the basic `AgentWorkflow` class to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream\n",
    "from llama_index.llms.ollama import Ollama \n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "# llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "llm = Ollama(model=\"myaniu/qwen2.5-1m:7b\")\n",
    "\n",
    "\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can run the agent and get the response and reasoning behind the tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  add {'a': 2, 'b': 2} => 4\n",
      "\n",
      "Called tool:  multiply {'a': 4, 'b': 2} => 8\n",
      "The result of (2 + 2) * 2 is 8."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='The result of (2 + 2) * 2 is 8.')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='add', tool_output=ToolOutput(content='4', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 2}, tool_id='multiply', tool_output=ToolOutput(content='8', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 2}}, raw_output=8, is_error=False), return_direct=False)], raw={'model': 'myaniu/qwen2.5-1m:7b', 'created_at': '2025-03-13T13:49:36.612066566Z', 'done': True, 'done_reason': 'stop', 'total_duration': 424664877, 'load_duration': 10738624, 'prompt_eval_count': 473, 'prompt_eval_duration': 16000000, 'eval_count': 17, 'eval_duration': 382000000, 'message': Message(role='assistant', content='The result of (2 + 2) * 2 is 8.', images=None, tool_calls=None), 'usage': {'prompt_tokens': 473, 'completion_tokens': 17, 'total_tokens': 490}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = agent.run(\"What is (2 + 2) * 2?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar fashion, we can pass state and context to the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text=\"You mentioned your name is Bob. Is there something specific you'd like to know or do related to that name or any numbers associated with it?\")]), tool_calls=[], raw={'model': 'myaniu/qwen2.5-1m:7b', 'created_at': '2025-03-13T13:49:37.802685571Z', 'done': True, 'done_reason': 'stop', 'total_duration': 723787947, 'load_duration': 14653674, 'prompt_eval_count': 439, 'prompt_eval_duration': 9000000, 'eval_count': 30, 'eval_duration': 688000000, 'message': Message(role='assistant', content=\"You mentioned your name is Bob. Is there something specific you'd like to know or do related to that name or any numbers associated with it?\", images=None, tool_calls=None), 'usage': {'prompt_tokens': 439, 'completion_tokens': 30, 'total_tokens': 469}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(\"My name is Bob.\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating RAG Agents with QueryEngineTools\n",
    "\n",
    "Let's now re-use the `QueryEngine` we defined in the [previous unit on tools](/tools.ipynb) and convert it into a `QueryEngineTool`. We will pass it to the `AgentWorkflow` class to create a RAG agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "# from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "# from llama_index.embeddings.huggingface_api import HuggingFaceInferenceAPIEmbedding\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Create a vector store\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Create a query engine\n",
    "# embed_model = HuggingFaceInferenceAPIEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "embed_model = OllamaEmbedding(model_name=\"qllama/bge-small-en-v1.5:f16\")\n",
    "\n",
    "# llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\")\n",
    "llm = Ollama(model=\"myaniu/qwen2.5-1m:7b\")\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"personas\",\n",
    "    description=\"descriptions for various types of personas\",\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# Create a RAG agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, we can once more get the response and reasoning behind the tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  personas {'input': 'science fiction'} => The provided context focuses on an anthropologist or cultural expert specializing in Cypriot culture. There is no indication or mention of any connection to science fiction within this context. Therefore, based on the given information, it's not possible to link the described person directly to science fiction topics.\n",
      "It appears that our database does not contain a persona specifically tailored for 'science fiction'. The provided description is related to an anthropologist specializing in Cypriot culture. If you're interested in personas or descriptions connected to science fiction, please provide more details so I can search accordingly. Alternatively, we could create a custom persona based on your requirements. Would you like to proceed with this option?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text=\"It appears that our database does not contain a persona specifically tailored for 'science fiction'. The provided description is related to an anthropologist specializing in Cypriot culture. If you're interested in personas or descriptions connected to science fiction, please provide more details so I can search accordingly. Alternatively, we could create a custom persona based on your requirements. Would you like to proceed with this option?\")]), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'science fiction'}, tool_id='personas', tool_output=ToolOutput(content=\"The provided context focuses on an anthropologist or cultural expert specializing in Cypriot culture. There is no indication or mention of any connection to science fiction within this context. Therefore, based on the given information, it's not possible to link the described person directly to science fiction topics.\", tool_name='personas', raw_input={'input': 'science fiction'}, raw_output=Response(response=\"The provided context focuses on an anthropologist or cultural expert specializing in Cypriot culture. There is no indication or mention of any connection to science fiction within this context. Therefore, based on the given information, it's not possible to link the described person directly to science fiction topics.\", source_nodes=[NodeWithScore(node=TextNode(id_='372496be-c985-453a-b534-bbbdbfdd02fa', embedding=None, metadata={'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='2fc1c32a-0584-4da3-bd4d-75a0ab5e6288', node_type='4', metadata={'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.8220602979104755e-38), NodeWithScore(node=TextNode(id_='b1b88e22-80c1-41ae-ba94-a54bfeafda72', embedding=None, metadata={'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='f404972e-6750-4523-99c2-30d3cd84854e', node_type='4', metadata={'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.8220602979104755e-38)], metadata={'372496be-c985-453a-b534-bbbdbfdd02fa': {'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}, 'b1b88e22-80c1-41ae-ba94-a54bfeafda72': {'file_path': '/home/daimler/workspaces/agents-course-huggingface/2.2-llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-03-11', 'last_modified_date': '2025-03-11'}}), is_error=False), return_direct=False)], raw={'model': 'myaniu/qwen2.5-1m:7b', 'created_at': '2025-03-13T13:49:43.005902129Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2012777684, 'load_duration': 17428281, 'prompt_eval_count': 262, 'prompt_eval_duration': 42000000, 'eval_count': 79, 'eval_duration': 1932000000, 'message': Message(role='assistant', content=\"It appears that our database does not contain a persona specifically tailored for 'science fiction'. The provided description is related to an anthropologist specializing in Cypriot culture. If you're interested in personas or descriptions connected to science fiction, please provide more details so I can search accordingly. Alternatively, we could create a custom persona based on your requirements. Would you like to proceed with this option?\", images=None, tool_calls=None), 'usage': {'prompt_tokens': 262, 'completion_tokens': 79, 'total_tokens': 341}}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = query_engine_agent.run(\n",
    "    \"Search the database for 'science fiction' and return some persona descriptions.\"\n",
    ")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating multi-agent systems\n",
    "\n",
    "We can also create multi-agent systems by passing multiple agents to the `AgentWorkflow` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentWorkflow,\n",
    "    ReActAgent,\n",
    ")\n",
    "\n",
    "\n",
    "# Define some tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# Create agent configs\n",
    "# NOTE: we can use FunctionAgent or ReActAgent here.\n",
    "# FunctionAgent works for LLMs with a function calling API.\n",
    "# ReActAgent works for any LLM.\n",
    "calculator_agent = ReActAgent(\n",
    "    name=\"calculator\",\n",
    "    description=\"Performs basic arithmetic operations\",\n",
    "    system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\",\n",
    "    tools=[add, subtract],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "query_agent = ReActAgent(\n",
    "    name=\"info_lookup\",\n",
    "    description=\"Looks up information about XYZ\",\n",
    "    system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\",\n",
    "    tools=[query_engine_tool],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Create and run the workflow\n",
    "agent = AgentWorkflow(agents=[calculator_agent, query_agent], root_agent=\"calculator\")\n",
    "\n",
    "# Run the system\n",
    "handler = agent.run(user_msg=\"Can you add 5 and 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to know the sum of 5 and 3. I will use the 'add' tool for this purpose.\n",
      "Action: add\n",
      "Action Input: {\"a\": 5, \"b\": 3}\n",
      "Called tool:  add {'a': 5, 'b': 3} => 8\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: The sum of 5 and 3 is 8."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={'tool_calls': []}, blocks=[TextBlock(block_type='text', text='The sum of 5 and 3 is 8.')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 5, 'b': 3}, tool_id='1b8923d3-ff1c-426e-8296-66a4709f88f1', tool_output=ToolOutput(content='8', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 5, 'b': 3}}, raw_output=8, is_error=False), return_direct=False)], raw={'model': 'myaniu/qwen2.5-1m:7b', 'created_at': '2025-03-13T13:49:45.561173895Z', 'done': True, 'done_reason': 'stop', 'total_duration': 852743669, 'load_duration': 11866284, 'prompt_eval_count': 791, 'prompt_eval_duration': 12000000, 'eval_count': 36, 'eval_duration': 815000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None), 'usage': {'prompt_tokens': 791, 'completion_tokens': 36, 'total_tokens': 827}}, current_agent_name='calculator')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

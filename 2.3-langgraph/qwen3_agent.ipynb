{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6e3d27",
   "metadata": {},
   "source": [
    "# Ollama Qwen3 Agent with LangGraph and LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e630781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_ollama in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.52 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain_ollama) (0.3.56)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.52->langchain_ollama) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (3.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (4.8.0)\n",
      "Requirement already satisfied: certifi in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/daimler/workspaces/agents-course-huggingface/.venv/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.52->langchain_ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d894de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.tools import tool\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad59ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "# load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f12c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define tool to get current system time\n",
    "@tool\n",
    "def get_current_time():\n",
    "    \"\"\"Returns current system time in YYYY-MM-DD HH:MM:SS format.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de930a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define graph state\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence, operator.add]  # List of conversation messages\n",
    "    next_agent: str  # Indicates next agent to execute\n",
    "\n",
    "# Initialize local language models with Ollama\n",
    "manager_llm = ChatOllama(\n",
    "    model=\"qwen3\",\n",
    "    temperature=0,  # Deterministic mode for deep reasoning\n",
    "    num_predict=100  # Increased reasoning capacity\n",
    ")\n",
    "\n",
    "operator_llm = ChatOllama(\n",
    "    model=\"qwen3\",\n",
    "    temperature=0,  # No deep reasoning\n",
    "    num_predict=50  # More concise responses\n",
    ")\n",
    "\n",
    "# Prompts for agents\n",
    "MANAGER_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are a Manager Agent specialized in coordinating tasks between other agents.\n",
    "Your current task is to obtain the system time by requesting help from the Operator Agent.\n",
    "\n",
    "Instructions:\n",
    "1. Analyze the request deeply and determine you need the Operator Agent\n",
    "2. Formulate a clear request to obtain the system time\n",
    "3. Once received, present the final response\n",
    "\n",
    "Conversation history:\n",
    "{history}\n",
    "\n",
    "User request: {input}\n",
    "\n",
    "Response:\n",
    "\"\"\")\n",
    "\n",
    "OPERATOR_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an Operator Agent responsible for executing specific tasks.\n",
    "Your current task is to provide the system time using your specialized tool.\n",
    "\n",
    "Instructions:\n",
    "1. Use the get_current_time() function when requesting system time\n",
    "2. Return only the function result without additional explanations\n",
    "3. /no_think\n",
    "\n",
    "Request: {input}\n",
    "\n",
    "Response:\n",
    "\"\"\")\n",
    "\n",
    "# Functions for graph nodes\n",
    "def manager_node(state):\n",
    "    # Process previous messages\n",
    "    history = \"\\n\".join([msg.content for msg in state[\"messages\"][-5:]])\n",
    "    user_input = \"Get system time\"\n",
    "    \n",
    "    # Generate manager response\n",
    "    prompt = MANAGER_PROMPT.format(history=history, input=user_input)\n",
    "    response = manager_llm.invoke(prompt)\n",
    "    \n",
    "    # Update state\n",
    "    new_messages = [\n",
    "        AIMessage(content=f\"[Manager]: {response.content}\"),\n",
    "        HumanMessage(content=\"[Manager->Operator]: I need to know the system time\")\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"messages\": new_messages,\n",
    "        \"next_agent\": \"operator\"\n",
    "    }\n",
    "\n",
    "def operator_node(state):\n",
    "    # Extract request from history\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "    \n",
    "    # Execute tool using invoke with empty input\n",
    "    current_time = get_current_time.invoke(\"\")\n",
    "    \n",
    "    # Create structured response\n",
    "    tool_response = f\"[Tool Response]: {current_time}\"\n",
    "    operator_response = operator_llm.invoke(f\"Request: {last_message}\\n\\n{tool_response}\")\n",
    "    \n",
    "    # Update state\n",
    "    new_messages = [\n",
    "        AIMessage(content=f\"[Operator]: {operator_response.content}\"),\n",
    "        HumanMessage(content=\"[Operator->Manager]: I have obtained the system time\")\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"messages\": new_messages,\n",
    "        \"next_agent\": \"end\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "113cf932",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure graph using LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"manager\", manager_node)\n",
    "workflow.add_node(\"operator\", operator_node)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"manager\")\n",
    "\n",
    "# Configure conditional flow\n",
    "def router(state):\n",
    "    return state[\"next_agent\"]\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"manager\",\n",
    "    router,\n",
    "    {\n",
    "        \"operator\": \"operator\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"operator\",\n",
    "    router,\n",
    "    {\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# Compile graph\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1f2e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ebdcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete conversation:\n",
      "[Manager]: <think>\n",
      "Okay, the user wants the system time. I need to coordinate with the Operator Agent to get that. Let me check the instructions again. First, I have to determine that I need the Operator Agent. Since the user is asking for the system time, which is likely something the Operator Agent has access to, that's the right agent to request from.\n",
      "\n",
      "Next, I need to formulate a clear request. The user's request is straightforward, so the message should be direct. Maybe something like\n",
      "[Operator]: <think>\n",
      "Okay, the user is asking for the system time. The tool response provided is \"2025-05-02 17:27:29\". Let me check if that's the correct format. The\n"
     ]
    }
   ],
   "source": [
    "# Execute full workflow\n",
    "final_state = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Get system time\")],\n",
    "    \"next_agent\": \"manager\"\n",
    "}, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "# Display results\n",
    "print(\"\\nComplete conversation:\")\n",
    "for msg in final_state[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(f\"{msg.content}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c63df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

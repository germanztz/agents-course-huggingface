{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# 1. Client Mail Agents 📌\n",
    "\n",
    "### **Que aprenderemos** 📚\n",
    "1. 🧠 Utiliza Langchain agents.  \n",
    "1. 🛠️ Usar el agente para programar y utilizar sus propias Tools.  \n",
    "1. 💡 No requiere suscripciones, utiliza solamente modelos de LLM locales y ligeros, en este caso usamos `qwen3:7b` sobre `ollama`.\n",
    "\n",
    "### **De qué trata el proyecto** 📚\n",
    "Este proyecto realiza operaciones sobre los clientes de una empresa. \n",
    "En este caso, consulta los clientes de una empresa y genera un e-mail utilizando el idioma prefrido del cliente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1004d8",
   "metadata": {},
   "source": [
    "### **Instalación de pre-requisitos** 🚀\n",
    "\n",
    "Esta línea es una instrucción para instalar paquetes de software en tu entorno de programación de Python. Es similar a usar `pip install` en la terminal, pero el `%` al principio es una \"magic command\" que se usa en entornos interactivos como Jupyter Notebook o Google Colab.\n",
    "\n",
    "**¿Cómo funciona?** 🧠\n",
    "\n",
    "1. **`%pip`:** Invoca el instalador de paquetes de Python, `pip`. 🛠️\n",
    "2. **`install`:** Le dice a `pip` que queremos instalar algo. 📦\n",
    "3. **`-U --upgrade`:** Estas son opciones. `-U` es una forma abreviada de `--upgrade`. Juntas, le dicen a `pip` que actualice los paquetes a la última versión si ya están instalados. 🔧\n",
    "4. **`pip`:** Este es el gestor de paquetes de Python. Es como una tienda donde puedes encontrar e instalar bibliotecas y herramientas creadas por otros programadores. 🛍️\n",
    "5. **`langgraph langchain_ollama`:** Estos son los nombres de los paquetes específicos que queremos instalar. `pip` los buscará en el \"Índice de Paquetes de Python\" (PyPI), los descargará y los instalará en tu entorno. 📥\n",
    "\n",
    "**Descripción de los paquetes:** 📚\n",
    "\n",
    "- **`langchain`:** Es un framework que simplifica la creación de aplicaciones que utilizan modelos de lenguaje grandes (LLMs). Piensa en ello como un conjunto de herramientas para conectar LLMs con otras fuentes de datos y lógica. 🤖\n",
    "- **`langchain_ollama`:** Una integración específica para usar modelos de lenguaje de la plataforma Ollama dentro de Langchain. Ollama te permite ejecutar LLMs localmente. 🧠\n",
    "- **`dotenv`:** Permite cargar variables de entorno desde un archivo `.env`. Esto es útil para guardar información sensible (como claves de API) fuera de tu código. 🔒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U pip langgraph langchain_ollama dotenv langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1e4f5",
   "metadata": {},
   "source": [
    "### 📁 **Carga de dependencias**\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "```\n",
    "- 📌 **`from dotenv import load_dotenv`**: Importa la función `load_dotenv` de `dotenv`, que carga las variables de entorno desde un archivo `.env`.\n",
    "- 📌 **`import os`**: Importa el módulo `os`, que permite interactuar con el sistema operativo (por ejemplo, acceder a variables de entorno).\n",
    "\n",
    " 🔄 **Carga de variables de entorno**\n",
    "```python\n",
    "load_dotenv()\n",
    "```\n",
    "- 🚀 **`load_dotenv()`**: Carga las variables de entorno desde el archivo `.env` en el directorio actual. Esto es útil para gestionar claves API, rutas, etc., sin hardcodearlas en el código.\n",
    "\n",
    " 📁 **Definición de carpeta de trabajo**\n",
    "```python\n",
    "workfolder = os.getenv('WORKFOLDER')\n",
    "```\n",
    "- 🗂️ **`os.getenv('WORKFOLDER')`**: Obtiene el valor de la variable de entorno `WORKFOLDER`, que probablemente define una carpeta donde se guardarán los archivos o datos del proyecto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "load_dotenv()\n",
    "workfolder = os.getenv('WORKFOLDER')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2516e00",
   "metadata": {},
   "source": [
    "### 🧩 Bloque 1: Importaciones\n",
    "```python\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "```\n",
    "- Se importan las librerías necesarias: `ChatOllama` para usar un modelo de lenguaje y `create_react_agent` para crear un agente de LangChain.\n",
    "- `ChatGoogleGenerativeAI` es una versión alternativa para Google Generative AI.\n",
    "\n",
    "### 🧠 Bloque 2: Definir el modelo de lenguaje LLM\n",
    "```python\n",
    "llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "llm_model = ChatOllama(model=\"qwen3\")\n",
    "llm_config = {\"recursion_limit\": 10}\n",
    "```\n",
    "- Se define el modelo de LLM que se utilizará: `ChatGoogleGenerativeAI` con un modelo específico y una temperatura para la generación de texto.\n",
    "- `ChatOllama` es otro modelo de lenguaje que se puede usar.\n",
    "- 🔄 **`llm_config`**: Define una configuración para el modelo de lenguaje.\n",
    "  - 🧠 **`\"recursion_limit\": 20`**: Limita la profundidad de la recursión para evitar bucles infinitos.\n",
    "\n",
    "\n",
    "### 🧠 Bloque 3: Crear el Agente\n",
    "```python\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=ChatOllama(model=\"qwen3\"), tools=[])\n",
    "```\n",
    "- Se crea un agente llamado `simple_agent` usando el modelo `qwen3` de Ollama. No se le asignan herramientas (tools) por ahora. 😎\n",
    "\n",
    "### 📄 Bloque 4: Mensaje de Entrada\n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": \"\"\"\n",
    "Generate the python code for a function that writes a string content in a file. \n",
    "a langchain tool with Annotated parameters and return type.\n",
    "3 parameters: content, file_path and append (True or False)\n",
    "should be able to handle exceptions and return an error message if the file cannot be written.\n",
    "Function must have a 30 words docstring\n",
    "use encoding utf8\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "```\n",
    "- Se pide que se genere un código de función en Python para escribir un contenido en un archivo, con anotaciones, manejo de excepciones y una documentación específica. 📝\n",
    "\n",
    "### 🚀 Bloque 5: Usar el Agente\n",
    "```python\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n",
    "```\n",
    "- Se usa el agente para procesar el mensaje de entrada. El resultado se muestra en pantalla usando `pretty_print()`. 🧠\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46fed548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Generate the python code for a function that writes a string content in a file. \n",
      "a langchain tool with Annotated parameters and return type.\n",
      "3 parameters: content, file_path and append (True or False)\n",
      "should be able to handle exceptions and return an error message if the file cannot be written.\n",
      "Function must have a 30 words docstring\n",
      "use encoding utf8\n",
      "give just the code, no introduction /no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "```python\n",
      "from langchain.tools import tool\n",
      "from typing import Annotated\n",
      "\n",
      "@tool\n",
      "def write_to_file(\n",
      "    content: Annotated[str, \"The content to write to the file.\"],\n",
      "    file_path: Annotated[str, \"The path to the file.\"],\n",
      "    append: Annotated[bool, \"Whether to append to the file or overwrite it.\"]\n",
      ") -> Annotated[str, \"Result message indicating success or error.\"]:\n",
      "    \"\"\"\n",
      "    Writes content to a file with specified path. Handles exceptions and returns error message on failure.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        mode = 'a' if append else 'w'\n",
      "        with open(file_path, mode, encoding='utf8') as f:\n",
      "            f.write(content)\n",
      "        return f\"Successfully wrote content to {file_path}\"\n",
      "    except Exception as e:\n",
      "        return f\"Error writing to file: {str(e)}\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm_model = ChatOllama(model=\"qwen3\")\n",
    "#  llm_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.2)\n",
    "llm_config = {\"recursion_limit\": 10}\n",
    "\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"\"\"\n",
    "Generate the python code for a function that writes a string content in a file. \n",
    "a langchain tool with Annotated parameters and return type.\n",
    "3 parameters: content, file_path and append (True or False)\n",
    "should be able to handle exceptions and return an error message if the file cannot be written.\n",
    "Function must have a 30 words docstring\n",
    "use encoding utf8\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e09131",
   "metadata": {},
   "source": [
    "### 🔹 **Bloque 1: Importaciones**\n",
    "### 🔹 **Bloque 2: Definición de la función `write_file`**\n",
    "```python\n",
    "@tool\n",
    "def write_file(\n",
    "    content: Annotated[str, \"The content to be written to the file.\"],\n",
    "    file_path: Annotated[str, \"The path to the file where content will be written.\"],\n",
    "    append: Annotated[bool, \"If True, append to the file; if False, overwrite it.\"],\n",
    "    encoding: Annotated[Optional[str], \"The encoding of the file.\"] = 'utf-8'\n",
    ") -> Annotated[str, \"Result message indicating success or error.\"]:\n",
    "```\n",
    "- **¿Qué hace?** Define una función llamada `write_file` que es una herramienta (por el decorador `@tool`). 🛠️\n",
    "- **¿Qué recibe?** \n",
    "  - `content`: El contenido a escribir. 📝\n",
    "  - `file_path`: La ruta del archivo. 🗂️\n",
    "  - `append`: Si es `True`, se añade al final; si es `False`, se sobrescribe. ✅\n",
    "  - `encoding`: Codificación del archivo (por defecto `utf-8`). 🔐\n",
    "- **¿Qué devuelve?** Un mensaje que indica si se escribió correctamente o hubo un error. 💬\n",
    "\n",
    "### 🔹 **Bloque 3: Lógica de escritura del archivo**\n",
    "```python\n",
    "    \"\"\"Writes content to a file in append or overwrite mode.\"\"\"\n",
    "    try:\n",
    "        mode = 'a' if append else 'w'\n",
    "        content = '\\n'+content if append else content\n",
    "        with open(file_path, mode, encoding=encoding) as f:\n",
    "            f.write(content)\n",
    "        return f\"Content successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {str(e)}\"\n",
    "```\n",
    "- **¿Qué hace?** \n",
    "  - **`mode = 'a' if append else 'w'`**: Define el modo de apertura del archivo (`'a'` para anexar, `'w'` para sobrescribir). 📁\n",
    "  - **`content = '\\n'+content if append else content`**: Si se está anexando, agrega una nueva línea al contenido. 📄\n",
    "  - **`with open(...) as f`**: Abre el archivo con los parámetros definidos. 🚪\n",
    "  - **`f.write(content)`**: Escribe el contenido en el archivo. ✍️\n",
    "  - **`return ...`**: Devuelve un mensaje de éxito o error. 🚨\n",
    "- **¿Por qué el `try-except`?** Para manejar errores en caso de que algo vaya mal, como que el archivo no exista o no se tenga permiso. ⚠️\n",
    "\n",
    "### 🔹 **Bloque 4: Llamada a la función**\n",
    "```python\n",
    "write_file.invoke(input={'content':'this is a test\\n', 'file_path':'/tmp4/file.txt', 'append': True})\n",
    "```\n",
    "- **¿Qué hace?** Llama a la función `write_file` con los parámetros especificados. 📡\n",
    "- **¿Qué pasa?** \n",
    "  - Escribe el contenido `'this is a test\\n'` en el archivo `/tmp4/file.txt`.\n",
    "  - Como `append` es `True`, se añade al final del archivo. 📁\n",
    "- **¿Dónde se guarda?** En la ruta `/tmp4/file.txt`. 🗂️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240354bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Error writing to file: [Errno 2] No such file or directory: '/tmp4/file.txt'\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from typing import Annotated, Optional\n",
    "\n",
    "@tool\n",
    "def write_file(\n",
    "    content: Annotated[str, \"The content to be written to the file.\"],\n",
    "    file_path: Annotated[str, \"The path to the file where content will be written.\"],\n",
    "    append: Annotated[bool, \"If True, append to the file; if False, overwrite it.\"],\n",
    "    encoding: Annotated[Optional[str], \"The encoding of the file.\"] = 'utf-8'\n",
    ") -> Annotated[str, \"Result message indicating success or error.\"]:\n",
    "    \"\"\"Writes content to a file in append or overwrite mode.\"\"\"\n",
    "    try:\n",
    "        mode = 'a' if append else 'w'\n",
    "        content = '\\n'+content if append else content\n",
    "        with open(file_path, mode, encoding=encoding) as f:\n",
    "            f.write(content)\n",
    "        return f\"Content successfully written to {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file: {str(e)}\"\n",
    "\n",
    "write_file.invoke(input={'content':'this is a test\\n', 'file_path':'/tmp4/file.txt', 'append': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a938689",
   "metadata": {},
   "source": [
    "**Mensaje de entrada del usuario**  \n",
    "```python src/1.client mail agents.ipynb\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "generate a csv list of 10 dummy clients with the following columns:\n",
    "id, name, address, phone, email, prefered_languaje\n",
    "write the list to file in '{workfolder}/clients.csv'\n",
    "/no_think\"\"\"\n",
    "}\n",
    "```\n",
    "📝 **Explicación:** Se define un mensaje de entrada del usuario que solicita generar una lista de 10 clientes ficticios en formato CSV, con columnas específicas, y guardar el archivo en una carpeta específica.  \n",
    "🎯 *El usuario pide que se genere un archivo CSV con datos de clientes.*\n",
    "\n",
    "**3. Uso del agente para procesar la solicitud**  \n",
    "🤖 **Explicación:** Aquí se usa el agente para procesar el mensaje de entrada. El agente genera una respuesta, y se imprime el último mensaje de la conversación en un formato legible.  \n",
    "📦 *El agente genera el CSV y lo escribe en el archivo especificado.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5dc4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "generate a csv list of 10 dummy clients with the following columns:\n",
      "id, name, address, phone, email, prefered_languaje\n",
      "write the list to file in '/home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv'\n",
      "/no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "Tool Calls:\n",
      "  write_file (e5de65d3-b072-470e-9ce3-94d15e40a996)\n",
      " Call ID: e5de65d3-b072-470e-9ce3-94d15e40a996\n",
      "  Args:\n",
      "    append: False\n",
      "    content: id,name,address,phone,email,prefered_languaje\n",
      "1,John Doe,123 Main St,555-1234,john@example.com,English\n",
      "2,Jane Smith,456 Oak Ave,555-5678,jane@example.com,Spanish\n",
      "3,Mike Johnson,789 Pine Rd,555-9012,mike@example.com,Portuguese\n",
      "4,Sarah Lee,321 Maple Dr,555-3456,sarah@example.com,French\n",
      "5,David Kim,654 Cedar Ln,555-6789,david@example.com,German\n",
      "6,Emily Davis,987 Birch St,555-2345,emily@example.com,Italian\n",
      "7,James Brown,234 Willow Dr,555-4567,james@example.com,Japanese\n",
      "8,Emma White,567 Oak St,555-7890,emma@example.com,Chinese\n",
      "9,Oliver Green,890 Pine Rd,555-1234,oliver@example.com,Arabic\n",
      "10,Charlotte Black,123 Maple Dr,555-5678,charlotte@example.com,Russian\n",
      "    file_path: /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: write_file\n",
      "\n",
      "Content successfully written to /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "The CSV file with 10 dummy client entries has been successfully created at the specified path:\n",
      "\n",
      "```\n",
      "/home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "```\n",
      "\n",
      "You can now find the file in that location and use it as needed. Let me know if you need any further assistance!\n"
     ]
    }
   ],
   "source": [
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[write_file])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "generate a csv list of 10 dummy clients with the following columns:\n",
    "id, name, address, phone, email, prefered_languaje\n",
    "write the list to file in '{workfolder}/clients.csv'\n",
    "/no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27747adc",
   "metadata": {},
   "source": [
    "### 1. **Creación del código de la segunda Tool** 😊  \n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Generate the python code for a function that return dict with all the client details for a given id. \n",
    "read clients from csv file_path in utf8\n",
    "is a langchain tool with typing Annotated params.\n",
    "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
    "handle exceptions\n",
    "Function must have a 20 word docstring\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "```\n",
    "- **¿Qué hace?** Define un mensaje de entrada que simula una petición del usuario para generar código.  \n",
    "- **Detalles:** Contiene instrucciones sobre cómo debe ser la función, incluyendo parámetros, manejo de excepciones y una docstring específica.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4024eb89-843d-4cc3-ab3f-e1eb4d031179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.477064Z",
     "start_time": "2024-05-15T08:19:42.397083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Generate the python code for a function that return dict with all the client details for a given id. \n",
      "read clients from csv file_path in utf8\n",
      "is a langchain tool with typing Annotated params.\n",
      "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
      "handle exceptions\n",
      "Function must have a 20 word docstring\n",
      "give just the code, no introduction /no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "from typing import Dict, Annotated, Optional\n",
      "from langchain.tools import tool\n",
      "import csv\n",
      "\n",
      "@tool\n",
      "def get_client_details(\n",
      "    id: Annotated[int, \"Client ID to retrieve details for\"],\n",
      "    file_path: Annotated[str, \"Path to the CSV file containing client data\"],\n",
      "    encoding: Optional[Annotated[str, \"File encoding, default is 'utf-8'\"]] = 'utf-8'\n",
      ") -> Dict:\n",
      "    \"\"\"Retrieve client details by ID from a CSV file. Handles exceptions and returns a dictionary.\"\"\"\n",
      "    try:\n",
      "        with open(file_path, mode='r', encoding=encoding) as file:\n",
      "            reader = csv.DictReader(file)\n",
      "            for row in reader:\n",
      "                if int(row['id']) == id:\n",
      "                    return dict(row)\n",
      "            return {}\n",
      "    except Exception as e:\n",
      "        print(f\"An error occurred: {e}\")\n",
      "        return {}\n"
     ]
    }
   ],
   "source": [
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "Generate the python code for a function that return dict with all the client details for a given id. \n",
    "read clients from csv file_path in utf8\n",
    "is a langchain tool with typing Annotated params.\n",
    "params: id: int, file_path: str, encoding: Optional[str] = 'utf-8'\n",
    "handle exceptions\n",
    "Function must have a 20 word docstring\n",
    "give just the code, no introduction /no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream({\"messages\": [input_message]}, llm_config, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621c389a",
   "metadata": {},
   "source": [
    "### 📁 **Definición de la función `get_client_details`**  \n",
    "La función se llama `get_client_details` y recibe tres parámetros:  \n",
    "- `id`: El ID del cliente que queremos buscar.  \n",
    "- `file_path`: La ruta del archivo CSV donde están los datos de los clientes.  \n",
    "- `encoding`: La codificación del archivo (por defecto es `'utf-8'`).  \n",
    "\n",
    "La función devuelve un diccionario con los detalles del cliente o un error si algo salió mal.\n",
    "\n",
    "### 🧠 **Bloque `try`**  \n",
    "Este bloque intenta leer el archivo CSV y buscar el cliente por su ID.  \n",
    "```python\n",
    "with open(file_path, mode='r', encoding=encoding) as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        if int(row['id']) == id:\n",
    "            return dict(row)\n",
    "    return {}\n",
    "```\n",
    "- Abre el archivo en modo lectura (`'r'`).  \n",
    "- Usa `csv.DictReader` para leer el archivo como un diccionario.  \n",
    "- Recorre cada fila del CSV y compara el ID del cliente con el `id` proporcionado.  \n",
    "- Si encuentra un cliente con el mismo ID, devuelve su información como un diccionario.  \n",
    "- Si no lo encuentra, devuelve un diccionario vacío `{}`.\n",
    "\n",
    "### ⚠️ **Bloque `except`**  \n",
    "Si ocurre un error durante la lectura del archivo (por ejemplo, el archivo no existe o tiene un formato incorrecto), se captura y se devuelve un mensaje de error.\n",
    "```python\n",
    "except Exception as e:\n",
    "    return {\"error\": str(e)}\n",
    "```\n",
    "- Captura cualquier excepción y la convierte en un mensaje de error.  \n",
    "- Devuelve un diccionario con la clave `\"error\"` y el mensaje de error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53db0c78-e357-48ba-ae5f-3fc04735a3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.810290Z",
     "start_time": "2024-05-15T08:19:46.561088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '6',\n",
       " 'name': 'Emily Davis',\n",
       " 'address': '987 Birch St',\n",
       " 'phone': '555-2345',\n",
       " 'email': 'emily@example.com',\n",
       " 'prefered_languaje': 'Italian'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from typing import Dict, Annotated, Optional\n",
    "import csv\n",
    "\n",
    "@tool\n",
    "def get_client_details(\n",
    "    id: Annotated[int, \"Client ID to retrieve details for\"],\n",
    "    file_path: Annotated[str, \"Path to the CSV file containing client data\"],\n",
    "    encoding: Optional[Annotated[str, \"File encoding, default is 'utf-8'\"]] = 'utf-8'\n",
    ") -> Dict[str, any]:\n",
    "    \"\"\"Retrieve client details by ID\"\"\"\n",
    "    try:\n",
    "        with open(file_path, mode='r', encoding=encoding) as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if int(row['id']) == id:\n",
    "                    return dict(row)\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "get_client_details.invoke(input={'id':6, 'file_path': f'{workfolder}/clients.csv'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b33b322",
   "metadata": {},
   "source": [
    "**Bloque 1: Crear un mensaje de entrada**  \n",
    "```python\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "get the client details of a client with id '{random.randint(0, 10)}'\n",
    "file is in {workfolder}/clients.csv\n",
    "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
    "use they prefered language\n",
    "especify the actual address and phone number of the client.\n",
    "\"\"\"\n",
    "}\n",
    "```\n",
    "- **¿Qué hace?** Crea un mensaje de entrada en formato JSON que simula una consulta de un usuario.  \n",
    "- **Detalles:**  \n",
    "  - Pide los detalles de un cliente con un ID aleatorio entre 0 y 10. 😊  \n",
    "  - Indica que los datos están en un archivo CSV llamado `clients.csv` en la carpeta `workfolder`. 🗂️  \n",
    "  - Solicita generar un email explicando que no se pudo entregar el paquete ni contactar al cliente. 📧  \n",
    "  - Menciona usar el idioma preferido del cliente. 🌍  \n",
    "  - Pide especificar la dirección y el número de teléfono del cliente. 📞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7a1260-d9f6-4011-b2b1-13fab5126997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.825649Z",
     "start_time": "2024-05-15T08:19:48.811753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "get the client details of a client with id '7'\n",
      "file is in /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
      "use they prefered language\n",
      "especify the actual address and phone number of the client.\n",
      "/no_think\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "Tool Calls:\n",
      "  get_client_details (2d4f5b95-ae07-44cd-ac07-09bb95ecd85c)\n",
      " Call ID: 2d4f5b95-ae07-44cd-ac07-09bb95ecd85c\n",
      "  Args:\n",
      "    file_path: /home/daimler/workspaces/agents-course-huggingface/.workspace/clients.csv\n",
      "    id: 7\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_client_details\n",
      "\n",
      "{\"id\": \"7\", \"name\": \"James Brown\", \"address\": \"234 Willow Dr\", \"phone\": \"555-4567\", \"email\": \"james@example.com\", \"prefered_languaje\": \"Japanese\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: simple_agent\n",
      "\n",
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Here is the email in the client's preferred language (Japanese):\n",
      "\n",
      "---\n",
      "\n",
      "親愛なるJames Brown 様、\n",
      "\n",
      "私たちは、ご指定の住所「234 Willow Dr」にパッケージを配達できませんでした。また、ご提供の電話番号「555-4567」でご連絡することもできませんでした。ご不便をおかけして大変申し訳ございません。\n",
      "\n",
      "ご確認いただけるようお願いいたします。何かご質問がございましたら、お気軽にお知らせください。\n",
      "\n",
      "ありがとうございます。\n",
      "お手伝いをさせていただきます。\n",
      "\n",
      "---\n",
      "\n",
      "If you need the email in English or any other language, please let me know!\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "import random\n",
    "\n",
    "simple_agent = create_react_agent(name=\"simple_agent\", model=llm_model, tools=[get_client_details])\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": f\"\"\"\n",
    "get the client details of a client with id '{random.randint(0, 10)}'\n",
    "file is in {workfolder}/clients.csv\n",
    "generate an email explaining we could not deliver the package at his address nor contact him at his phone number.\n",
    "use they prefered language\n",
    "especify the actual address and phone number of the client.\n",
    "/no_think\"\"\"\n",
    "}\n",
    "\n",
    "# Use the agent\n",
    "for step in simple_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

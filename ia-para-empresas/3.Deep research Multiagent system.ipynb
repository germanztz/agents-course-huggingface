{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# Deep research Multiagent system\n",
    "\n",
    "\n",
    "### Original doc:\n",
    "\n",
    "    https://www.youtube.com/watch?v=mjPSkPLbu1s\n",
    "\n",
    "<div style=\"width: 100%; height: 768px; overflow: hidden;\">\n",
    "  <iframe width=\"1024\" height=\"768\" src=\"https://www.youtube.com/embed/mjPSkPLbu1s?si=nrN8Y4pnHNAj-5WZ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --upgrade pip langgraph langchain_community langchain_anthropic langchain-tavily langchain_experimental langchain_ollama mcp langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "workfolder = os.getenv('WORKFOLDER')\n",
    "mcp_file_path = os.getenv('MCP_SRV_PATH')\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler() \n",
    "llm_config = {\"configurable\": {\"thread_id\": \"abc123\"}, \"recursion_limit\": 20, \"callbacks\": [langfuse_handler]}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd0c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_current_time', description='Returns current system time.', args_schema={'description': 'Returns current system time.', 'properties': {}, 'title': 'get_current_time', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x79362dddfa60>),\n",
       " StructuredTool(name='read_file', description='Read content from a file.', args_schema={'description': 'Read content from a file.', 'properties': {'file_path': {'description': 'Path to the file to read', 'title': 'File Path', 'type': 'string'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}, 'start': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 0, 'description': 'The start line. Default is 0', 'title': 'Start'}, 'end': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'The end line. Default is None', 'title': 'End'}}, 'required': ['file_path'], 'title': 'read_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x79368dba5e40>),\n",
       " StructuredTool(name='write_file', description='Writes text content to a file in append or overwrite mode.', args_schema={'description': 'Writes text content to a file in append or overwrite mode.', 'properties': {'content': {'description': 'The content to be written to the file.', 'title': 'Content', 'type': 'string'}, 'file_path': {'description': 'The path to the file where content will be written.', 'title': 'File Path', 'type': 'string'}, 'append': {'description': 'If True, append to the file; if False, overwrite it.', 'title': 'Append', 'type': 'boolean'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}}, 'required': ['content', 'file_path', 'append'], 'title': 'write_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x79362fd7b1a0>),\n",
       " StructuredTool(name='execute_bash', description='Execute a bash command.', args_schema={'description': 'Execute a bash command.', 'properties': {'command': {'description': 'The bash command to execute', 'title': 'Command', 'type': 'string'}, 'timeout': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 60, 'description': 'Timeout in seconds.', 'title': 'Timeout'}}, 'required': ['command'], 'title': 'execute_bash', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x79362dc8dd00>),\n",
       " TavilySearch(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"mcp\": {\n",
    "            \"command\": \"python\",\n",
    "            # Make sure to update to the full absolute path to your math_server.py file\n",
    "            \"args\": [mcp_file_path],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        # \"weather\": {\n",
    "        #     # make sure you start your weather server on port 8000\n",
    "        #     \"url\": \"http://localhost:8000/mcp/\",\n",
    "        #     \"transport\": \"streamable_http\",\n",
    "        # }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "tools.append(TavilySearch())\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46fed548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Build a Multi-Agent Deep Research System\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to build a Multi-Agent Deep Research System. Let me start by understanding what that entails. A multi-agent system typically involves multiple autonomous agents that interact to achieve common or individual goals. Deep research might refer to using deep learning techniques or extensive data analysis.\n",
      "\n",
      "First, I need to break down the components. Maybe the user is looking for a system that combines multiple AI agents, each handling different tasks, possibly using deep learning models. I should check recent advancements in multi-agent systems and how they integrate deep learning.\n",
      "\n",
      "I should search for information on existing frameworks or architectures for multi-agent systems. Also, look into how deep learning is applied in such systems, like reinforcement learning with multiple agents. Maybe there are case studies or papers on this topic.\n",
      "\n",
      "Wait, the user might be interested in both the theoretical aspects and practical implementation. So, I need to cover topics like agent communication, coordination mechanisms, reward structures, and scalability. Also, challenges like handling complex environments or ensuring agents' cooperation versus competition.\n",
      "\n",
      "I should use the Tavily search tool to find recent articles, research papers, or tutorials on building such systems. Parameters like search_depth should be set to 'advanced' since it's a complex topic. Maybe include domains like AI research or machine learning to get relevant results. Exclude domains that might not be relevant, like general tech blogs unless specified.\n",
      "\n",
      "Check if there are any specific tools or libraries that facilitate multi-agent deep learning, such as Ray, TensorFlow, or PyTorch. Also, look into real-world applications to provide context. The user might need guidance on setting up the environment, training models, and evaluating performance.\n",
      "\n",
      "I should structure the questions to cover the foundational concepts, technical implementation, challenges, and applications. Ensuring that the questions are comprehensive but not too broad. Maybe include questions about agent design, communication protocols, and integration of deep learning models.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  tavily_search (a1b3e191-591a-4d6d-9c51-b6d98eb94b6f)\n",
      " Call ID: a1b3e191-591a-4d6d-9c51-b6d98eb94b6f\n",
      "  Args:\n",
      "    exclude_domains: ['twitter.com', 'reddit.com']\n",
      "    include_domains: ['ai.googleblog.com', 'arxiv.org', 'medium.com']\n",
      "    query: Multi-Agent Deep Research System\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Multi-Agent Deep Research System\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://noailabs.medium.com/llm-powered-deep-research-systems-multi-agent-pipelines-d21c33410282\", \"title\": \"LLM-Powered Deep Research Systems: Multi-Agent Pipelines\", \"content\": \"Why Multi-Agent Systems for Research?\\n\\nTraditional AI often struggles with open-ended research. The process is inherently dynamic, requiring flexibility to pivot based on new discoveries. Our multi-agent approach mirrors how humans conduct research: a “lead agent” plans the strategy, then autonomously dispatches specialized “subagents” to explore different facets of a query in parallel. This allows for: [...] The traditional multi-agent approach involves an orchestrator breaking down a task into subtasks, assigning them to separate sub-agents, and then an aggregator combining the results. However, this method faces challenges: agents work independently without full visibility, and errors from one agent can negatively impact the final output. A proposed improvement is sharing conversational history and actions among agents, similar to OpenAI’s handoff principle. However, this can lead to context [...] Our internal evaluations show a significant performance boost, with multi-agent Claude Opus 4 outperforming single-agent Opus 4 by over 90% on complex research tasks. The secret sauce? Efficiently utilizing more tokens across parallel agents to tackle problems that exceed a single agent’s capacity.\\n\\nEngineering the Research System: Key Principles\\n\\nBuilding a robust multi-agent system involves intricate coordination. We discovered several critical principles:\", \"score\": 0.834852, \"raw_content\": null}, {\"url\": \"https://medium.com/@karanbhutani477/multi-agent-frameworks-for-llm-powered-deep-research-systems-abf30d32fa29\", \"title\": \"Multi-Agent Frameworks for LLM-Powered Deep Research ...\", \"content\": \"To enable this kind of complex behavior, modern LLM research systems adopt a multi-agent framework within a single unified model. In practice, this often doesn’t mean separate AI models, but rather distinct functional phases or modules orchestrated by the LLM. Here are the key components in the architecture, as exemplified by OpenAI’s ChatGPT with Deep Research and similar systems: [...] As LLM research agents become more advanced, we can expect them to tackle increasingly complex tasks: writing detailed literature reviews, conducting meta-analyses of scientific papers, or even helping programmers by researching documentation and code examples. The patterns established by today’s systems will serve as a foundation. OpenAI’s ChatGPT with browsing and code, Google’s Gemini with its integrated tools, and open frameworks from projects like DeepResearcher show a common path forward [...] OpenAI isn’t alone in this realm. The idea of LLMs as deep research assistants has caught fire across the AI community, leading to a flurry of systems with similar goals. Google introduced Gemini Deep Research in late 2024, building these multi-step research capabilities into its Gemini AI model. Perplexity AI, known for its LLM search engine, launched Perplexity Deep Research shortly after, and even open-source projects like DeepSeek emerged in response. Each of these systems shares the core\", \"score\": 0.78944516, \"raw_content\": null}, {\"url\": \"https://medium.com/@kushalbanda/how-we-built-our-multi-agent-research-system-5f5e10b2a8d6\", \"title\": \"How we built our multi-agent research system — Anthropic\", \"content\": \"The key lies in understanding that multi-agent systems represent a new paradigm requiring specialized approaches to architecture, evaluation, and operational practices. Success demands careful engineering, comprehensive testing, detail-oriented prompt and tool design, and tight collaboration between research, product, and engineering teams with deep understanding of current agent capabilities. [...] The performance gains are substantial. Anthropic’s internal evaluations demonstrate that their multi-agent system with Claude Opus 4 as the lead agent and Claude Sonnet 4 subagents outperformed single-agent Claude Opus 4 by 90.2% on research evaluation tasks. This isn’t merely an incremental improvement; it represents a qualitative leap in capability, particularly for breadth-first queries requiring simultaneous exploration of multiple independent directions. [...] This article synthesizes insights from Anthropic’s technical post “How we built our multi-agent research system,” written by Jeremy Hadfield, Barry Zhang, Kenneth Lien, Florian Scholz, Jeremy Fox, and Daniel Ford, reflecting the collective efforts of multiple teams who brought the Research feature to production.\\n\\n## References\\n\\n1. Build Multi-Agent Research System: \\n2. Building Effective Agents — Anthropic: \\n3. Anthropic Agent Cookbook: \\n\\nAI\\n\\nAgents\\n\\nSoftware Development\\n\\nDeep Learning\", \"score\": 0.73322314, \"raw_content\": null}], \"response_time\": 2.36, \"request_id\": \"2485ca58-874e-491e-b1e4-822788bff152\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to build a Multi-Agent Deep Research System. Let me start by understanding what that entails. A multi-agent system typically involves multiple autonomous agents that interact to achieve common or individual goals. Deep research might refer to using deep learning techniques or extensive data analysis.\n",
      "\n",
      "First, I need to break down the components. Maybe the user is looking for a system that combines multiple AI agents, each handling different tasks, possibly using deep learning models. I should check recent advancements in multi-agent systems and how they integrate deep learning.\n",
      "\n",
      "I should search for information on existing frameworks or architectures for multi-agent systems. Also, look into how deep learning is applied in such systems, like reinforcement learning with multiple agents. Maybe there are case studies or papers on this topic.\n",
      "\n",
      "Wait, the user might be interested in both the theoretical aspects and practical implementation. So, I need to cover topics like agent communication, coordination mechanisms, reward structures, and scalability. Also, challenges like handling complex environments or ensuring agents' cooperation versus competition.\n",
      "\n",
      "I should use the Tavily search tool to find recent articles, research papers, or tutorials on building such systems. Parameters like search_depth should be set to 'advanced' since it's a complex topic. Maybe include domains like AI research or machine learning to get relevant results. Exclude domains that might not be relevant, like general tech blogs unless specified.\n",
      "\n",
      "Check if there are any specific tools or libraries that facilitate multi-agent deep learning, such as Ray, TensorFlow, or PyTorch. Also, look into real-world applications to provide context. The user might need guidance on setting up the environment, training models, and evaluating performance.\n",
      "\n",
      "I should structure the questions to cover the foundational concepts, technical implementation, challenges, and applications. Ensuring that the questions are comprehensive but not too broad. Maybe include questions about agent design, communication protocols, and integration of deep learning models.\n",
      "</think>\n",
      "\n",
      "**topic**: Multi-Agent Deep Research System  \n",
      "**questions**:  \n",
      "1. What are the key principles and architecture of a multi-agent deep research system?  \n",
      "2. How do multi-agent systems improve the efficiency and effectiveness of complex research tasks compared to single-agent approaches?  \n",
      "3. What are the challenges in designing coordination mechanisms for multi-agent systems in deep research?  \n",
      "4. How do deep learning techniques integrate with multi-agent frameworks to enhance research capabilities?  \n",
      "5. What are the best practices for evaluating the performance of a multi-agent deep research system?  \n",
      "6. Can you provide examples of real-world applications of multi-agent deep research systems?  \n",
      "7. What tools or frameworks are commonly used to build and deploy multi-agent deep research systems?  \n",
      "8. How do agents in a deep research system handle dynamic environments and evolving research goals?  \n",
      "9. What role does communication and information sharing play in the success of multi-agent research systems?  \n",
      "10. How can challenges like agent autonomy, collaboration, and error propagation be mitigated in multi-agent deep research systems?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to build a Multi-Agent Deep Research System. Let me start by understanding what that entails. A multi-agent system typically involves multiple autonomous agents that interact to achieve common or individual goals. Deep research might refer to using deep learning techniques or extensive data analysis.\n",
      "\n",
      "First, I need to break down the components. Maybe the user is looking for a system that combines multiple AI agents, each handling different tasks, possibly using deep learning models. I should check recent advancements in multi-agent systems and how they integrate deep learning.\n",
      "\n",
      "I should search for information on existing frameworks or architectures for multi-agent systems. Also, look into how deep learning is applied in such systems, like reinforcement learning with multiple agents. Maybe there are case studies or papers on this topic.\n",
      "\n",
      "Wait, the user might be interested in both the theoretical aspects and practical implementation. So, I need to cover topics like agent communication, coordination mechanisms, reward structures, and scalability. Also, challenges like handling complex environments or ensuring agents' cooperation versus competition.\n",
      "\n",
      "I should use the Tavily search tool to find recent articles, research papers, or tutorials on building such systems. Parameters like search_depth should be set to 'advanced' since it's a complex topic. Maybe include domains like AI research or machine learning to get relevant results. Exclude domains that might not be relevant, like general tech blogs unless specified.\n",
      "\n",
      "Check if there are any specific tools or libraries that facilitate multi-agent deep learning, such as Ray, TensorFlow, or PyTorch. Also, look into real-world applications to provide context. The user might need guidance on setting up the environment, training models, and evaluating performance.\n",
      "\n",
      "I should structure the questions to cover the foundational concepts, technical implementation, challenges, and applications. Ensuring that the questions are comprehensive but not too broad. Maybe include questions about agent design, communication protocols, and integration of deep learning models.\n",
      "</think>\n",
      "\n",
      "**topic**: Multi-Agent Deep Research System  \n",
      "**questions**:  \n",
      "1. What are the key principles and architecture of a multi-agent deep research system?  \n",
      "2. How do multi-agent systems improve the efficiency and effectiveness of complex research tasks compared to single-agent approaches?  \n",
      "3. What are the challenges in designing coordination mechanisms for multi-agent systems in deep research?  \n",
      "4. How do deep learning techniques integrate with multi-agent frameworks to enhance research capabilities?  \n",
      "5. What are the best practices for evaluating the performance of a multi-agent deep research system?  \n",
      "6. Can you provide examples of real-world applications of multi-agent deep research systems?  \n",
      "7. What tools or frameworks are commonly used to build and deploy multi-agent deep research systems?  \n",
      "8. How do agents in a deep research system handle dynamic environments and evolving research goals?  \n",
      "9. What role does communication and information sharing play in the success of multi-agent research systems?  \n",
      "10. How can challenges like agent autonomy, collaboration, and error propagation be mitigated in multi-agent deep research systems?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "You are a topic analizer. \n",
    "1. search the topic in the Internet\n",
    "2. using the results generate questions that, together, cover the topic.\n",
    "output format: **topic**: \\n**questions**: \\n \n",
    "\"\"\"\n",
    "  # Create the agent\n",
    "topic_analizer = create_react_agent(name=\"topic_analizer\", model=ChatOllama(model=\"qwen3\"), \n",
    "    tools=[TavilySearch(max_results=3)], response_format='json', prompt=system_prompt)\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"Build a Multi-Agent Deep Research System\"}\n",
    "\n",
    "# Use the agent\n",
    "for step in topic_analizer.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240354bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_react_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      4\u001b[39m system_prompt = \u001b[33m\"\"\"\u001b[39m\u001b[33m \u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mYou are a search assistant\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m1. For each question do an internet search\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m4. Output format json: [\u001b[39m\u001b[33m{\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: [\u001b[39m\u001b[33m{\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[33murl\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m }]}]}\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m   \u001b[38;5;66;03m# Create the agent\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m search_agent = \u001b[43mcreate_react_agent\u001b[49m(name=\u001b[33m\"\u001b[39m\u001b[33msearch_agent\u001b[39m\u001b[33m\"\u001b[39m, model=ChatOllama(model=\u001b[33m\"\u001b[39m\u001b[33mqwen3\u001b[39m\u001b[33m\"\u001b[39m), \n\u001b[32m     11\u001b[39m     tools=[TavilySearch()], response_format=\u001b[33m'\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m'\u001b[39m, prompt=system_prompt)\n\u001b[32m     13\u001b[39m content = \u001b[33m\"\"\"\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHow to build a Multi-Agent Deep Research System\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestions\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: [ \u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhat is the core architecture of a Multi-Agent Deep Research System?\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}, \u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWhat tools are essential for multi-agent research execution?\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}, \u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHow to implement a multi-agent research workflow?\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m}]}\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     17\u001b[39m input_message = {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: content,}\n",
      "\u001b[31mNameError\u001b[39m: name 'create_react_agent' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "You are a search assistant\n",
    "1. For each question do an internet search\n",
    "4. Output format json: [{ \"question\": \"\", \"results\": [{ \"url\": \"\", \"title\": \"\" }]}]}\n",
    "\"\"\"\n",
    "  # Create the agent\n",
    "search_agent = create_react_agent(name=\"search_agent\", model=ChatOllama(model=\"qwen3\"), \n",
    "    tools=[TavilySearch()], response_format='json', prompt=system_prompt)\n",
    "\n",
    "content = \"\"\"{\"topic\": \"How to build a Multi-Agent Deep Research System\", \"questions\": [ \n",
    "{\"question\": \"What is the core architecture of a Multi-Agent Deep Research System?\"}, \n",
    "{\"question\": \"What tools are essential for multi-agent research execution?\"}, \n",
    "{\"question\": \"How to implement a multi-agent research workflow?\"}]}\"\"\"\n",
    "input_message = {\"role\": \"user\", \"content\": content,}\n",
    "\n",
    "# Use the agent\n",
    "for step in search_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.web_operations import scrape_webpages\n",
    "import json\n",
    "\n",
    "summarization_agent = create_agent(\"summarization_agent\", \"qwen3:14b\", [scrape_webpages])\n",
    "content = read_file.invoke('prompts/search_agent_output_example.json')\n",
    "# Convert string to json object\n",
    "content = json.loads(content)\n",
    "\n",
    "for question in content['questions']:\n",
    "    input_message = {\"role\": \"user\", \"content\": json.dumps(question),}\n",
    "\n",
    "    # Use the agent\n",
    "    config = {\"configurable\": {\"thread_id\": \"abc123\"}, \"recursion_limit\": 10, \"callbacks\": [langfuse_handler]}\n",
    "    for step in summarization_agent.stream(\n",
    "        {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdd0a3",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354568e2-aef0-4af9-8a79-e64d3eea752f",
   "metadata": {},
   "source": [
    "## Create Tools\n",
    "\n",
    "Each team will be composed of one or more agents each with one or more tools. Below, define all the tools to be used by your different teams.\n",
    "\n",
    "We'll start with the research team.\n",
    "\n",
    "**ResearchTeam tools**\n",
    "\n",
    "The research team can use a search engine and url scraper to find information on the web. Feel free to add additional functionality below to boost the team performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024eb89-843d-4cc3-ab3f-e1eb4d031179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.477064Z",
     "start_time": "2024-05-15T08:19:42.397083Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from web_scraper import scrape_webpages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c427982-fadf-4721-a77e-2465df9fc6bc",
   "metadata": {},
   "source": [
    "**Document writing team tools**\n",
    "\n",
    "Next up, we will give some tools for the doc writing team to use.\n",
    "We define some bare-bones file-access tools below.\n",
    "\n",
    "Note that this gives the agents access to your file-system, which can be unsafe. We also haven't optimized the tool descriptions for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ee1c6-2b6a-439d-9046-df54e1e15698",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "We are going to create a few utility functions to make it more concise when we want to:\n",
    "\n",
    "1. Create a worker agent.\n",
    "2. Create a supervisor for the sub-graph.\n",
    "\n",
    "These will simplify the graph compositional code at the end for us so it's easier to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fb60f-1aac-455b-b67d-8d2e4ccfd747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:46.559082Z",
     "start_time": "2024-05-15T08:19:44.541330Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00282b1f-bb4d-4ee7-9bae-e8e6f586f12e",
   "metadata": {},
   "source": [
    "## Define Agent Teams\n",
    "\n",
    "Now we can get to define our hierarchical teams. \"Choose your player!\"\n",
    "\n",
    "### Research Team\n",
    "\n",
    "The research team will have a search agent and a web scraping \"research_agent\" as the two worker nodes. Let's create those, as well as the team supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db0c78-e357-48ba-ae5f-3fc04735a3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.810290Z",
     "start_time": "2024-05-15T08:19:46.561088Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c6ee8-a461-4081-8a97-a3a06ec0f994",
   "metadata": {},
   "source": [
    "Now that we've created the necessary components, defining their interactions is easy. Add the nodes to the team graph, and define the edges, which determine the transition criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a1260-d9f6-4011-b2b1-13fab5126997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.825649Z",
     "start_time": "2024-05-15T08:19:48.811753Z"
    }
   },
   "outputs": [],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f59bed6134685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.936523Z",
     "start_time": "2024-05-15T08:19:48.827798Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee8f2c-fbde-427b-ba54-ae0c7ce5fbfb",
   "metadata": {},
   "source": [
    "We can give this team work directly. Try it out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b0604-a178-4246-a36f-2dedae606680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.952470Z",
     "start_time": "2024-05-15T08:19:51.937879Z"
    }
   },
   "outputs": [],
   "source": [
    "# for s in research_graph.stream(\n",
    "#     {\"messages\": [(\"user\", \"when is Ed Sheeran's next tour in 2025?\")]},\n",
    "#     config={\"recursion_limit\": 100, \"callbacks\": [langfuse_handler]},\n",
    "#     ):\n",
    "#     print(s)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdbf44-9481-430c-8429-fa142ed8a626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.677722Z",
     "start_time": "2024-05-15T08:19:51.953933Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_file, edit_document, read_file],\n",
    "    prompt=(\n",
    "        \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_file],\n",
    "    prompt=(\n",
    "        \"You can read documents and create outlines for the document writer. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "chart_generating_agent = create_react_agent(\n",
    "    llm, tools=[read_file, python_repl_tool]\n",
    ")\n",
    "\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2cd9b-29aa-458e-903d-4e49179e5d59",
   "metadata": {},
   "source": [
    "With the objects themselves created, we can form the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c644f-8966-4d2e-98d2-80d73520e9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.693123Z",
     "start_time": "2024-05-15T08:19:53.678906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph here\n",
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "paper_writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7d1e48a9c39a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:13.913188Z",
     "start_time": "2024-05-15T08:32:11.598993Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860fd46-c24d-40a5-a6ba-e8fddcd43369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.723467Z",
     "start_time": "2024-05-15T08:19:53.709307Z"
    }
   },
   "outputs": [],
   "source": [
    "# for s in paper_writing_graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             (\n",
    "#                 \"user\",\n",
    "#                 \"Write an outline for poem about cats and then write the poem to disk.\",\n",
    "#             )\n",
    "#         ]\n",
    "#     },\n",
    "#     {\"recursion_limit\": 100, \"callbacks\": [langfuse_handler]},\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5b08d-9a9a-474a-94b4-f7aaa8ff19e6",
   "metadata": {},
   "source": [
    "## Add Layers\n",
    "\n",
    "In this design, we are enforcing a top-down planning policy. We've created two graphs already, but we have to decide how to route work between the two.\n",
    "\n",
    "We'll create a _third_ graph to orchestrate the previous two, and add some connectors to define how this top-level state is shared between the different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfbe34-43f5-4a3d-8e9b-6a1d9b339aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880e573-612f-4d24-97c1-2079382a4a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.469348Z",
     "start_time": "2024-05-15T08:19:55.455831Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the graph.\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ff3ae26cd42ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:33.694459Z",
     "start_time": "2024-05-15T08:32:31.524790Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8badbf-d728-44bd-a2a7-5b4e587c92fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.796497Z",
     "start_time": "2024-05-15T08:19:55.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Research AI agents and write in a file using the writing_team a brief report about them.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150, \"callbacks\": [langfuse_handler]},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

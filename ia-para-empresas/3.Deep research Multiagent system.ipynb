{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276",
   "metadata": {},
   "source": [
    "# Deep research Multiagent system\n",
    "\n",
    "\n",
    "### Original doc:\n",
    "\n",
    "    https://www.youtube.com/watch?v=mjPSkPLbu1s\n",
    "\n",
    "<div style=\"width: 100%; height: 768px; overflow: hidden;\">\n",
    "  <iframe width=\"1024\" height=\"768\" src=\"https://www.youtube.com/embed/mjPSkPLbu1s?si=nrN8Y4pnHNAj-5WZ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.364369Z",
     "start_time": "2024-05-15T08:19:42.359273Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --upgrade pip langgraph langchain_community langchain_anthropic langchain-tavily langchain_experimental langchain_ollama mcp langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c2f3de-c730-4aec-85a6-af2c2f058803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:42.395571Z",
     "start_time": "2024-05-15T08:19:42.365662Z"
    }
   },
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# load environment variables from .env file\n",
    "load_dotenv()\n",
    "workfolder = os.getenv('WORKFOLDER')\n",
    "mcp_file_path = os.getenv('MCP_SRV_PATH')\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler() \n",
    "llm_config = {\"configurable\": {\"thread_id\": \"abc123\"}, \"recursion_limit\": 20, \"callbacks\": [langfuse_handler]}\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd0c4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='get_current_time', description='Returns current system time.', args_schema={'description': 'Returns current system time.', 'properties': {}, 'title': 'get_current_time', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7a54c2203ba0>),\n",
       " StructuredTool(name='read_file', description='Read content from a file.', args_schema={'description': 'Read content from a file.', 'properties': {'file_path': {'description': 'Path to the file to read', 'title': 'File Path', 'type': 'string'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}, 'start': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 0, 'description': 'The start line. Default is 0', 'title': 'Start'}, 'end': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'The end line. Default is None', 'title': 'End'}}, 'required': ['file_path'], 'title': 'read_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7a5476e771a0>),\n",
       " StructuredTool(name='write_file', description='Writes text content to a file in append or overwrite mode.', args_schema={'description': 'Writes text content to a file in append or overwrite mode.', 'properties': {'content': {'description': 'The content to be written to the file.', 'title': 'Content', 'type': 'string'}, 'file_path': {'description': 'The path to the file where content will be written.', 'title': 'File Path', 'type': 'string'}, 'append': {'description': 'If True, append to the file; if False, overwrite it.', 'title': 'Append', 'type': 'boolean'}, 'encoding': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': 'utf-8', 'description': 'The encoding of the file.', 'title': 'Encoding'}}, 'required': ['content', 'file_path', 'append'], 'title': 'write_file', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7a5474edba60>),\n",
       " StructuredTool(name='execute_bash', description='Execute a bash command.', args_schema={'description': 'Execute a bash command.', 'properties': {'command': {'description': 'The bash command to execute', 'title': 'Command', 'type': 'string'}, 'timeout': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': 60, 'description': 'Timeout in seconds.', 'title': 'Timeout'}}, 'required': ['command'], 'title': 'execute_bash', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7a5474edb600>),\n",
       " TavilySearch(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"mcp\": {\n",
    "            \"command\": \"python\",\n",
    "            # Make sure to update to the full absolute path to your math_server.py file\n",
    "            \"args\": [mcp_file_path],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        # \"weather\": {\n",
    "        #     # make sure you start your weather server on port 8000\n",
    "        #     \"url\": \"http://localhost:8000/mcp/\",\n",
    "        #     \"transport\": \"streamable_http\",\n",
    "        # }\n",
    "    }\n",
    ")\n",
    "tools = await client.get_tools()\n",
    "tools.append(TavilySearch())\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fed548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Build a Multi-Agent Deep Research System\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to build a Multi-Agent Deep Research System. Let me start by understanding what that entails. A multi-agent system typically involves multiple autonomous agents that interact to achieve a common goal. Deep research might refer to using deep learning techniques or extensive data analysis. \n",
      "\n",
      "First, I need to break down the components. Maybe the user is looking for a system that combines multiple AI agents, each specialized in different tasks, working together. They might want to integrate deep learning models for data processing and analysis.\n",
      "\n",
      "I should consider the tools available. The tavily_search function can help find relevant information on current research and existing systems. Using it with the right parameters could provide up-to-date resources. Also, checking if there are any recent papers or articles on multi-agent systems with deep learning.\n",
      "\n",
      "Wait, the user might need guidance on architecture, coordination between agents, data handling, and evaluation methods. Maybe they need to know about frameworks or libraries that support such systems. I should generate questions that cover these aspects to ensure the system is comprehensive.\n",
      "\n",
      "I should also think about potential challenges, like communication between agents, avoiding redundancy, and ensuring scalability. Including questions on these topics would help address possible issues. Maybe the user is a researcher or developer looking to implement this, so practical steps and resources would be valuable.\n",
      "\n",
      "I need to make sure the questions cover both theoretical and practical aspects. Let me list possible questions: defining the system's goals, selecting appropriate agents, integrating deep learning models, data management strategies, coordination mechanisms, evaluation metrics, handling failures, scalability, existing tools, and ethical considerations. That should cover the main areas.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  tavily_search (da256ce6-f09d-4dac-a039-4b3266d3a729)\n",
      " Call ID: da256ce6-f09d-4dac-a039-4b3266d3a729\n",
      "  Args:\n",
      "    include_domains: ['arxiv.org', 'research.google.com']\n",
      "    query: Multi-Agent Deep Research System architecture\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "  tavily_search (3141fe9b-924d-40c4-aa49-cf651a801a2d)\n",
      " Call ID: 3141fe9b-924d-40c4-aa49-cf651a801a2d\n",
      "  Args:\n",
      "    include_domains: ['ai.googleblog.com', 'medium.com']\n",
      "    query: Collaborative AI agents for deep research\n",
      "    search_depth: advanced\n",
      "    time_range: month\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"Collaborative AI agents for deep research\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://medium.com/@fahey_james/the-state-of-ai-agents-agent-teams-oct-2025-27d7dac01667\", \"title\": \"The State of AI Agents & Agent Teams (Oct 2025)\", \"content\": \"6) What to choose right now (quick guidance)\\n\\n• Greenfield, want fastest path to value: Start with OpenAI Apps SDK/AgentKit + MCP for speed and rich UI; add Deep Research for long-horizon tasks.\\n\\n• Google Cloud shop, heavy browser workflows: Gemini 2.5 Computer Use + Vertex AI Agent Builder / Gemini Enterprise.\\n\\n• Azure-first enterprise: Microsoft Agent Framework + Azure AI Foundry Agent Service, enable Deep Research in the same runtime. [...] • Microsoft Agent Framework (open source) + Azure AI Foundry Agent Service give a full development-to-production path; Azure has first-party “Deep Research” and strong governance/observability.\\n\\nGood fit: enterprises on Azure/M365 that need identity, networking, compliance, and multi-agent observability out of the box.\\n\\nAmazon Web Services [...] • Microsoft Agent Framework (open source) unifies ideas from Semantic Kernel and AutoGen with production runtimes for multi-agent deployments.\\n\\nC. Enterprise agent platforms\\n\\nWhen you need SSO, observability, policies, evaluation, and scale:\\n\\n• Azure AI Foundry Agent Service: managed runtime for building, debugging, governing, and shipping agents as micro-services, with “Deep Research” now offered in-platform.\", \"score\": 0.62934244, \"raw_content\": null}, {\"url\": \"https://medium.com/@kanerika/multi-agent-workflows-a-practical-guide-to-design-tools-and-deployment-3b0a2c46e389\", \"title\": \"Multi-Agent Workflows: A Practical Guide to Design, Tools ...\", \"content\": \"At Kanerika, we bring deep expertise in agentic AI and advanced AI/ML solutions that help businesses across industries move faster, work smarter, and achieve measurable results. From manufacturing to retail, finance, and healthcare, our purpose-built AI agents and custom generative AI models are already transforming how companies overcome bottlenecks and streamline operations. [...] ADK offers a powerful solution for building intricate, collaborative agent systems within a well-defined framework.\\n\\n### 2. LlamaIndex Multi-Agent\\n\\nAgentWorkflow is itself a Workflow pre-configured to understand agents, state and tool-calling.\\n\\n### 3. OpenAI Swarm\\n\\nSwarm currently operates via a single-agent control loop, making it more suitable for lightweight experiments.\\n\\n## Framework Selection Decision Matrix [...] 1. Collaborative Systems\\n\\nIn this example, different agents collaborate on a shared scratchpad of messages. This means that all the work either of them do is visible to the other. Think of it like a shared Google Doc where team members can see everyone’s contributions and edit together. This collaborative approach works well for research projects or content creation where transparency matters.\", \"score\": 0.4813325, \"raw_content\": null}, {\"url\": \"https://medium.com/google-cloud/give-your-ai-agents-deep-understanding-coding-the-multi-agent-adk-solution-041e844cdebb\", \"title\": \"Give Your AI Agents Deep Understanding — Coding the ...\", \"content\": \"ask for theabsolute path to the repository/folder, and optionally an output path.Here's the detailed process you should follow:1.  Discover Files: Use the `discover_files` tool with the provided `repo_path` to get a list of all    relevant files paths, in the return value `files`.2.  Check Files List: Check you received a success response and a list of files.    If not, you should provide an appropriate response to the user and STOP HERE.3.  Summarize Files: Delegate to the [...] process is as follows:1.  File Reading: The `file_reader_agent` reads the content of specified    files, storing the content in the session state.2.  Content Summarization: The `content_summariser_agent` takes the    collected file content and performs two key tasks:    - It generates a concise summary for each individual file.    - It generates a higher-level summary for the entire project based on the      content of all files.The final output is a single JSON object containing both the [...] files, you MUST also provide an overall project summary, in no more than three paragraphs. - The project summary should be a high-level overview of the repository/folder, based on the content of the files.- Focus on the content that is helpful for understanding the purpose of the project and the core components.- The project summary MUST be stored in the same output JSON object with the key 'project'.   This is CRITICAL for the overall understanding of the repository.# Output Format- The JSON\", \"score\": 0.47270843, \"raw_content\": null}, {\"url\": \"https://medium.com/@daniel.lozovsky/how-17-agentic-ai-patterns-are-actually-building-the-future-of-intelligent-systems-df9d5d329f0b\", \"title\": \"How 17 Agentic AI Patterns Are Actually Building ...\", \"content\": \"That’s why smart organizations are moving beyond single-agent systems to what researchers call agentic architectures — patterns where multiple specialized AI agents work together, each focusing on what they do best.\\n\\n## The 17 Patterns That Actually Matter\\n\\nThrough extensive research and real-world implementation, several distinct patterns have emerged. Each one solves a different problem in how AI systems think, act, and collaborate.\\n\\n## Pattern 1: Reflection — Making AI Self-Critical [...] I tested this with complex research tasks. A simple tool-using agent might make one search and try to answer. A ReAct agent makes multiple searches, uses the information from each search to inform the next one, and builds up a comprehensive understanding step by step.\\n\\nThe difference in quality is dramatic. For multi-step research tasks, ReAct patterns scored 8–9/10 compared to 5–6/10 for single-step systems.\\n\\n## Pattern 4: Planning — Mapping the Route Before Starting [...] I’ve spent the last few months diving deep into how companies are actually building these systems. And what I found surprised me. The organizations getting 10–25% EBITDA gains aren’t using some secret AI model. They’re using specific architectural patterns that make AI agents work together like a well-orchestrated team.\", \"score\": 0.45769477, \"raw_content\": null}, {\"url\": \"https://medium.com/@angelaf_56127/under-the-radar-weekly-top-5-ai-agents-in-prompt-engineering-out-october-10-2025-775be6218b92\", \"title\": \"Under the Radar | Weekly Top 5: AI Agents In, Prompt ...\", \"content\": \"Technology professional since the mid 80s. Founder of The Open Record. Exploring human-AI collaboration through transparent research and open dialogue.\\n\\n## No responses yet\\n\\nWrite a response\\n\\nWhat are your thoughts?\\n\\n## More from Angela Fisher\\n\\nAngela Fisher\\n\\n## The 2042 Convergence\\n\\n### How Policy Choices Are Engineering a Social Catastrophe\\n\\nSep 25\\n\\n6\\n\\n1\\n\\nAngela Fisher\\n\\n## Epstein had a Global Network. Not just a plane and an Island. [...] Every week, we will bring you the Top 5 most in-demand opportunities. We will present one deep dive, replace old titles with fresh new ones if the data changes, and include at least one entry level path. Careers and jobs can change faster than people are accustomed to. This week’s golden opportunity could be next week’s lead balloon. The data is current as of October 9, 2025 and subject to change. [...] DISCLAIMER: The information in this article is for educational and informational purposes only. Results may vary significantly based on individual circumstances, skills, location, and market conditions. This guide does not guarantee employment, income, or success in any field. Job markets change rapidly, and salary ranges are estimates that may not reflect current or future conditions. Always conduct your own research, consult with career professionals, and verify all information before making\", \"score\": 0.36779293, \"raw_content\": null}], \"response_time\": 3.53, \"request_id\": \"ca391f9b-79ee-499d-9c3b-fda211d63dc1\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this. The user wants me to act as a topic analyzer. The task is to search the given topic on the internet using the provided tools, then generate a list of questions that cover the topic. The output should be in JSON format with the topic and an array of questions.\n",
      "\n",
      "First, I need to understand the topic. The user provided a query: \"Collaborative AI agents for deep research\". So, the main focus is on collaborative AI agents, specifically in the context of deep research. \n",
      "\n",
      "Looking at the tools available, the most relevant one is the tavily_search function. It allows me to perform a search with various parameters. The user's query might need recent information, so I should check the time range. The results from the previous response include articles from October 2025, which is a future date. Wait, that's odd. Maybe there's a typo? But assuming the data is correct, perhaps the search was done in a future context. Anyway, I need to use the tavily_search function to gather information on collaborative AI agents for deep research.\n",
      "\n",
      "I should structure the search query properly. The main topic is collaborative AI agents for deep research. The parameters for tavily_search include query, search_type, and maybe time_range. Since the user's initial query didn't specify a time frame, I'll use the default. However, the previous results had articles from October 2025, which might be a placeholder. Maybe the user's example is using a future date for demonstration. \n",
      "\n",
      "Next, after performing the search, I need to analyze the results. The articles mention things like OpenAI Apps SDK, Microsoft Agent Framework, Azure AI Foundry, and various patterns like ReAct and Planning. These are all related to collaborative AI agents. The key points are the tools and frameworks used, the benefits of collaboration, specific patterns that enhance research, and enterprise solutions.\n",
      "\n",
      "Now, generating questions. The user wants questions that cover the topic. So, I should think about different aspects: tools and frameworks, collaboration benefits, specific patterns, challenges, case studies, future trends, and implementation steps. Each of these areas can form a question. For example, \"What are the key tools and frameworks used in collaborative AI agents for deep research?\" or \"What are the benefits of using collaborative AI agents in research projects?\"\n",
      "\n",
      "I need to ensure the questions are comprehensive and cover various dimensions of the topic. Also, considering the previous search results, the questions should reflect the content found, like the mention of Azure, Microsoft, and specific patterns. \n",
      "\n",
      "Wait, the user's example response had a list of questions, so I should follow that structure. Let me list out possible questions based on the information from the search results. For instance, the first article talks about starting with OpenAI Apps SDK and Microsoft's solutions. So a question about the best practices for setting up collaborative AI agents. Another article mentions the ReAct pattern, so a question on that. Also, the need for governance and observability in enterprise settings. \n",
      "\n",
      "I should make sure each question is distinct and covers different aspects. Maybe 5-7 questions. Let me check the previous example's answer. The user's example had 5 questions, so maybe that's a good number. \n",
      "\n",
      "Putting it all together, the JSON should have the topic as \"Collaborative AI Agents for Deep Research\" and the questions array with the generated questions. I need to make sure the questions are clear and relevant to the topic, based on the search results provided.\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"topic\": \"Collaborative AI Agents for Deep Research\",\n",
      "  \"questions\": [\n",
      "    \"What are the key tools and frameworks currently used to develop collaborative AI agents for deep research?\",\n",
      "    \"How do collaborative AI agents enhance the efficiency and depth of research compared to single-agent systems?\",\n",
      "    \"What are the most effective architectural patterns (e.g., ReAct, Planning) for enabling collaboration among AI agents in research tasks?\",\n",
      "    \"What challenges arise when implementing collaborative AI agents for complex, long-horizon research projects, and how are they addressed?\",\n",
      "    \"How do enterprise platforms like Azure AI Foundry and Microsoft Agent Framework support the deployment of collaborative AI agents with governance and observability?\",\n",
      "    \"What role does multi-agent communication and shared state management play in successful deep research workflows?\",\n",
      "    \"What are the best practices for integrating collaborative AI agents with existing research infrastructure and workflows?\"\n",
      "  ]\n",
      "}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: topic_analizer\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this. The user wants me to act as a topic analyzer. The task is to search the given topic on the internet using the provided tools, then generate a list of questions that cover the topic. The output should be in JSON format with the topic and an array of questions.\n",
      "\n",
      "First, I need to understand the topic. The user provided a query: \"Collaborative AI agents for deep research\". So, the main focus is on collaborative AI agents, specifically in the context of deep research. \n",
      "\n",
      "Looking at the tools available, the most relevant one is the tavily_search function. It allows me to perform a search with various parameters. The user's query might need recent information, so I should check the time range. The results from the previous response include articles from October 2025, which is a future date. Wait, that's odd. Maybe there's a typo? But assuming the data is correct, perhaps the search was done in a future context. Anyway, I need to use the tavily_search function to gather information on collaborative AI agents for deep research.\n",
      "\n",
      "I should structure the search query properly. The main topic is collaborative AI agents for deep research. The parameters for tavily_search include query, search_type, and maybe time_range. Since the user's initial query didn't specify a time frame, I'll use the default. However, the previous results had articles from October 2025, which might be a placeholder. Maybe the user's example is using a future date for demonstration. \n",
      "\n",
      "Next, after performing the search, I need to analyze the results. The articles mention things like OpenAI Apps SDK, Microsoft Agent Framework, Azure AI Foundry, and various patterns like ReAct and Planning. These are all related to collaborative AI agents. The key points are the tools and frameworks used, the benefits of collaboration, specific patterns that enhance research, and enterprise solutions.\n",
      "\n",
      "Now, generating questions. The user wants questions that cover the topic. So, I should think about different aspects: tools and frameworks, collaboration benefits, specific patterns, challenges, case studies, future trends, and implementation steps. Each of these areas can form a question. For example, \"What are the key tools and frameworks used in collaborative AI agents for deep research?\" or \"What are the benefits of using collaborative AI agents in research projects?\"\n",
      "\n",
      "I need to ensure the questions are comprehensive and cover various dimensions of the topic. Also, considering the previous search results, the questions should reflect the content found, like the mention of Azure, Microsoft, and specific patterns. \n",
      "\n",
      "Wait, the user's example response had a list of questions, so I should follow that structure. Let me list out possible questions based on the information from the search results. For instance, the first article talks about starting with OpenAI Apps SDK and Microsoft's solutions. So a question about the best practices for setting up collaborative AI agents. Another article mentions the ReAct pattern, so a question on that. Also, the need for governance and observability in enterprise settings. \n",
      "\n",
      "I should make sure each question is distinct and covers different aspects. Maybe 5-7 questions. Let me check the previous example's answer. The user's example had 5 questions, so maybe that's a good number. \n",
      "\n",
      "Putting it all together, the JSON should have the topic as \"Collaborative AI Agents for Deep Research\" and the questions array with the generated questions. I need to make sure the questions are clear and relevant to the topic, based on the search results provided.\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"topic\": \"Collaborative AI Agents for Deep Research\",\n",
      "  \"questions\": [\n",
      "    \"What are the key tools and frameworks currently used to develop collaborative AI agents for deep research?\",\n",
      "    \"How do collaborative AI agents enhance the efficiency and depth of research compared to single-agent systems?\",\n",
      "    \"What are the most effective architectural patterns (e.g., ReAct, Planning) for enabling collaboration among AI agents in research tasks?\",\n",
      "    \"What challenges arise when implementing collaborative AI agents for complex, long-horizon research projects, and how are they addressed?\",\n",
      "    \"How do enterprise platforms like Azure AI Foundry and Microsoft Agent Framework support the deployment of collaborative AI agents with governance and observability?\",\n",
      "    \"What role does multi-agent communication and shared state management play in successful deep research workflows?\",\n",
      "    \"What are the best practices for integrating collaborative AI agents with existing research infrastructure and workflows?\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool \n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "You are a topic analizer. \n",
    "1. search the topic in the Internet\n",
    "2. using the results generate questions that, together, cover the topic.\n",
    "output format (json): {\"topic\": \"\",  \"questions\": [ \"\", ... ]}\n",
    "\"\"\"\n",
    "  # Create the agent\n",
    "topic_analizer = create_react_agent(name=\"topic_analizer\", model=ChatOllama(model=\"qwen3\"), \n",
    "    tools=tools, response_format='json', prompt=system_prompt)\n",
    "\n",
    "input_message = {\"role\": \"user\", \"content\": \"Build a Multi-Agent Deep Research System\"}\n",
    "\n",
    "# Use the agent\n",
    "for step in topic_analizer.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "240354bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "{\"topic\": \"How to build a Multi-Agent Deep Research System\", \"questions\": [ \n",
      "{\"question\": \"What is the core architecture of a Multi-Agent Deep Research System?\"}, \n",
      "{\"question\": \"What tools are essential for multi-agent research execution?\"}, \n",
      "{\"question\": \"How to implement a multi-agent research workflow?\"}]}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: search_agent\n",
      "\n",
      "<think>\n",
      "Okay, let's tackle this query about building a Multi-Agent Deep Research System. The user has three questions: core architecture, essential tools, and implementing the workflow.\n",
      "\n",
      "First, I need to understand what a Multi-Agent Deep Research System is. From what I know, multi-agent systems involve multiple interacting agents, and deep research might relate to using deep learning techniques. So the core architecture probably involves agent communication, coordination mechanisms, and integration with deep learning models.\n",
      "\n",
      "For the first question, I should look up existing architectures in multi-agent systems and how they're adapted for deep research. Maybe there are papers or frameworks that outline this. I'll need to search for terms like \"core architecture multi-agent deep research system\" to find relevant sources.\n",
      "\n",
      "The second question is about essential tools. Tools could include frameworks like TensorFlow or PyTorch for deep learning, communication libraries like ROS or Message Passing Interface (MPI), and maybe simulation environments like Unity or Gazebo. I should search for toolkits or libraries specifically mentioned in multi-agent research contexts.\n",
      "\n",
      "Third question is about implementing the workflow. This might involve steps like defining agent roles, setting up communication protocols, integrating deep learning models, and testing. I need to find guides or tutorials on implementing such systems. Searching for \"multi-agent research workflow implementation\" could yield some resources.\n",
      "\n",
      "I should use the tavily_search function for each question. Let me structure each search query properly. For the first question, the query would be \"core architecture of a Multi-Agent Deep Research System\". For the second, \"essential tools for multi-agent research execution\". Third, \"how to implement a multi-agent research workflow\".\n",
      "\n",
      "I need to make sure the search parameters are set correctly. Since the user is asking about current methods and tools, maybe set the time_range to \"year\" to get the latest information. Also, check if there are any specific domains to include or exclude. Since it's about research systems, including academic sources might be important, so include_domains could be set to [\"arxiv.org\", \"researchgate.net\"] or similar. But the user hasn't specified, so maybe leave it as default unless the search results are too broad.\n",
      "\n",
      "Wait, the tools function allows for include_domains. Maybe adding academic domains would help find more relevant papers or resources. Alternatively, if the user is looking for practical tools, including domains like GitHub or specific ML frameworks' sites might be better. But without specific info, I'll proceed with default parameters unless the search results aren't sufficient.\n",
      "\n",
      "Also, the search_depth should be \"advanced\" since the topic is complex and requires in-depth information. That's the default, so no need to change. Time_range might be set to \"year\" to ensure the latest tools and methods are included. Let me adjust that for each query.\n",
      "\n",
      "Putting it all together, for each question, I'll call tavily_search with the respective query, time_range set to \"year\", and search_depth as \"advanced\". That should provide comprehensive and up-to-date results.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  tavily_search (c4c247eb-63f3-45e9-baab-08876ce06c87)\n",
      " Call ID: c4c247eb-63f3-45e9-baab-08876ce06c87\n",
      "  Args:\n",
      "    query: core architecture of a Multi-Agent Deep Research System\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "  tavily_search (efb60f57-d853-4b10-af0b-8f1410c9f81c)\n",
      " Call ID: efb60f57-d853-4b10-af0b-8f1410c9f81c\n",
      "  Args:\n",
      "    query: essential tools for multi-agent research execution\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "  tavily_search (bf7af532-f394-4477-95c9-6f5c801cb9d1)\n",
      " Call ID: bf7af532-f394-4477-95c9-6f5c801cb9d1\n",
      "  Args:\n",
      "    query: how to implement a multi-agent research workflow\n",
      "    search_depth: advanced\n",
      "    time_range: year\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"how to implement a multi-agent research workflow\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.anthropic.com/engineering/built-multi-agent-research-system\", \"title\": \"How we built our multi-agent research system - Anthropic\", \"content\": \"Process diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any [...] Subagent output to a filesystem to minimize the ‘game of telephone.’Direct subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. [...] 3.   Scale effort to query complexity.Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries,\", \"score\": 0.8029425, \"raw_content\": null}, {\"url\": \"https://medium.com/cwan-engineering/building-multi-agent-systems-with-langgraph-04f90f312b8e\", \"title\": \"Building Multi-Agent Systems with LangGraph - Medium\", \"content\": \"The researcher agent is just the first step in building a comprehensive multi-agent system. In future articles, we’ll explore:\\n\\n1. Building a Critic Agent to evaluate and challenge the researcher’s findings\\n2. Creating a Writer Agent to synthesize information into cohesive content\\n3. Implementing a Coordinator Agent to manage workflow between agents\\n4. Developing advanced routing logic for more dynamic agent interactions [...] This structured format makes it easier for subsequent agents (like critics and writers) to process and build upon the researcher’s findings.\\n\\n### A More Robust Research Workflow\\n\\nWith our enhanced researcher agent, we can create a more robust workflow:\\n\\nWe implement this workflow with a specialized state type: [...] The Critic Agent serves critical functions in a multi-agent workflow:\\n\\n1. Quality Assurance: Identifies inaccuracies, gaps, or flaws in the research\\n2. Bias Detection: Highlights potential biases in the provided information\\n3. Completeness Check: Ensures all aspects of a topic are adequately covered\\n4. Alternative Perspectives: Introduces different viewpoints or interpretations\\n5. Constructive Feedback: Provides actionable suggestions for improvement\\n\\n### Modern Implementation with LangGraph\", \"score\": 0.7890553, \"raw_content\": null}, {\"url\": \"https://trilogyai.substack.com/p/multi-agent-deep-research-architecture\", \"title\": \"Multi-Agent Deep Research Architecture\", \"content\": \"conversations. A possible workflow: the Researcher agent dumps all found info into a shared document; the Analyst agent reads it and creates an outline; the Writer agent fills out the outline. This could be more efficient than a single agent doing everything sequentially, and it mirrors the way complex reports are often produced by teams. The outcome might be more reliable too, since each agent double-checks or supplements the others. [...] Another innovative workflow is to use a hierarchical reasoning approach. Instead of a linear loop, the agent could recursively break down the problem into a tree of sub-problems (a methodology sometimes called “Tree of Thoughts”). For instance, the top-level question is split into sub-questions A, B, C. Then each of those might be further split, and leaf nodes (specific factual questions) are answered by searching. The intermediate nodes then synthesize their children’s answers, and finally the [...] ### Multi-Agent Collaboration and Role Assignment\\n\\nTaking inspiration from human teams, a custom system could implement multiple agents with distinct roles that collaborate on research and synthesis. For example:\", \"score\": 0.78054583, \"raw_content\": null}, {\"url\": \"https://docs.typingmind.com/ai-agents/build-multi-agent-workflows\", \"title\": \"Build Multi-Agent Workflows - TypingMind Docs\", \"content\": \"## How to use Multi-Agent Workflows on TypingMind?\\n\\nTypingMind simplifies creating and managing multi-agent workflows. Here’s how you can get started:\\n\\n### Step 1: Build an AI Agent\\n\\nYou can start by creating a new AI Agent on TypingMind:\\n\\n Provide custom system instruction to guide the AI Agent behavior.\\n\\n Assign a base model for the AI Agent to make sure you will get the optimized results from the most appropriate AI model. [...] Large projects includes multiple stakeholders, deadlines, and deliverables. Multi-Agent Workflows help manage and coordinate effectively:\\n\\n Task Allocator: break down the project into tasks and assigns them to the right team members.\\n\\n Timeline Coordinator: set deadlines and monitors progress.\\n\\n Risk Manager: identify risks and suggests solutions.\\n\\n Progress Reporter: compile status updates and generates reports.Example: \\\"Summarize the weekly progress report for the product launch.\\\"\\n\\n```\\n\\njson [...] By delegating tasks to specialized AI agents, businesses can eliminate bottlenecks, improve accuracy, and accelerate their workflows.\\n\\nHowever, building such workflows often requires significant time, resources, and technical expertise. This can be a barrier for many teams.\\n\\nFortunately, TypingMind provides a no-code solution for creating and managing multi-agent workflows, make it accessible and easy to implement for everyone. Let’s see how it works via TypingMind.\", \"score\": 0.7730283, \"raw_content\": null}, {\"url\": \"https://www.langflow.org/blog/how-to-build-a-deep-research-multi-agent-system\", \"title\": \"How to Build a Deep-Research Multi‑Agent System | Langflow\", \"content\": \"1.   Add a `Chat Input`\\n2.   Add 5 agents and fill in your API keys\\n3.   Give your agents the right tools: \\n       The research agent gets the Web Search tool to find the right sources, and\\n       The summarizer agent gets the URL component as a tool to read the contents of sources and summarize them. Be sure to turn \\\"tool mode\\\" to on on the URL component. [...] ` and build the flow. You can either start by dragging and dropping this JSON file into your project, or by manually building the flow yourself. Either way, the flow will end up looking something like this:Image 4: The final Multi-Agent System\\n\\nThe final Multi-Agent System\\n\\nTo manually build the flow, follow these steps: [...] 1.   Keep outputs structured: given that we have many agents that talk to each other, it's critical that we do not end up with a game of broken telephone. A great way to mitigate against this is to work with data as structured as possible, even working with JSON/DataFrames if/where you can.\", \"score\": 0.71185225, \"raw_content\": null}], \"response_time\": 1.98, \"request_id\": \"a09db70c-3c90-4940-bb73-54279e353d4c\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: search_agent\n",
      "\n",
      "<think>\n",
      "Okay, the user asked about implementing a multi-agent research workflow. Let me break down the information from the provided search results to create a helpful answer.\n",
      "\n",
      "First, the Anthropic article mentions a LeadResearcher agent that creates a plan and uses subagents. They emphasize saving the plan in memory to handle token limits. Subagents can output directly to a filesystem to avoid information loss. Also, scaling rules are embedded in prompts based on task complexity. That's important for resource allocation.\n",
      "\n",
      "The Medium article talks about expanding the system with Critic, Writer, and Coordinator agents. The Critic checks for quality, bias, and completeness. The Writer synthesizes info, and the Coordinator manages workflow. Structured state types help subsequent agents process findings efficiently.\n",
      "\n",
      "TrilogyAI's Substack post suggests a hierarchical approach, like a Tree of Thoughts, breaking problems into sub-problems. They also mention role-based agents, such as Researcher, Analyst, and Writer, working in parallel to improve reliability through cross-checking.\n",
      "\n",
      "TypingMind's documentation provides a practical guide with steps to build agents, assign tools, and manage workflows. They mention task allocation, timeline coordination, risk management, and progress reporting. The no-code solution is a big plus for teams without technical expertise.\n",
      "\n",
      "Langflow's blog explains setting up agents with specific tools, like Web Search and URL components for summarizing. Structured outputs using JSON or DataFrames are recommended to prevent the \"game of telephone.\"\n",
      "\n",
      "Putting this together, the answer should outline key components: LeadResearcher with subagents, structured workflows, role-specific agents (Critic, Writer, Coordinator), hierarchical reasoning, and tools for managing complexity. Also, mention platforms like TypingMind and Langflow that offer tools or frameworks to implement these workflows. Highlight the importance of structured data, memory persistence, and scaling rules. Make sure to note the benefits like improved accuracy, efficiency, and collaboration.\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"question\": \"how to implement a multi-agent research workflow\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"url\": \"https://www.anthropic.com/engineering/built-multi-agent-research-system\",\n",
      "      \"title\": \"How we built our multi-agent research system - Anthropic\",\n",
      "      \"content\": \"Process diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any [...] Subagent output to a filesystem to minimize the ‘game of telephone.’Direct subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. [...] 3.   Scale effort to query complexity.Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries,\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://medium.com/cwan-engineering/building-multi-agent-systems-with-langgraph-04f90f312b8e\",\n",
      "      \"title\": \"Building Multi-Agent Systems with LangGraph - Medium\",\n",
      "      \"content\": \"The researcher agent is just the first step in building a comprehensive multi-agent system. In future articles, we’ll explore:\\n\\n1. Building a Critic Agent to evaluate and challenge the researcher’s findings\\n2. Creating a Writer Agent to synthesize information into cohesive content\\n3. Implementing a Coordinator Agent to manage workflow between agents\\n4. Developing advanced routing logic for more dynamic agent interactions [...] This structured format makes it easier for subsequent agents (like critics and writers) to process and build upon the researcher’s findings.\\n\\n### A More Robust Research Workflow\\n\\nWith our enhanced researcher agent, we can create a more robust workflow:\\n\\nWe implement this workflow with a specialized state type: [...] The Critic Agent serves critical functions in a multi-agent workflow:\\n\\n1. Quality Assurance: Identifies inaccuracies, gaps, or flaws in the research\\n2. Bias Detection: Highlights potential biases in the provided information\\n3. Completeness Check: Ensures all aspects of a topic are adequately covered\\n4. Alternative Perspectives: Introduces different viewpoints or interpretations\\n5. Constructive Feedback: Provides actionable suggestions for improvement\\n\\n### Modern Implementation with LangGraph\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://trilogyai.substack.com/p/multi-agent-deep-research-architecture\",\n",
      "      \"title\": \"Multi-Agent Deep Research Architecture\",\n",
      "      \"content\": \"conversations. A possible workflow: the Researcher agent dumps all found info into a shared document; the Analyst agent reads it and creates an outline; the Writer agent fills out the outline. This could be more efficient than a single agent doing everything sequentially, and it mirrors the way complex reports are often produced by teams. The outcome might be more reliable too, since each agent double-checks or supplements the others. [...] Another innovative workflow is to use a hierarchical reasoning approach. Instead of a linear loop, the agent could recursively break down the problem into a tree of sub-problems (a methodology sometimes called “Tree of Thoughts”). For instance, the top-level question is split into sub-questions A, B, C. Then each of those might be further split, and leaf nodes (specific factual questions) are answered by searching. The intermediate nodes then synthesize their children’s answers, and finally the [...] ### Multi-Agent Collaboration and Role Assignment\\n\\nTaking inspiration from human teams, a custom system could implement multiple agents with distinct roles that collaborate on research and synthesis. For example:\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://docs.typingmind.com/ai-agents/build-multi-agent-workflows\",\n",
      "      \"title\": \"Build Multi-Agent Workflows - TypingMind Docs\",\n",
      "      \"content\": \"## How to use Multi-Agent Workflows on TypingMind?\\n\\nTypingMind simplifies creating and managing multi-agent workflows. Here’s how you can get started:\\n\\n### Step 1: Build an AI Agent\\n\\nYou can start by creating a new AI Agent on TypingMind:\\n\\n Provide custom system instruction to guide the AI Agent behavior.\\n\\n Assign a base model for the AI Agent to make sure you will get the optimized results from the most appropriate AI model. [...] Large projects includes multiple stakeholders, deadlines, and deliverables. Multi-Agent Workflows help manage and coordinate effectively:\\n\\n Task Allocator: break down the project into tasks and assigns them to the right team members.\\n\\n Timeline Coordinator: set deadlines and monitors progress.\\n\\n Risk Manager: identify risks and suggests solutions.\\n\\n Progress Reporter: compile status updates and generates reports.Example: \\\"Summarize the weekly progress report for the product launch.\\\"\\n\\n```\\n\\njson [...] By delegating tasks to specialized AI agents, businesses can eliminate bottlenecks, improve accuracy, and accelerate their workflows.\\n\\nHowever, building such workflows often requires significant time, resources, and technical expertise. This can be a barrier for many teams.\\n\\nFortunately, TypingMind provides a no-code solution for creating and managing multi-agent workflows, make it accessible and easy to implement for everyone. Let’s see how it works via TypingMind.\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://www.langflow.org/blog/how-to-build-a-deep-research-multi-agent-system\",\n",
      "      \"title\": \"How to Build a Deep-Research Multi‑Agent System | Langflow\",\n",
      "      \"content\": \"1.   Add a `Chat Input`\\n2.   Add 5 agents and fill in your API keys\\n3.   Give your agents the right tools: \\n       The research agent gets the Web Search tool to find the right sources, and\\n       The summarizer agent gets the URL component as a tool to read the contents of sources and summarize them. Be sure to turn \\\"tool mode\\\" to on on the URL component. [...] ` and build the flow. You can either start by dragging and dropping this JSON file into your project, or by manually building the flow yourself. Either way, the flow will end up looking something like this:Image 4: The final Multi-Agent System\\n\\nThe final Multi-Agent System\\n\\nTo manually build the flow, follow these steps: [...] 1.   Keep outputs structured: given that we have many agents that talk to each other, it's critical that we do not end up with a game of broken telephone. A great way to mitigate against this is to work with data as structured as possible, even working with JSON/DataFrames if/where you can.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: search_agent\n",
      "\n",
      "<think>\n",
      "Okay, the user asked about implementing a multi-agent research workflow. Let me break down the information from the provided search results to create a helpful answer.\n",
      "\n",
      "First, the Anthropic article mentions a LeadResearcher agent that creates a plan and uses subagents. They emphasize saving the plan in memory to handle token limits. Subagents can output directly to a filesystem to avoid information loss. Also, scaling rules are embedded in prompts based on task complexity. That's important for resource allocation.\n",
      "\n",
      "The Medium article talks about expanding the system with Critic, Writer, and Coordinator agents. The Critic checks for quality, bias, and completeness. The Writer synthesizes info, and the Coordinator manages workflow. Structured state types help subsequent agents process findings efficiently.\n",
      "\n",
      "TrilogyAI's Substack post suggests a hierarchical approach, like a Tree of Thoughts, breaking problems into sub-problems. They also mention role-based agents, such as Researcher, Analyst, and Writer, working in parallel to improve reliability through cross-checking.\n",
      "\n",
      "TypingMind's documentation provides a practical guide with steps to build agents, assign tools, and manage workflows. They mention task allocation, timeline coordination, risk management, and progress reporting. The no-code solution is a big plus for teams without technical expertise.\n",
      "\n",
      "Langflow's blog explains setting up agents with specific tools, like Web Search and URL components for summarizing. Structured outputs using JSON or DataFrames are recommended to prevent the \"game of telephone.\"\n",
      "\n",
      "Putting this together, the answer should outline key components: LeadResearcher with subagents, structured workflows, role-specific agents (Critic, Writer, Coordinator), hierarchical reasoning, and tools for managing complexity. Also, mention platforms like TypingMind and Langflow that offer tools or frameworks to implement these workflows. Highlight the importance of structured data, memory persistence, and scaling rules. Make sure to note the benefits like improved accuracy, efficiency, and collaboration.\n",
      "</think>\n",
      "\n",
      "{\n",
      "  \"question\": \"how to implement a multi-agent research workflow\",\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"url\": \"https://www.anthropic.com/engineering/built-multi-agent-research-system\",\n",
      "      \"title\": \"How we built our multi-agent research system - Anthropic\",\n",
      "      \"content\": \"Process diagram showing the complete workflow of our multi-agent Research system. When a user submits a query, the system creates a LeadResearcher agent that enters an iterative research process. The LeadResearcher begins by thinking through the approach and saving its plan to Memory to persist the context, since if the context window exceeds 200,000 tokens it will be truncated and it is important to retain the plan. It then creates specialized Subagents (two are shown here, but it can be any [...] Subagent output to a filesystem to minimize the ‘game of telephone.’Direct subagent outputs can bypass the main coordinator for certain types of results, improving both fidelity and performance. Rather than requiring subagents to communicate everything through the lead agent, implement artifact systems where specialized agents can create outputs that persist independently. Subagents call tools to store their work in external systems, then pass lightweight references back to the coordinator. [...] 3.   Scale effort to query complexity.Agents struggle to judge appropriate effort for different tasks, so we embedded scaling rules in the prompts. Simple fact-finding requires just 1 agent with 3-10 tool calls, direct comparisons might need 2-4 subagents with 10-15 calls each, and complex research might use more than 10 subagents with clearly divided responsibilities. These explicit guidelines help the lead agent allocate resources efficiently and prevent overinvestment in simple queries,\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://medium.com/cwan-engineering/building-multi-agent-systems-with-langgraph-04f90f312b8e\",\n",
      "      \"title\": \"Building Multi-Agent Systems with LangGraph - Medium\",\n",
      "      \"content\": \"The researcher agent is just the first step in building a comprehensive multi-agent system. In future articles, we’ll explore:\\n\\n1. Building a Critic Agent to evaluate and challenge the researcher’s findings\\n2. Creating a Writer Agent to synthesize information into cohesive content\\n3. Implementing a Coordinator Agent to manage workflow between agents\\n4. Developing advanced routing logic for more dynamic agent interactions [...] This structured format makes it easier for subsequent agents (like critics and writers) to process and build upon the researcher’s findings.\\n\\n### A More Robust Research Workflow\\n\\nWith our enhanced researcher agent, we can create a more robust workflow:\\n\\nWe implement this workflow with a specialized state type: [...] The Critic Agent serves critical functions in a multi-agent workflow:\\n\\n1. Quality Assurance: Identifies inaccuracies, gaps, or flaws in the research\\n2. Bias Detection: Highlights potential biases in the provided information\\n3. Completeness Check: Ensures all aspects of a topic are adequately covered\\n4. Alternative Perspectives: Introduces different viewpoints or interpretations\\n5. Constructive Feedback: Provides actionable suggestions for improvement\\n\\n### Modern Implementation with LangGraph\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://trilogyai.substack.com/p/multi-agent-deep-research-architecture\",\n",
      "      \"title\": \"Multi-Agent Deep Research Architecture\",\n",
      "      \"content\": \"conversations. A possible workflow: the Researcher agent dumps all found info into a shared document; the Analyst agent reads it and creates an outline; the Writer agent fills out the outline. This could be more efficient than a single agent doing everything sequentially, and it mirrors the way complex reports are often produced by teams. The outcome might be more reliable too, since each agent double-checks or supplements the others. [...] Another innovative workflow is to use a hierarchical reasoning approach. Instead of a linear loop, the agent could recursively break down the problem into a tree of sub-problems (a methodology sometimes called “Tree of Thoughts”). For instance, the top-level question is split into sub-questions A, B, C. Then each of those might be further split, and leaf nodes (specific factual questions) are answered by searching. The intermediate nodes then synthesize their children’s answers, and finally the [...] ### Multi-Agent Collaboration and Role Assignment\\n\\nTaking inspiration from human teams, a custom system could implement multiple agents with distinct roles that collaborate on research and synthesis. For example:\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://docs.typingmind.com/ai-agents/build-multi-agent-workflows\",\n",
      "      \"title\": \"Build Multi-Agent Workflows - TypingMind Docs\",\n",
      "      \"content\": \"## How to use Multi-Agent Workflows on TypingMind?\\n\\nTypingMind simplifies creating and managing multi-agent workflows. Here’s how you can get started:\\n\\n### Step 1: Build an AI Agent\\n\\nYou can start by creating a new AI Agent on TypingMind:\\n\\n Provide custom system instruction to guide the AI Agent behavior.\\n\\n Assign a base model for the AI Agent to make sure you will get the optimized results from the most appropriate AI model. [...] Large projects includes multiple stakeholders, deadlines, and deliverables. Multi-Agent Workflows help manage and coordinate effectively:\\n\\n Task Allocator: break down the project into tasks and assigns them to the right team members.\\n\\n Timeline Coordinator: set deadlines and monitors progress.\\n\\n Risk Manager: identify risks and suggests solutions.\\n\\n Progress Reporter: compile status updates and generates reports.Example: \\\"Summarize the weekly progress report for the product launch.\\\"\\n\\n```\\n\\njson [...] By delegating tasks to specialized AI agents, businesses can eliminate bottlenecks, improve accuracy, and accelerate their workflows.\\n\\nHowever, building such workflows often requires significant time, resources, and technical expertise. This can be a barrier for many teams.\\n\\nFortunately, TypingMind provides a no-code solution for creating and managing multi-agent workflows, make it accessible and easy to implement for everyone. Let’s see how it works via TypingMind.\"\n",
      "    },\n",
      "    {\n",
      "      \"url\": \"https://www.langflow.org/blog/how-to-build-a-deep-research-multi-agent-system\",\n",
      "      \"title\": \"How to Build a Deep-Research Multi‑Agent System | Langflow\",\n",
      "      \"content\": \"1.   Add a `Chat Input`\\n2.   Add 5 agents and fill in your API keys\\n3.   Give your agents the right tools: \\n       The research agent gets the Web Search tool to find the right sources, and\\n       The summarizer agent gets the URL component as a tool to read the contents of sources and summarize them. Be sure to turn \\\"tool mode\\\" to on on the URL component. [...] ` and build the flow. You can either start by dragging and dropping this JSON file into your project, or by manually building the flow yourself. Either way, the flow will end up looking something like this:Image 4: The final Multi-Agent System\\n\\nThe final Multi-Agent System\\n\\nTo manually build the flow, follow these steps: [...] 1.   Keep outputs structured: given that we have many agents that talk to each other, it's critical that we do not end up with a game of broken telephone. A great way to mitigate against this is to work with data as structured as possible, even working with JSON/DataFrames if/where you can.\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "import json\n",
    "\n",
    "system_prompt = \"\"\" \n",
    "You are a search assistant\n",
    "1. For each question in the topic do an internet search\n",
    "4. Output format json: [{ \"question\": \"\", \"results\": [{ \"url\": \"\", \"title\": \"\" }]}]}\n",
    "\"\"\"\n",
    "  # Create the agent\n",
    "search_agent = create_react_agent(name=\"search_agent\", model=ChatOllama(model=\"qwen3\"), \n",
    "    tools=[TavilySearch()], response_format='json', prompt=system_prompt)\n",
    "\n",
    "content = \"\"\"{\"topic\": \"How to build a Multi-Agent Deep Research System\", \"questions\": [ \n",
    "{\"question\": \"What is the core architecture of a Multi-Agent Deep Research System?\"}, \n",
    "{\"question\": \"What tools are essential for multi-agent research execution?\"}, \n",
    "{\"question\": \"How to implement a multi-agent research workflow?\"}]}\"\"\"\n",
    "input_message = {\"role\": \"user\", \"content\": content,}\n",
    "\n",
    "# Use the agent\n",
    "for step in search_agent.stream(\n",
    "    {\"messages\": [input_message]}, llm_config, stream_mode=\"values\"\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5dc4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.web_operations import scrape_webpages\n",
    "import json\n",
    "\n",
    "summarization_agent = create_agent(\"summarization_agent\", \"qwen3:14b\", [scrape_webpages])\n",
    "content = read_file.invoke('prompts/search_agent_output_example.json')\n",
    "# Convert string to json object\n",
    "content = json.loads(content)\n",
    "\n",
    "for question in content['questions']:\n",
    "    input_message = {\"role\": \"user\", \"content\": json.dumps(question),}\n",
    "\n",
    "    # Use the agent\n",
    "    config = {\"configurable\": {\"thread_id\": \"abc123\"}, \"recursion_limit\": 10, \"callbacks\": [langfuse_handler]}\n",
    "    for step in summarization_agent.stream(\n",
    "        {\"messages\": [input_message]}, config, stream_mode=\"values\"\n",
    "    ):\n",
    "        step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fdd0a3",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354568e2-aef0-4af9-8a79-e64d3eea752f",
   "metadata": {},
   "source": [
    "## Create Tools\n",
    "\n",
    "Each team will be composed of one or more agents each with one or more tools. Below, define all the tools to be used by your different teams.\n",
    "\n",
    "We'll start with the research team.\n",
    "\n",
    "**ResearchTeam tools**\n",
    "\n",
    "The research team can use a search engine and url scraper to find information on the web. Feel free to add additional functionality below to boost the team performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024eb89-843d-4cc3-ab3f-e1eb4d031179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:44.477064Z",
     "start_time": "2024-05-15T08:19:42.397083Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from web_scraper import scrape_webpages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c427982-fadf-4721-a77e-2465df9fc6bc",
   "metadata": {},
   "source": [
    "**Document writing team tools**\n",
    "\n",
    "Next up, we will give some tools for the doc writing team to use.\n",
    "We define some bare-bones file-access tools below.\n",
    "\n",
    "Note that this gives the agents access to your file-system, which can be unsafe. We also haven't optimized the tool descriptions for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504ee1c6-2b6a-439d-9046-df54e1e15698",
   "metadata": {},
   "source": [
    "## Helper Utilities\n",
    "\n",
    "We are going to create a few utility functions to make it more concise when we want to:\n",
    "\n",
    "1. Create a worker agent.\n",
    "2. Create a supervisor for the sub-graph.\n",
    "\n",
    "These will simplify the graph compositional code at the end for us so it's easier to see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fb60f-1aac-455b-b67d-8d2e4ccfd747",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:46.559082Z",
     "start_time": "2024-05-15T08:19:44.541330Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Literal\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "\n",
    "def make_supervisor_node(llm: BaseChatModel, members: list[str]) -> str:\n",
    "    options = [\"FINISH\"] + members\n",
    "    system_prompt = (\n",
    "        \"You are a supervisor tasked with managing a conversation between the\"\n",
    "        f\" following workers: {members}. Given the following user request,\"\n",
    "        \" respond with the worker to act next. Each worker will perform a\"\n",
    "        \" task and respond with their results and status. When finished,\"\n",
    "        \" respond with FINISH.\"\n",
    "    )\n",
    "\n",
    "    class Router(TypedDict):\n",
    "        \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "        next: Literal[*options]\n",
    "\n",
    "    def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "        \"\"\"An LLM-based router.\"\"\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "        ] + state[\"messages\"]\n",
    "        response = llm.with_structured_output(Router).invoke(messages)\n",
    "        goto = response[\"next\"]\n",
    "        if goto == \"FINISH\":\n",
    "            goto = END\n",
    "\n",
    "        return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "    return supervisor_node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00282b1f-bb4d-4ee7-9bae-e8e6f586f12e",
   "metadata": {},
   "source": [
    "## Define Agent Teams\n",
    "\n",
    "Now we can get to define our hierarchical teams. \"Choose your player!\"\n",
    "\n",
    "### Research Team\n",
    "\n",
    "The research team will have a search agent and a web scraping \"research_agent\" as the two worker nodes. Let's create those, as well as the team supervisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db0c78-e357-48ba-ae5f-3fc04735a3b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.810290Z",
     "start_time": "2024-05-15T08:19:46.561088Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "search_agent = create_react_agent(llm, tools=[tavily_tool])\n",
    "\n",
    "\n",
    "def search_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = search_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"search\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "web_scraper_agent = create_react_agent(llm, tools=[scrape_webpages])\n",
    "\n",
    "\n",
    "def web_scraper_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = web_scraper_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"web_scraper\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "research_supervisor_node = make_supervisor_node(llm, [\"search\", \"web_scraper\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c6ee8-a461-4081-8a97-a3a06ec0f994",
   "metadata": {},
   "source": [
    "Now that we've created the necessary components, defining their interactions is easy. Add the nodes to the team graph, and define the edges, which determine the transition criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a1260-d9f6-4011-b2b1-13fab5126997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:48.825649Z",
     "start_time": "2024-05-15T08:19:48.811753Z"
    }
   },
   "outputs": [],
   "source": [
    "research_builder = StateGraph(State)\n",
    "research_builder.add_node(\"supervisor\", research_supervisor_node)\n",
    "research_builder.add_node(\"search\", search_node)\n",
    "research_builder.add_node(\"web_scraper\", web_scraper_node)\n",
    "\n",
    "research_builder.add_edge(START, \"supervisor\")\n",
    "research_graph = research_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f59bed6134685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.936523Z",
     "start_time": "2024-05-15T08:19:48.827798Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(research_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee8f2c-fbde-427b-ba54-ae0c7ce5fbfb",
   "metadata": {},
   "source": [
    "We can give this team work directly. Try it out below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912b0604-a178-4246-a36f-2dedae606680",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:51.952470Z",
     "start_time": "2024-05-15T08:19:51.937879Z"
    }
   },
   "outputs": [],
   "source": [
    "# for s in research_graph.stream(\n",
    "#     {\"messages\": [(\"user\", \"when is Ed Sheeran's next tour in 2025?\")]},\n",
    "#     config={\"recursion_limit\": 100, \"callbacks\": [langfuse_handler]},\n",
    "#     ):\n",
    "#     print(s)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749b99ab-f6f0-4c5d-a90b-10102465d186",
   "metadata": {},
   "source": [
    "### Document Writing Team\n",
    "\n",
    "Create the document writing team below using a similar approach. This time, we will give each agent access to different file-writing tools.\n",
    "\n",
    "Note that we are giving file-system access to our agent here, which is not safe in all cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcdbf44-9481-430c-8429-fa142ed8a626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.677722Z",
     "start_time": "2024-05-15T08:19:51.953933Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"qwen3\")\n",
    "\n",
    "doc_writer_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[write_file, edit_document, read_file],\n",
    "    prompt=(\n",
    "        \"You can read, write and edit documents based on note-taker's outlines. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def doc_writing_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = doc_writer_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"doc_writer\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "note_taking_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[create_outline, read_file],\n",
    "    prompt=(\n",
    "        \"You can read documents and create outlines for the document writer. \"\n",
    "        \"Don't ask follow-up questions.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def note_taking_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = note_taking_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"note_taker\")\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "chart_generating_agent = create_react_agent(\n",
    "    llm, tools=[read_file, python_repl_tool]\n",
    ")\n",
    "\n",
    "\n",
    "def chart_generating_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = chart_generating_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "doc_writing_supervisor_node = make_supervisor_node(\n",
    "    llm, [\"doc_writer\", \"note_taker\", \"chart_generator\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee2cd9b-29aa-458e-903d-4e49179e5d59",
   "metadata": {},
   "source": [
    "With the objects themselves created, we can form the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5c644f-8966-4d2e-98d2-80d73520e9fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.693123Z",
     "start_time": "2024-05-15T08:19:53.678906Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the graph here\n",
    "paper_writing_builder = StateGraph(State)\n",
    "paper_writing_builder.add_node(\"supervisor\", doc_writing_supervisor_node)\n",
    "paper_writing_builder.add_node(\"doc_writer\", doc_writing_node)\n",
    "paper_writing_builder.add_node(\"note_taker\", note_taking_node)\n",
    "paper_writing_builder.add_node(\"chart_generator\", chart_generating_node)\n",
    "\n",
    "paper_writing_builder.add_edge(START, \"supervisor\")\n",
    "paper_writing_graph = paper_writing_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7d1e48a9c39a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:13.913188Z",
     "start_time": "2024-05-15T08:32:11.598993Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(paper_writing_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860fd46-c24d-40a5-a6ba-e8fddcd43369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:53.723467Z",
     "start_time": "2024-05-15T08:19:53.709307Z"
    }
   },
   "outputs": [],
   "source": [
    "# for s in paper_writing_graph.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             (\n",
    "#                 \"user\",\n",
    "#                 \"Write an outline for poem about cats and then write the poem to disk.\",\n",
    "#             )\n",
    "#         ]\n",
    "#     },\n",
    "#     {\"recursion_limit\": 100, \"callbacks\": [langfuse_handler]},\n",
    "# ):\n",
    "#     print(s)\n",
    "#     print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5b08d-9a9a-474a-94b4-f7aaa8ff19e6",
   "metadata": {},
   "source": [
    "## Add Layers\n",
    "\n",
    "In this design, we are enforcing a top-down planning policy. We've created two graphs already, but we have to decide how to route work between the two.\n",
    "\n",
    "We'll create a _third_ graph to orchestrate the previous two, and add some connectors to define how this top-level state is shared between the different graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbfbe34-43f5-4a3d-8e9b-6a1d9b339aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "teams_supervisor_node = make_supervisor_node(llm, [\"research_team\", \"writing_team\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4880e573-612f-4d24-97c1-2079382a4a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.469348Z",
     "start_time": "2024-05-15T08:19:55.455831Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_research_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = research_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"research_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def call_paper_writing_team(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    response = paper_writing_graph.invoke({\"messages\": state[\"messages\"][-1]})\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=response[\"messages\"][-1].content, name=\"writing_team\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the graph.\n",
    "super_builder = StateGraph(State)\n",
    "super_builder.add_node(\"supervisor\", teams_supervisor_node)\n",
    "super_builder.add_node(\"research_team\", call_research_team)\n",
    "super_builder.add_node(\"writing_team\", call_paper_writing_team)\n",
    "\n",
    "super_builder.add_edge(START, \"supervisor\")\n",
    "super_graph = super_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270ff3ae26cd42ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:32:33.694459Z",
     "start_time": "2024-05-15T08:32:31.524790Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(super_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8badbf-d728-44bd-a2a7-5b4e587c92fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T08:19:55.796497Z",
     "start_time": "2024-05-15T08:19:55.796497Z"
    }
   },
   "outputs": [],
   "source": [
    "for s in super_graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\"user\", \"Research AI agents and write in a file using the writing_team a brief report about them.\")\n",
    "        ],\n",
    "    },\n",
    "    {\"recursion_limit\": 150, \"callbacks\": [langfuse_handler]},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

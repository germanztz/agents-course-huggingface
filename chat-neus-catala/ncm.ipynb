{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Pipelieline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index\n",
    "from llama_index.llms.ollama import Ollama \n",
    "from llama_index.core.agent.workflow import ReActAgent, AgentWorkflow, ToolCallResult, AgentStream\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core import SimpleDirectoryReader, Settings\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.ingestion import IngestionPipeline, IngestionCache, DocstoreStrategy\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "# from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "from llama_index.core.schema import TransformComponent\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import chromadb\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import glob\n",
    "import PyPDF2\n",
    "import json\n",
    "import re\n",
    "from typing import ClassVar\n",
    "import torch\n",
    "\n",
    "from llama_index.core.extractors import TitleExtractor, QuestionsAnsweredExtractor\n",
    "from llama_index.core.llama_dataset.legacy.embedding import DEFAULT_QA_GENERATE_PROMPT_TMPL\n",
    "import random\n",
    "\n",
    "\n",
    "data_path = \"./data/\"\n",
    "project_name = \"neus_catala\"\n",
    "embed_model=\"jina/jina-embeddings-v2-base-es\"\n",
    "# embed_model=\"qllama/bge-small-en-v1.5:f16\"\n",
    "# embed_model=\"BAAI/bge-base-en-v1.5\"\n",
    "file_prefix = re.sub('[^A-Za-z0-9]', '_', f\"{project_name}_{embed_model}\")\n",
    "default_path = f\"{data_path}{file_prefix}\"\n",
    "\n",
    "chroma_file = default_path + '_chroma.db' #68MB\n",
    "ingest_cache_file = default_path + \"_cache.json\"\n",
    "\n",
    "from llama_index.core import Settings\n",
    "# Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "Settings.embed_model = OllamaEmbedding(model_name=embed_model)\n",
    "# Settings.llm = Ollama(model=\"qwen2.5:7b-instruct\", base_url=\"http://localhost:11434\") # Funciona de manera satisfactoria\n",
    "Settings.llm = Ollama(model=\"llama3.2:latest\", request_timeout=360.0)\n",
    "\n",
    "\n",
    "db = chromadb.PersistentClient(path=chroma_file)\n",
    "chroma_collection = db.get_or_create_collection(name=project_name)\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "ingest_cache = IngestionCache()\n",
    "if os.path.isfile(ingest_cache_file):\n",
    "    ingest_cache.from_persist_path(ingest_cache_file)\n",
    "\n",
    "\n",
    "class TextCleaner(TransformComponent):\n",
    "\n",
    "    rx_nl: ClassVar  = re.compile(r'(\\n\\s*\\n)')\n",
    "    rx_hyphen: ClassVar  = re.compile(r'(-\\n)')\n",
    "    rx_notdot: ClassVar  = re.compile(r'(?<!\\.)\\n')\n",
    "    rx_num_leter: ClassVar  = re.compile(r'(\\d)([a-zA-Z])')\n",
    "\n",
    "    def __call__(self, nodes, **kwargs):\n",
    "        # nodes = list(map(lambda node: TextCleaner()(node), nodes))\n",
    "        for node in nodes:\n",
    "            text = self.rx_nl.sub('\\n', node.text)\n",
    "            text = self.rx_hyphen.sub('', text)\n",
    "            text = self.rx_notdot.sub(' ', text)\n",
    "            text = self.rx_num_leter.sub(r'\\1 \\2', text)   \n",
    "            node.set_content(text)\n",
    "        return nodes\n",
    "\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        TextCleaner(),\n",
    "        SentenceSplitter(chunk_size=512),\n",
    "        Settings.embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    "    cache=ingest_cache,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digest Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new Documents\n"
     ]
    }
   ],
   "source": [
    "input_dir = data_path + \"documents\"\n",
    "already_processed_files = list(set( m['file_path'] for m in chroma_collection.get(include=['metadatas'])['metadatas']))\n",
    "\n",
    "try:\n",
    "    documents = SimpleDirectoryReader(\n",
    "        input_dir=input_dir, \n",
    "        exclude=already_processed_files\n",
    "        ).load_data()\n",
    "\n",
    "\n",
    "    nodes = await pipeline.arun(documents=documents, show_progress=True)\n",
    "    ingest_cache.persist(ingest_cache_file)\n",
    "    len(nodes)\n",
    "except ValueError:\n",
    "    print('No new Documents')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Generation of the pairs Question / answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset\n",
    "    )\n",
    "from llama_index.core.llama_dataset.legacy.embedding import DEFAULT_QA_GENERATE_PROMPT_TMPL\n",
    "import os\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)\n",
    "\n",
    "qa_file = default_path + \"_qa.json\"\n",
    "regenerate = False\n",
    "\n",
    "if not os.path.isfile(qa_file) or regenerate:\n",
    "    \n",
    "\n",
    "    nodes = [item.node for item in index\n",
    "        .as_retriever(similarity_top_k=1000000)\n",
    "        .retrieve(\"\")]\n",
    "\n",
    "    qa_dataset = generate_question_context_pairs(\n",
    "        random.sample(nodes, min(len(nodes), 100)), \n",
    "        num_questions_per_chunk=1,\n",
    "        qa_generate_prompt_tmpl=DEFAULT_QA_GENERATE_PROMPT_TMPL+ \"\\n Please respond directly to the question without any introductory text or formatting.\",\n",
    "    )\n",
    "    qa_dataset.save_json(qa_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of the responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 65.51it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "# Convert to retriever\n",
    "retriever = index.as_retriever(similarity_top_k=5)\n",
    "# Define metrics\n",
    "metrics = [\"hit_rate\", \"mrr\", \"precision\", \"recall\", \"ap\", \"ndcg\"]\n",
    "\n",
    "# Create RetrieverEvaluator\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(metrics, retriever=retriever)\n",
    "qa_dataset = EmbeddingQAFinetuneDataset.from_json(qa_file)\n",
    "\n",
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset, show_progress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ap</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>top-2 eval</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.361167</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.361167</td>\n",
       "      <td>0.391114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr  precision  recall        ap      ndcg\n",
       "0  top-2 eval      0.48  0.361167      0.096    0.48  0.361167  0.391114"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    columns = {\n",
    "        \"retrievers\": [name],\n",
    "        **{k: [full_df[k].mean()] for k in metrics},\n",
    "    }\n",
    "\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "\n",
    "    return metric_df\n",
    "\n",
    "display_results(\"top-2 eval\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What was the outcome of Comorera's glosa (comment) on the debate, which settled a part of the discussion?\n",
      "Metrics: {'hit_rate': 1.0, 'mrr': 0.5, 'precision': 0.2, 'recall': 1.0, 'ap': 0.5, 'ndcg': 0.6309297535714575}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Comorera settled a part of the discussion by saying that they did not want to fight against Negrín, but rather change his attitude towards Catalonia."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved_ids ['affe51fe-76e3-4b1a-98a8-0d25419d1f50', '9a809744-4f34-41c5-b43e-7871fad239d6', '895e1ab0-38ab-4992-839a-b64029731291', 'db1ee260-0f94-48c5-8c83-696aae49b3e5', 'a7ea7d7e-d726-4b95-af60-1e31f7429e3d']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "['- 40 presentó un extenso informe en el que, animado por la entonces exitosa campaña de Teruel, abogaba por la política de guerra emprendida  por el gobierno Negrín, anunciaba – en términos optimistas – el restablecimiento de relaciones con la CNT y, sobre todo, examinaba las relaciones entre los dos gobiernos, el de la Generalitat y el de la República  y apuntaba una serie de problemas que habían de resolverse como  condición para la victoria. Los términos de Comorera fueron explícitos:  “Hi ha un altre fet negatiu, certes incomprensions davant el problema  de Catalunya. Hi ha funcionaris que no accepten el nostre Estatut. Hi  ha funcionaris que tracten de crear conflictes entre els dos governs  (…) Però això té relativament poca importància. El pitjor és que hi ha  determinades tendències a no acceptar la situació legal de Catalunya  creada en virtut del nostre Estatut i de la Constitució de la República, i  a produir situacions de fet que el dia de demà es tradueixin en un nou  estat jurídic(…) nosaltres estem en contra de tot allò que signifiqui retallar la Nostra autonomia” . El comunicado oficial de la sesión del Comité  Central finalizó apelando a “la convivència dels dos Governs (…) sobre  la base del respecte absolut a l’Estatut i els nostres drets autonòmics.', 'Propuso un cambio de actitud hacia Negrín y manifestó  “explicarse algo” de la actitud de Negrín si éste conocía  “la campaña sistemática de Comorera contra él”. La cuestión quedó zanjada por Comorera al glosar el debate  diciendo “que ellos no quieren luchar contra Negrín  sino cambiar su actitud para con Catalunya. El P.S.U. no es negrinista,  como no lo es seguramente el P.C. Dice que si por parte nuestra hay una  presión suficiente se podrá cambiar la actitud de Negrín”. Mije volvía a  las sospechas gruesas, Comorera intentaba esquivarlo, sin chocar abiertamente con él. Pero en cualquier caso el mayor, por el rango que había  tenido, crítico con Comorera en el seno del PSUC no consiguió el apoyo  explícito del Buró Político del P.C.E. En aquella misma sesión del ejecutivo', 'La  resistencia de Comorera dejó la propuesta de Dolores Ibarruri en suspenso, pero el incidente puso de relieve la división del Secretariado del PSUC  en un tema fundamental. Para la posición de Comorera, además, lo peor  era que Soliva y Wenceslao Colomer eran los que desempeñaban las  funciones operativas más importantes en el seno del Secretariado, en particular la relación con la organización del interior. A partir de ese momento  la mejoría de la actividad resistente del PSUC en Catalunya contrastó con  la nube de conflicto que se configuraba en el panorama de la dirección del  partido en Francia.\\nDurante un par de años sólo fue una nube. La expectativa de derrota de  la dictadura, por la presión interna – constantemente sobrevalorada, pero  creciente en 1946 y 1947 – y sobre todo por la presión exterior, que era  en la que ingenuamente confiaron por encima de todo las instituciones  republicanas en el exilio, evitó que las nubes que de tanto en tanto se formaban descargaran en tormenta. La identidad del PSUC y sus relaciones  con el PCE reapareció en el Tercer Pleno del Comité Central del PCE,', 'No obstante la armonía entre la dirección  del PCE y del PSUC y en el seno de la dirección renovada del PSUC, no  duró mucho. De manera inesperada, en mayo de 1946 Comorera fue convocado a una reunión del Buró Político del PCE – del que todavía no formaba parte – y allí Dolores Ibarruri le planteó explícitamente la integración  del PSUC dentro del PCE, aunque se mantuvieran las siglas del partido  catalán para identificar la que habría de ser de nuevo la regional catalana  del PCE, sólo a efectos formales propagandísticos. Comorera rechazó la  propuesta, aunque no inmediatamente, y acabó llevando la cuestión al  Secretariado del PSUC, donde Vidiella y Moix le dieron su apoyo, pero no  Soliva y Wenceslao Colomer, que – coherentes con su propia trayectoria  personal – no eran contrarios a la propuesta del Buró Político del PCE. La  resistencia de Comorera dejó la propuesta de Dolores Ibarruri en suspenso, pero el incidente puso de relieve la división del Secretariado del PSUC  en un tema fundamental. Para la posición de Comorera, además, lo peor  era que Soliva y Wenceslao Colomer eran los que desempeñaban las  funciones operativas más importantes en el seno del Secretariado, en particular la relación con la organización del interior. A partir de ese momento  la mejoría de la actividad resistente del PSUC en Catalunya contrastó con  la nube de conflicto que se configuraba en el panorama de la dirección del  partido en Francia.\\nDurante un par de años sólo fue una nube.', '- 59 en contra de ello, Leandre Colomer y Ricard Viñas basaron la ruptura en  las diferencias surgidas en el debate político de 1948 y 1949 y en la posición discrepante de Comorera con respecto a lo que se conocería como  el “viraje táctico”. Miquel Caminal, en su biografía de Comorera confesó  que era difícil precisar todo ello. Ahora pienso que todo sumó. Que sin las  discrepancias, o diferencias cuando menos, en el debate no se habría  suscitado de nuevo la cuestión de la relación entre el PSUC y el PCE y  que sin el conflicto  larvado que sobre esta última cuestión había el desenlace final podría haber sido otro. El resultado fue que en el verano de 1949  se precipitó el enfrentamiento por una sucesión de hechos fortuitos que  se embarcaron en aquella doble controversia, qué línea política había que  seguir y cuales habían de ser las relaciones del PSUC y del PCE, avocados de una manera u otra a novedades políticas. Vidiella cayó enfermo,  en junio de 1949, y encomendó la dirección de Lluita a Pere Ardiaca, que  volvía así a estar al frente del periódico portavoz del partido.']"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "nest_asyncio.apply()\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "for (sample_id, sample_query) in random.sample(list(qa_dataset.queries.items()),1):\n",
    "    sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "\n",
    "    eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "    print(eval_result) \n",
    "    response = query_engine.query(sample_query)\n",
    "    display(HTML(f'{response}'))\n",
    "    \n",
    "    print('retrieved_ids',f'{eval_result.retrieved_ids}')\n",
    "    display(HTML(f'{eval_result.retrieved_texts}'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
